[2022-03-22 18:03:49,889] {taskinstance.py:669} INFO - Dependencies all met for <TaskInstance: bigquery_data_load.load_data 2022-03-22T18:03:34.079853+00:00 [queued]>
[2022-03-22 18:03:50,069] {taskinstance.py:669} INFO - Dependencies all met for <TaskInstance: bigquery_data_load.load_data 2022-03-22T18:03:34.079853+00:00 [queued]>
[2022-03-22 18:03:50,071] {taskinstance.py:879} INFO - 
--------------------------------------------------------------------------------
[2022-03-22 18:03:50,072] {taskinstance.py:880} INFO - Starting attempt 1 of 1
[2022-03-22 18:03:50,072] {taskinstance.py:881} INFO - 
--------------------------------------------------------------------------------
[2022-03-22 18:03:50,384] {taskinstance.py:900} INFO - Executing <Task(GoogleCloudStorageToBigQueryOperator): load_data> on 2022-03-22T18:03:34.079853+00:00
[2022-03-22 18:03:50,390] {standard_task_runner.py:53} INFO - Started process 1846 to run task
[2022-03-22 18:03:50,681] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: bigquery_data_load.load_data 2022-03-22T18:03:34.079853+00:00 [running]> DESKTOP-NRCNVOU.localdomain
[2022-03-22 18:03:50,787] {logging_mixin.py:112} INFO - [2022-03-22 18:03:50,787] {gcp_api_base_hook.py:146} INFO - Getting connection using `google.auth.default()` since no key file is defined for hook.
[2022-03-22 18:03:51,247] {taskinstance.py:1145} ERROR - INTERNAL: No default project is specified
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 983, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py", line 268, in execute
    cursor.run_load(
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/contrib/hooks/bigquery_hook.py", line 1210, in run_load
    _split_tablename(table_input=destination_project_dataset_table,
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/contrib/hooks/bigquery_hook.py", line 2189, in _split_tablename
    raise ValueError("INTERNAL: No default project is specified")
ValueError: INTERNAL: No default project is specified
[2022-03-22 18:03:51,251] {taskinstance.py:1189} INFO - Marking task as FAILED.dag_id=bigquery_data_load, task_id=load_data, execution_date=20220322T180334, start_date=20220322T180349, end_date=20220322T180351
[2022-03-22 18:03:59,491] {logging_mixin.py:112} INFO - [2022-03-22 18:03:59,490] {local_task_job.py:103} INFO - Task exited with return code 1
