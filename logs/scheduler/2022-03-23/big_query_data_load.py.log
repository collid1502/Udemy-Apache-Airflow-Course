[2022-03-23 08:01:54,678] {scheduler_job.py:153} INFO - Started process (PID=4428) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:01:54,697] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:01:54,700] {logging_mixin.py:112} INFO - [2022-03-23 08:01:54,700] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:01:54,775] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:01:54,787] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:01:54,795] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:01:54,819] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:01:55,150] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:01:55,559] {scheduler_job.py:1294} INFO - Created <DagRun bigquery_data_load @ 2022-03-23T07:00:00+00:00: scheduled__2022-03-23T07:00:00+00:00, externally triggered: False>
[2022-03-23 08:01:55,579] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 07:00:00+00:00: scheduled__2022-03-23T07:00:00+00:00, externally triggered: False>
[2022-03-23 08:01:55,674] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:01:55,695] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 07:00:00+00:00 [scheduled]> in ORM
[2022-03-23 08:01:55,849] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.172 seconds
[2022-03-23 08:02:13,668] {scheduler_job.py:153} INFO - Started process (PID=4457) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:13,676] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:13,678] {logging_mixin.py:112} INFO - [2022-03-23 08:02:13,678] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:13,707] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:13,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:13,714] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:13,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:13,963] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:14,044] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 07:00:00+00:00: scheduled__2022-03-23T07:00:00+00:00, externally triggered: False>
[2022-03-23 08:02:14,262] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:14,285] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.617 seconds
[2022-03-23 08:02:17,700] {scheduler_job.py:153} INFO - Started process (PID=4479) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:17,708] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:17,715] {logging_mixin.py:112} INFO - [2022-03-23 08:02:17,714] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:17,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:17,790] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:17,792] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:17,810] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:18,121] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:18,201] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 07:00:00+00:00: scheduled__2022-03-23T07:00:00+00:00, externally triggered: False>
[2022-03-23 08:02:18,245] {logging_mixin.py:112} INFO - [2022-03-23 08:02:18,245] {dagrun.py:309} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 07:00:00+00:00: scheduled__2022-03-23T07:00:00+00:00, externally triggered: False> failed
[2022-03-23 08:02:18,344] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:18,373] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.673 seconds
[2022-03-23 08:02:21,640] {scheduler_job.py:153} INFO - Started process (PID=4489) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:21,649] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:21,650] {logging_mixin.py:112} INFO - [2022-03-23 08:02:21,650] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:21,697] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:21,703] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:21,706] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:21,724] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:22,013] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:22,135] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:22,170] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.530 seconds
[2022-03-23 08:02:25,673] {scheduler_job.py:153} INFO - Started process (PID=4494) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:25,679] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:25,680] {logging_mixin.py:112} INFO - [2022-03-23 08:02:25,680] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:25,710] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:25,715] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:25,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:25,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:25,992] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:26,095] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:26,120] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.448 seconds
[2022-03-23 08:02:29,677] {scheduler_job.py:153} INFO - Started process (PID=4502) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:29,691] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:29,692] {logging_mixin.py:112} INFO - [2022-03-23 08:02:29,692] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:29,773] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:29,780] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:29,787] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:29,817] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:30,267] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:30,421] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:30,450] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.774 seconds
[2022-03-23 08:02:33,696] {scheduler_job.py:153} INFO - Started process (PID=4514) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:33,710] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:33,715] {logging_mixin.py:112} INFO - [2022-03-23 08:02:33,714] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:33,767] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:33,781] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:33,795] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:33,824] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:34,219] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:34,356] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:34,411] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.715 seconds
[2022-03-23 08:02:37,688] {scheduler_job.py:153} INFO - Started process (PID=4522) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:37,694] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:37,696] {logging_mixin.py:112} INFO - [2022-03-23 08:02:37,695] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:37,728] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:37,733] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:37,737] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:37,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:38,162] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:38,243] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:38,267] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.580 seconds
[2022-03-23 08:02:47,040] {scheduler_job.py:153} INFO - Started process (PID=4536) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:47,049] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:47,051] {logging_mixin.py:112} INFO - [2022-03-23 08:02:47,051] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:47,120] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:47,125] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:47,128] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:47,142] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:48,470] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:48,606] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:48,642] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.602 seconds
[2022-03-23 08:02:49,780] {scheduler_job.py:153} INFO - Started process (PID=4541) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:49,796] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:49,801] {logging_mixin.py:112} INFO - [2022-03-23 08:02:49,801] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:49,897] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:49,903] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:49,915] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:49,935] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:50,310] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:50,445] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:50,482] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.702 seconds
[2022-03-23 08:02:53,740] {scheduler_job.py:153} INFO - Started process (PID=4546) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:53,746] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:53,748] {logging_mixin.py:112} INFO - [2022-03-23 08:02:53,747] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:53,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:53,787] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:53,789] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:53,804] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:54,058] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:54,137] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:54,158] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.418 seconds
[2022-03-23 08:02:57,789] {scheduler_job.py:153} INFO - Started process (PID=4552) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:57,811] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:02:57,819] {logging_mixin.py:112} INFO - [2022-03-23 08:02:57,819] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:57,935] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:02:57,941] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:57,945] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:02:57,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:02:58,416] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:02:58,527] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:02:58,564] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.775 seconds
[2022-03-23 08:03:03,534] {scheduler_job.py:153} INFO - Started process (PID=4560) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:03,540] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:03,541] {logging_mixin.py:112} INFO - [2022-03-23 08:03:03,541] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:03,583] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:03,589] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:03,593] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:03,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:03,850] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:03,928] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:03,948] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.414 seconds
[2022-03-23 08:03:05,992] {scheduler_job.py:153} INFO - Started process (PID=4564) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:05,999] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:06,002] {logging_mixin.py:112} INFO - [2022-03-23 08:03:06,001] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:06,055] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:06,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:06,071] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:06,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:06,352] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:06,479] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:06,508] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.516 seconds
[2022-03-23 08:03:10,029] {scheduler_job.py:153} INFO - Started process (PID=4572) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:10,034] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:10,035] {logging_mixin.py:112} INFO - [2022-03-23 08:03:10,035] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:10,065] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:10,070] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:10,072] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:10,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:10,714] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:10,780] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:10,808] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.779 seconds
[2022-03-23 08:03:15,003] {scheduler_job.py:153} INFO - Started process (PID=4577) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:15,029] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:15,033] {logging_mixin.py:112} INFO - [2022-03-23 08:03:15,033] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:15,299] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:15,313] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:15,316] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:15,345] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:15,898] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:16,113] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:16,138] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.135 seconds
[2022-03-23 08:03:18,045] {scheduler_job.py:153} INFO - Started process (PID=4585) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:18,052] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:18,053] {logging_mixin.py:112} INFO - [2022-03-23 08:03:18,053] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:18,092] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:18,096] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:18,098] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:18,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:18,428] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:18,581] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:18,607] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.562 seconds
[2022-03-23 08:03:22,209] {scheduler_job.py:153} INFO - Started process (PID=4590) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:22,221] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:22,226] {logging_mixin.py:112} INFO - [2022-03-23 08:03:22,225] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:22,344] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:22,351] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:22,354] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:22,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:23,233] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:23,984] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:24,146] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.937 seconds
[2022-03-23 08:03:28,005] {scheduler_job.py:153} INFO - Started process (PID=4595) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:28,028] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:28,032] {logging_mixin.py:112} INFO - [2022-03-23 08:03:28,032] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:28,336] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:28,344] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:28,348] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:28,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:29,927] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:30,058] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:30,085] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.080 seconds
[2022-03-23 08:03:33,020] {scheduler_job.py:153} INFO - Started process (PID=4606) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:33,037] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:33,052] {logging_mixin.py:112} INFO - [2022-03-23 08:03:33,051] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:33,129] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:33,134] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:33,137] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:33,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:33,536] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:33,620] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:33,642] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.622 seconds
[2022-03-23 08:03:36,470] {scheduler_job.py:153} INFO - Started process (PID=4611) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:36,479] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:36,483] {logging_mixin.py:112} INFO - [2022-03-23 08:03:36,483] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:36,562] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:36,570] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:36,574] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:36,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:36,886] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:36,976] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:37,006] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.536 seconds
[2022-03-23 08:03:40,491] {scheduler_job.py:153} INFO - Started process (PID=4616) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:40,497] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:40,499] {logging_mixin.py:112} INFO - [2022-03-23 08:03:40,498] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:40,548] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:40,553] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:40,555] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:40,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:40,821] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:40,898] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:40,923] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.432 seconds
[2022-03-23 08:03:44,506] {scheduler_job.py:153} INFO - Started process (PID=4624) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:44,511] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:44,513] {logging_mixin.py:112} INFO - [2022-03-23 08:03:44,512] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:44,542] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:44,546] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:44,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:44,558] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:44,822] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:44,908] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:44,932] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.426 seconds
[2022-03-23 08:03:48,470] {scheduler_job.py:153} INFO - Started process (PID=4629) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:48,477] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:48,479] {logging_mixin.py:112} INFO - [2022-03-23 08:03:48,479] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:48,505] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:48,510] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:48,512] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:48,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:48,742] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:48,827] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:48,849] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.379 seconds
[2022-03-23 08:03:52,518] {scheduler_job.py:153} INFO - Started process (PID=4634) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:52,527] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:52,529] {logging_mixin.py:112} INFO - [2022-03-23 08:03:52,528] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:52,558] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:52,562] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:52,565] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:52,572] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:52,923] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:53,025] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:53,047] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.529 seconds
[2022-03-23 08:03:56,522] {scheduler_job.py:153} INFO - Started process (PID=4642) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:56,528] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:03:56,529] {logging_mixin.py:112} INFO - [2022-03-23 08:03:56,529] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:56,560] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:03:56,564] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:56,567] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:03:56,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:03:56,842] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:03:56,926] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:03:56,951] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.429 seconds
[2022-03-23 08:04:00,495] {scheduler_job.py:153} INFO - Started process (PID=4647) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:00,501] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:00,502] {logging_mixin.py:112} INFO - [2022-03-23 08:04:00,502] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:00,534] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:00,538] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:00,541] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:00,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:00,774] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:00,859] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:00,881] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.386 seconds
[2022-03-23 08:04:04,843] {scheduler_job.py:153} INFO - Started process (PID=4655) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:04,860] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:04,871] {logging_mixin.py:112} INFO - [2022-03-23 08:04:04,871] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:05,021] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:05,028] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:05,039] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:05,052] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:05,504] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:05,608] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:05,635] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.792 seconds
[2022-03-23 08:04:08,534] {scheduler_job.py:153} INFO - Started process (PID=4660) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:08,540] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:08,541] {logging_mixin.py:112} INFO - [2022-03-23 08:04:08,541] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:08,569] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:08,573] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:08,575] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:08,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:08,805] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:08,872] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:08,892] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.358 seconds
[2022-03-23 08:04:12,520] {scheduler_job.py:153} INFO - Started process (PID=4665) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:12,527] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:12,528] {logging_mixin.py:112} INFO - [2022-03-23 08:04:12,528] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:12,576] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:12,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:12,586] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:12,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:12,858] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:12,937] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:12,974] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-03-23 08:04:16,532] {scheduler_job.py:153} INFO - Started process (PID=4673) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:16,538] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:16,540] {logging_mixin.py:112} INFO - [2022-03-23 08:04:16,540] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:16,573] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:16,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:16,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:16,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:16,876] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:16,956] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:16,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.447 seconds
[2022-03-23 08:04:20,554] {scheduler_job.py:153} INFO - Started process (PID=4678) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:20,561] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:20,563] {logging_mixin.py:112} INFO - [2022-03-23 08:04:20,562] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:20,593] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:20,597] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:20,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:20,607] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:20,867] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:20,958] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:20,998] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.444 seconds
[2022-03-23 08:04:24,577] {scheduler_job.py:153} INFO - Started process (PID=4686) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:24,592] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:24,594] {logging_mixin.py:112} INFO - [2022-03-23 08:04:24,594] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:24,717] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:24,723] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:24,734] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:24,748] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:25,184] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:25,485] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:25,512] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.935 seconds
[2022-03-23 08:04:28,535] {scheduler_job.py:153} INFO - Started process (PID=4691) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:28,544] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:28,545] {logging_mixin.py:112} INFO - [2022-03-23 08:04:28,545] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:28,578] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:28,582] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:28,584] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:28,599] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:28,854] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:28,938] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:28,960] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.424 seconds
[2022-03-23 08:04:32,566] {scheduler_job.py:153} INFO - Started process (PID=4699) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:32,574] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:32,576] {logging_mixin.py:112} INFO - [2022-03-23 08:04:32,575] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:32,610] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:32,614] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:32,616] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:32,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:32,921] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:33,122] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:33,171] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.605 seconds
[2022-03-23 08:04:36,533] {scheduler_job.py:153} INFO - Started process (PID=4704) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:36,544] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:36,546] {logging_mixin.py:112} INFO - [2022-03-23 08:04:36,545] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:36,591] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:36,596] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:36,598] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:36,615] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:37,285] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:37,558] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:37,817] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.284 seconds
[2022-03-23 08:04:40,544] {scheduler_job.py:153} INFO - Started process (PID=4709) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:40,554] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:40,557] {logging_mixin.py:112} INFO - [2022-03-23 08:04:40,556] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:40,616] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:40,623] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:40,626] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:40,648] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:41,351] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:41,489] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:41,523] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.979 seconds
[2022-03-23 08:04:44,587] {scheduler_job.py:153} INFO - Started process (PID=4717) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:44,604] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:44,605] {logging_mixin.py:112} INFO - [2022-03-23 08:04:44,605] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:44,817] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:44,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:44,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:44,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:45,459] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:04:45,569] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:04:45,598] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.011 seconds
[2022-03-23 08:04:51,561] {scheduler_job.py:153} INFO - Started process (PID=4725) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:51,566] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:04:51,567] {logging_mixin.py:112} INFO - [2022-03-23 08:04:51,567] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:04:51,609] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:04:51,613] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:51,615] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:04:51,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:01,870] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:02,027] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:02,100] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 10.540 seconds
[2022-03-23 08:05:03,090] {scheduler_job.py:153} INFO - Started process (PID=4740) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:03,106] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:03,108] {logging_mixin.py:112} INFO - [2022-03-23 08:05:03,108] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:03,210] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:03,224] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:03,227] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:03,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:03,894] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:04,206] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:04,286] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.197 seconds
[2022-03-23 08:05:06,598] {scheduler_job.py:153} INFO - Started process (PID=4746) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:06,604] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:06,616] {logging_mixin.py:112} INFO - [2022-03-23 08:05:06,616] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:06,667] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:06,677] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:06,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:06,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:07,053] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:07,482] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:07,514] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.916 seconds
[2022-03-23 08:05:09,073] {scheduler_job.py:153} INFO - Started process (PID=4751) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:09,081] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:09,083] {logging_mixin.py:112} INFO - [2022-03-23 08:05:09,083] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:09,134] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:09,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:09,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:09,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:09,717] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:09,841] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:09,864] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.791 seconds
[2022-03-23 08:05:13,113] {scheduler_job.py:153} INFO - Started process (PID=4756) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:13,121] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:13,122] {logging_mixin.py:112} INFO - [2022-03-23 08:05:13,122] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:13,217] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:13,222] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:13,225] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:13,242] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:13,713] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:13,828] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:13,883] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.770 seconds
[2022-03-23 08:05:17,061] {scheduler_job.py:153} INFO - Started process (PID=4764) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:17,067] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:17,068] {logging_mixin.py:112} INFO - [2022-03-23 08:05:17,068] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:17,108] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:17,112] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:17,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:17,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:17,600] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:17,731] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:17,770] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.709 seconds
[2022-03-23 08:05:21,078] {scheduler_job.py:153} INFO - Started process (PID=4769) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:21,085] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:21,087] {logging_mixin.py:112} INFO - [2022-03-23 08:05:21,087] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:21,137] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:21,150] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:21,153] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:21,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:21,726] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:21,878] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:21,913] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.836 seconds
[2022-03-23 08:05:25,112] {scheduler_job.py:153} INFO - Started process (PID=4774) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:25,117] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:25,118] {logging_mixin.py:112} INFO - [2022-03-23 08:05:25,118] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:25,144] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:25,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:25,151] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:25,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:25,667] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:25,762] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:25,795] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.683 seconds
[2022-03-23 08:05:29,079] {scheduler_job.py:153} INFO - Started process (PID=4782) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:29,084] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:29,086] {logging_mixin.py:112} INFO - [2022-03-23 08:05:29,086] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:29,134] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:29,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:29,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:29,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:29,615] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:29,722] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:29,747] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.668 seconds
[2022-03-23 08:05:33,085] {scheduler_job.py:153} INFO - Started process (PID=4787) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:33,096] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:33,098] {logging_mixin.py:112} INFO - [2022-03-23 08:05:33,097] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:33,136] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:33,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:33,150] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:33,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:33,549] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:33,652] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:33,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.597 seconds
[2022-03-23 08:05:37,189] {scheduler_job.py:153} INFO - Started process (PID=4795) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:37,199] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:37,200] {logging_mixin.py:112} INFO - [2022-03-23 08:05:37,200] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:37,256] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:37,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:37,273] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:37,312] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:37,716] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:37,830] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:37,860] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.671 seconds
[2022-03-23 08:05:41,107] {scheduler_job.py:153} INFO - Started process (PID=4800) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:41,113] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:41,115] {logging_mixin.py:112} INFO - [2022-03-23 08:05:41,115] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:41,147] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:41,152] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:41,154] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:41,167] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:41,468] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:41,547] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:41,572] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.465 seconds
[2022-03-23 08:05:45,125] {scheduler_job.py:153} INFO - Started process (PID=4805) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:45,131] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:45,133] {logging_mixin.py:112} INFO - [2022-03-23 08:05:45,133] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:45,180] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:45,185] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:45,189] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:45,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:45,452] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:45,544] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:45,571] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.446 seconds
[2022-03-23 08:05:49,270] {scheduler_job.py:153} INFO - Started process (PID=4813) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:49,279] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:49,280] {logging_mixin.py:112} INFO - [2022-03-23 08:05:49,280] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:49,329] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:49,334] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:49,341] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:49,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:49,650] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:49,753] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:49,779] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.508 seconds
[2022-03-23 08:05:53,108] {scheduler_job.py:153} INFO - Started process (PID=4818) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:53,114] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:53,116] {logging_mixin.py:112} INFO - [2022-03-23 08:05:53,116] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:53,149] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:53,154] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:53,157] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:53,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:53,459] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:53,567] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:53,592] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.484 seconds
[2022-03-23 08:05:57,146] {scheduler_job.py:153} INFO - Started process (PID=4823) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:57,153] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:05:57,156] {logging_mixin.py:112} INFO - [2022-03-23 08:05:57,156] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:57,202] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:05:57,209] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:57,212] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:05:57,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:05:57,701] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:05:57,814] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:05:57,839] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.693 seconds
[2022-03-23 08:06:01,626] {scheduler_job.py:153} INFO - Started process (PID=4831) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:01,632] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:01,634] {logging_mixin.py:112} INFO - [2022-03-23 08:06:01,633] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:01,673] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:01,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:01,681] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:01,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:02,115] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:02,271] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:02,301] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.676 seconds
[2022-03-23 08:06:05,142] {scheduler_job.py:153} INFO - Started process (PID=4838) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:05,149] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:05,151] {logging_mixin.py:112} INFO - [2022-03-23 08:06:05,150] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:05,188] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:05,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:05,196] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:05,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:05,470] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:05,569] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:05,607] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.466 seconds
[2022-03-23 08:06:09,157] {scheduler_job.py:153} INFO - Started process (PID=4846) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:09,163] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:09,165] {logging_mixin.py:112} INFO - [2022-03-23 08:06:09,164] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:09,193] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:09,197] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:09,199] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:09,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:09,443] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:09,530] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:09,551] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.394 seconds
[2022-03-23 08:06:13,201] {scheduler_job.py:153} INFO - Started process (PID=4851) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:13,208] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:13,209] {logging_mixin.py:112} INFO - [2022-03-23 08:06:13,209] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:13,251] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:13,257] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:13,259] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:13,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:13,519] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:13,594] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:13,616] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-03-23 08:06:17,149] {scheduler_job.py:153} INFO - Started process (PID=4856) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:17,155] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:17,158] {logging_mixin.py:112} INFO - [2022-03-23 08:06:17,157] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:17,195] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:17,200] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:17,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:17,218] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:17,464] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:17,560] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:17,591] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.442 seconds
[2022-03-23 08:06:21,301] {scheduler_job.py:153} INFO - Started process (PID=4864) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:21,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:21,320] {logging_mixin.py:112} INFO - [2022-03-23 08:06:21,320] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:21,392] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:21,399] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:21,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:21,424] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:22,302] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:22,616] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:22,655] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.354 seconds
[2022-03-23 08:06:30,058] {scheduler_job.py:153} INFO - Started process (PID=4875) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:30,065] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:30,067] {logging_mixin.py:112} INFO - [2022-03-23 08:06:30,067] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:30,103] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:30,109] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:30,112] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:30,130] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:30,577] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:30,713] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:30,744] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.686 seconds
[2022-03-23 08:06:32,971] {scheduler_job.py:153} INFO - Started process (PID=4880) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:32,978] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:32,979] {logging_mixin.py:112} INFO - [2022-03-23 08:06:32,979] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:33,015] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:33,019] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:33,021] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:33,036] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:33,279] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:33,364] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:33,390] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-03-23 08:06:36,976] {scheduler_job.py:153} INFO - Started process (PID=4885) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:36,983] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:36,984] {logging_mixin.py:112} INFO - [2022-03-23 08:06:36,984] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:37,037] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:37,042] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:37,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:37,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:37,408] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:37,503] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:37,529] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.554 seconds
[2022-03-23 08:06:41,033] {scheduler_job.py:153} INFO - Started process (PID=4893) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:41,049] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:41,051] {logging_mixin.py:112} INFO - [2022-03-23 08:06:41,051] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:41,193] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:41,199] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:41,207] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:41,216] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:41,520] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:41,636] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:41,661] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.628 seconds
[2022-03-23 08:06:44,994] {scheduler_job.py:153} INFO - Started process (PID=4901) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:45,000] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:45,002] {logging_mixin.py:112} INFO - [2022-03-23 08:06:45,002] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:45,041] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:45,047] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:45,056] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:45,065] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:45,331] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:45,439] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:45,465] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.471 seconds
[2022-03-23 08:06:49,005] {scheduler_job.py:153} INFO - Started process (PID=4906) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:49,014] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:49,015] {logging_mixin.py:112} INFO - [2022-03-23 08:06:49,015] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:49,046] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:49,050] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:49,059] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:49,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:49,321] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:49,412] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:49,433] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.428 seconds
[2022-03-23 08:06:53,031] {scheduler_job.py:153} INFO - Started process (PID=4912) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:53,040] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:53,042] {logging_mixin.py:112} INFO - [2022-03-23 08:06:53,041] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:53,100] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:53,111] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:53,126] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:53,153] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:53,424] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:53,524] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:53,546] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.515 seconds
[2022-03-23 08:06:56,989] {scheduler_job.py:153} INFO - Started process (PID=4920) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:56,994] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:06:56,996] {logging_mixin.py:112} INFO - [2022-03-23 08:06:56,995] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:57,025] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:06:57,033] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:57,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:06:57,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:06:57,301] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:06:57,412] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:06:57,442] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-03-23 08:07:01,007] {scheduler_job.py:153} INFO - Started process (PID=4925) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:01,014] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:01,016] {logging_mixin.py:112} INFO - [2022-03-23 08:07:01,016] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:01,044] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:01,053] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:01,058] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:01,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:01,263] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:01,382] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:01,414] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.407 seconds
[2022-03-23 08:07:05,089] {scheduler_job.py:153} INFO - Started process (PID=4936) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:05,098] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:05,100] {logging_mixin.py:112} INFO - [2022-03-23 08:07:05,099] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:05,181] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:05,191] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:05,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:05,205] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:05,564] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:05,701] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:05,741] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.653 seconds
[2022-03-23 08:07:09,017] {scheduler_job.py:153} INFO - Started process (PID=4943) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:09,023] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:09,025] {logging_mixin.py:112} INFO - [2022-03-23 08:07:09,025] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:09,058] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:09,062] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:09,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:09,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:09,299] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:09,391] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:09,413] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.396 seconds
[2022-03-23 08:07:13,012] {scheduler_job.py:153} INFO - Started process (PID=4948) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:13,017] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:13,019] {logging_mixin.py:112} INFO - [2022-03-23 08:07:13,019] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:13,062] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:13,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:13,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:13,080] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:13,334] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:13,411] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:13,433] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.422 seconds
[2022-03-23 08:07:17,083] {scheduler_job.py:153} INFO - Started process (PID=4956) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:17,092] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:17,094] {logging_mixin.py:112} INFO - [2022-03-23 08:07:17,093] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:17,142] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:17,147] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:17,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:17,157] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:17,415] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:17,512] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:17,541] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.458 seconds
[2022-03-23 08:07:21,038] {scheduler_job.py:153} INFO - Started process (PID=4961) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:21,044] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:21,045] {logging_mixin.py:112} INFO - [2022-03-23 08:07:21,045] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:21,088] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:21,095] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:21,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:21,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:21,595] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:21,888] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:21,983] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.945 seconds
[2022-03-23 08:07:25,038] {scheduler_job.py:153} INFO - Started process (PID=4988) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:25,044] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:25,046] {logging_mixin.py:112} INFO - [2022-03-23 08:07:25,045] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:25,098] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:25,102] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:25,104] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:25,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:25,375] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:25,468] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:25,492] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-03-23 08:07:29,065] {scheduler_job.py:153} INFO - Started process (PID=4993) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:29,076] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:29,078] {logging_mixin.py:112} INFO - [2022-03-23 08:07:29,077] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:29,129] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:29,133] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:29,135] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:29,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:29,407] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:29,474] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:29,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.433 seconds
[2022-03-23 08:07:33,061] {scheduler_job.py:153} INFO - Started process (PID=5002) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:33,075] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:33,077] {logging_mixin.py:112} INFO - [2022-03-23 08:07:33,077] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:33,126] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:33,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:33,136] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:33,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:33,531] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:33,648] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:33,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.621 seconds
[2022-03-23 08:07:37,065] {scheduler_job.py:153} INFO - Started process (PID=5013) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:37,093] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:37,096] {logging_mixin.py:112} INFO - [2022-03-23 08:07:37,096] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:37,159] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:37,165] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:37,168] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:37,185] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:37,745] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:37,935] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:37,971] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.906 seconds
[2022-03-23 08:07:41,223] {scheduler_job.py:153} INFO - Started process (PID=5025) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:41,279] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:41,283] {logging_mixin.py:112} INFO - [2022-03-23 08:07:41,282] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:41,411] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:41,443] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:41,460] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:41,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:41,963] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:42,352] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:42,500] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.278 seconds
[2022-03-23 08:07:45,073] {scheduler_job.py:153} INFO - Started process (PID=5033) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:45,092] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:45,094] {logging_mixin.py:112} INFO - [2022-03-23 08:07:45,093] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:45,159] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:45,169] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:45,171] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:45,179] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:46,228] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:46,342] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:46,373] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.300 seconds
[2022-03-23 08:07:49,232] {scheduler_job.py:153} INFO - Started process (PID=5038) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:49,270] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:49,278] {logging_mixin.py:112} INFO - [2022-03-23 08:07:49,278] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:49,451] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:49,459] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:49,463] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:49,489] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:49,802] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:49,985] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:50,017] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.786 seconds
[2022-03-23 08:07:53,107] {scheduler_job.py:153} INFO - Started process (PID=5043) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:53,120] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:53,121] {logging_mixin.py:112} INFO - [2022-03-23 08:07:53,121] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:53,160] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:53,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:53,166] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:53,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:53,717] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:54,199] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:54,247] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.140 seconds
[2022-03-23 08:07:57,384] {scheduler_job.py:153} INFO - Started process (PID=5051) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:57,418] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:07:57,468] {logging_mixin.py:112} INFO - [2022-03-23 08:07:57,467] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:57,535] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:07:57,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:57,553] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:07:57,586] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:07:58,202] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:07:58,532] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:07:58,631] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.247 seconds
[2022-03-23 08:08:01,101] {scheduler_job.py:153} INFO - Started process (PID=5056) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:01,116] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:01,121] {logging_mixin.py:112} INFO - [2022-03-23 08:08:01,120] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:01,211] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:01,215] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:01,217] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:01,229] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:01,586] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:08:01,702] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:08:01,725] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.625 seconds
[2022-03-23 08:08:05,312] {scheduler_job.py:153} INFO - Started process (PID=5061) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:05,345] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:05,348] {logging_mixin.py:112} INFO - [2022-03-23 08:08:05,347] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:05,431] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:05,436] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:05,444] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:05,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:06,238] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:08:06,420] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:08:06,466] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.154 seconds
[2022-03-23 08:08:09,088] {scheduler_job.py:153} INFO - Started process (PID=5069) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:09,102] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:09,103] {logging_mixin.py:112} INFO - [2022-03-23 08:08:09,103] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:09,138] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:09,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:09,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:09,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:09,337] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.249 seconds
[2022-03-23 08:08:13,186] {scheduler_job.py:153} INFO - Started process (PID=5074) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:13,202] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:13,204] {logging_mixin.py:112} INFO - [2022-03-23 08:08:13,203] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:13,357] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:13,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:13,396] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:13,422] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:13,693] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.508 seconds
[2022-03-23 08:08:17,215] {scheduler_job.py:153} INFO - Started process (PID=5080) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:17,236] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:17,245] {logging_mixin.py:112} INFO - [2022-03-23 08:08:17,245] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:17,354] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:17,387] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:17,395] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:17,450] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:18,447] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.233 seconds
[2022-03-23 08:08:21,120] {scheduler_job.py:153} INFO - Started process (PID=5086) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:21,128] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:21,130] {logging_mixin.py:112} INFO - [2022-03-23 08:08:21,129] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:21,177] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:21,181] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:21,183] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:21,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:21,376] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.256 seconds
[2022-03-23 08:08:25,107] {scheduler_job.py:153} INFO - Started process (PID=5093) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:25,114] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:25,116] {logging_mixin.py:112} INFO - [2022-03-23 08:08:25,116] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:25,154] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:25,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:25,167] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:25,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:25,456] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.349 seconds
[2022-03-23 08:08:29,149] {scheduler_job.py:153} INFO - Started process (PID=5098) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:29,154] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:29,155] {logging_mixin.py:112} INFO - [2022-03-23 08:08:29,155] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:29,211] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:29,216] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:29,221] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:29,231] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:29,711] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.563 seconds
[2022-03-23 08:08:33,290] {scheduler_job.py:153} INFO - Started process (PID=5106) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:33,305] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:33,387] {logging_mixin.py:112} INFO - [2022-03-23 08:08:33,387] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:33,757] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:33,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:33,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:33,790] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:34,338] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.049 seconds
[2022-03-23 08:08:37,118] {scheduler_job.py:153} INFO - Started process (PID=5111) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:37,124] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:37,126] {logging_mixin.py:112} INFO - [2022-03-23 08:08:37,126] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:37,158] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:37,163] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:37,165] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:37,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:37,378] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.260 seconds
[2022-03-23 08:08:41,165] {scheduler_job.py:153} INFO - Started process (PID=5116) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:41,171] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:41,175] {logging_mixin.py:112} INFO - [2022-03-23 08:08:41,175] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:41,223] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:41,230] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:41,232] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:41,245] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:41,459] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.294 seconds
[2022-03-23 08:08:45,140] {scheduler_job.py:153} INFO - Started process (PID=5121) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:45,145] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:45,146] {logging_mixin.py:112} INFO - [2022-03-23 08:08:45,146] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:45,184] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:45,193] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:45,196] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:45,238] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:45,442] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.302 seconds
[2022-03-23 08:08:49,138] {scheduler_job.py:153} INFO - Started process (PID=5130) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:49,144] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:49,146] {logging_mixin.py:112} INFO - [2022-03-23 08:08:49,146] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:49,183] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:49,188] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:49,191] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:49,200] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:49,447] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.309 seconds
[2022-03-23 08:08:53,823] {scheduler_job.py:153} INFO - Started process (PID=5135) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:53,839] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:53,841] {logging_mixin.py:112} INFO - [2022-03-23 08:08:53,841] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:53,887] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:53,904] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:53,907] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:53,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:54,150] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:08:57,161] {scheduler_job.py:153} INFO - Started process (PID=5141) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:57,169] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:08:57,170] {logging_mixin.py:112} INFO - [2022-03-23 08:08:57,170] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:57,214] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:08:57,218] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:57,220] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:08:57,229] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:08:57,392] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.231 seconds
[2022-03-23 08:09:01,147] {scheduler_job.py:153} INFO - Started process (PID=5148) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:01,153] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:01,155] {logging_mixin.py:112} INFO - [2022-03-23 08:09:01,155] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:01,194] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:01,199] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:01,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:01,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:01,407] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.261 seconds
[2022-03-23 08:09:05,197] {scheduler_job.py:153} INFO - Started process (PID=5153) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:05,202] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:05,204] {logging_mixin.py:112} INFO - [2022-03-23 08:09:05,203] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:05,243] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:05,247] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:05,249] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:05,264] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:06,467] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.270 seconds
[2022-03-23 08:09:09,154] {scheduler_job.py:153} INFO - Started process (PID=5161) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:09,161] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:09,162] {logging_mixin.py:112} INFO - [2022-03-23 08:09:09,162] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:09,193] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:09,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:09,200] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:09,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:09,373] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.219 seconds
[2022-03-23 08:09:13,167] {scheduler_job.py:153} INFO - Started process (PID=5166) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:13,178] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:13,180] {logging_mixin.py:112} INFO - [2022-03-23 08:09:13,179] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:13,214] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:13,219] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:13,221] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:13,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:13,432] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.265 seconds
[2022-03-23 08:09:17,221] {scheduler_job.py:153} INFO - Started process (PID=5171) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:17,230] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:17,231] {logging_mixin.py:112} INFO - [2022-03-23 08:09:17,231] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:17,277] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:17,284] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:17,287] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:17,301] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:17,484] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:09:21,176] {scheduler_job.py:153} INFO - Started process (PID=5180) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:21,183] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:21,185] {logging_mixin.py:112} INFO - [2022-03-23 08:09:21,184] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:21,231] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:21,236] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:21,239] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:21,253] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:21,493] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.318 seconds
[2022-03-23 08:09:25,182] {scheduler_job.py:153} INFO - Started process (PID=5185) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:25,191] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:25,193] {logging_mixin.py:112} INFO - [2022-03-23 08:09:25,193] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:25,222] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:25,227] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:25,228] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:25,237] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:25,418] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.236 seconds
[2022-03-23 08:09:29,225] {scheduler_job.py:153} INFO - Started process (PID=5190) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:29,231] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:29,232] {logging_mixin.py:112} INFO - [2022-03-23 08:09:29,232] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:29,266] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:29,270] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:29,273] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:29,282] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:29,460] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.235 seconds
[2022-03-23 08:09:33,199] {scheduler_job.py:153} INFO - Started process (PID=5198) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:33,207] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:33,209] {logging_mixin.py:112} INFO - [2022-03-23 08:09:33,209] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:33,238] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:33,242] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:33,244] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:33,252] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:33,416] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.217 seconds
[2022-03-23 08:09:37,218] {scheduler_job.py:153} INFO - Started process (PID=5203) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:37,226] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:37,229] {logging_mixin.py:112} INFO - [2022-03-23 08:09:37,229] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:37,264] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:37,268] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:37,271] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:37,285] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:37,479] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.261 seconds
[2022-03-23 08:09:41,243] {scheduler_job.py:153} INFO - Started process (PID=5208) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:41,292] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:41,297] {logging_mixin.py:112} INFO - [2022-03-23 08:09:41,297] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:41,375] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:41,381] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:41,386] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:41,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:41,670] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.427 seconds
[2022-03-23 08:09:45,204] {scheduler_job.py:153} INFO - Started process (PID=5216) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:45,210] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:45,212] {logging_mixin.py:112} INFO - [2022-03-23 08:09:45,212] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:45,251] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:45,255] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:45,258] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:45,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:45,518] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-03-23 08:09:49,210] {scheduler_job.py:153} INFO - Started process (PID=5221) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:49,216] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:49,217] {logging_mixin.py:112} INFO - [2022-03-23 08:09:49,217] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:49,248] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:49,252] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:49,254] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:49,268] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:49,448] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.239 seconds
[2022-03-23 08:09:53,250] {scheduler_job.py:153} INFO - Started process (PID=5229) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:53,255] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:53,256] {logging_mixin.py:112} INFO - [2022-03-23 08:09:53,256] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:53,291] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:53,295] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:53,297] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:53,305] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:53,478] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.229 seconds
[2022-03-23 08:09:57,239] {scheduler_job.py:153} INFO - Started process (PID=5235) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:57,244] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:09:57,246] {logging_mixin.py:112} INFO - [2022-03-23 08:09:57,246] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:57,273] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:09:57,278] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:57,279] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:09:57,288] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:09:57,471] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.232 seconds
[2022-03-23 08:10:01,210] {scheduler_job.py:153} INFO - Started process (PID=5240) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:01,216] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:01,217] {logging_mixin.py:112} INFO - [2022-03-23 08:10:01,217] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:01,244] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:01,248] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:01,250] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:01,259] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:01,443] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.233 seconds
[2022-03-23 08:10:05,259] {scheduler_job.py:153} INFO - Started process (PID=5248) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:05,265] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:05,266] {logging_mixin.py:112} INFO - [2022-03-23 08:10:05,266] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:05,311] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:05,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:05,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:05,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:05,491] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.232 seconds
[2022-03-23 08:10:09,243] {scheduler_job.py:153} INFO - Started process (PID=5253) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:09,249] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:09,250] {logging_mixin.py:112} INFO - [2022-03-23 08:10:09,250] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:09,288] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:09,293] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:09,295] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:09,305] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:09,477] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.234 seconds
[2022-03-23 08:10:13,282] {scheduler_job.py:153} INFO - Started process (PID=5261) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:13,292] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:13,295] {logging_mixin.py:112} INFO - [2022-03-23 08:10:13,294] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:13,335] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:13,339] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:13,341] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:13,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:13,510] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.228 seconds
[2022-03-23 08:10:17,297] {scheduler_job.py:153} INFO - Started process (PID=5266) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:17,302] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:17,304] {logging_mixin.py:112} INFO - [2022-03-23 08:10:17,304] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:17,338] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:17,342] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:17,344] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:17,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:17,528] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.230 seconds
[2022-03-23 08:10:21,276] {scheduler_job.py:153} INFO - Started process (PID=5271) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:21,293] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:21,303] {logging_mixin.py:112} INFO - [2022-03-23 08:10:21,302] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:21,390] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:21,397] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:21,399] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:21,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:21,582] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.306 seconds
[2022-03-23 08:10:25,274] {scheduler_job.py:153} INFO - Started process (PID=5279) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:25,280] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:25,281] {logging_mixin.py:112} INFO - [2022-03-23 08:10:25,281] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:25,312] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:25,316] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:25,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:25,328] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:25,586] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-03-23 08:10:29,313] {scheduler_job.py:153} INFO - Started process (PID=5285) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:29,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:29,320] {logging_mixin.py:112} INFO - [2022-03-23 08:10:29,320] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:29,363] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:29,368] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:29,370] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:29,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:29,541] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.228 seconds
[2022-03-23 08:10:33,269] {scheduler_job.py:153} INFO - Started process (PID=5290) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:33,275] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:33,277] {logging_mixin.py:112} INFO - [2022-03-23 08:10:33,277] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:33,310] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:33,317] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:33,319] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:33,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:33,495] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.227 seconds
[2022-03-23 08:10:37,303] {scheduler_job.py:153} INFO - Started process (PID=5298) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:37,317] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:37,318] {logging_mixin.py:112} INFO - [2022-03-23 08:10:37,318] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:37,359] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:37,366] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:37,369] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:37,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:37,620] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.317 seconds
[2022-03-23 08:10:41,372] {scheduler_job.py:153} INFO - Started process (PID=5303) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:41,387] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:41,392] {logging_mixin.py:112} INFO - [2022-03-23 08:10:41,392] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:41,442] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:41,448] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:41,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:41,465] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:41,721] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.350 seconds
[2022-03-23 08:10:45,325] {scheduler_job.py:153} INFO - Started process (PID=5311) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:45,332] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:45,333] {logging_mixin.py:112} INFO - [2022-03-23 08:10:45,333] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:45,378] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:45,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:45,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:45,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:45,669] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.344 seconds
[2022-03-23 08:10:49,310] {scheduler_job.py:153} INFO - Started process (PID=5316) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:49,316] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:49,318] {logging_mixin.py:112} INFO - [2022-03-23 08:10:49,317] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:49,359] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:49,366] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:49,370] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:49,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:49,698] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:10:49,955] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:10:49,986] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.676 seconds
[2022-03-23 08:10:53,365] {scheduler_job.py:153} INFO - Started process (PID=5321) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:53,372] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:10:53,379] {logging_mixin.py:112} INFO - [2022-03-23 08:10:53,378] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:53,569] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:10:53,576] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:53,580] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:10:53,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:10:54,293] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:10:54,387] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:10:49.846461+00:00: manual__2022-03-23T08:10:49.846461+00:00, externally triggered: True>
[2022-03-23 08:10:54,498] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:10:54,522] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 08:10:49.846461+00:00 [scheduled]> in ORM
[2022-03-23 08:10:54,700] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.335 seconds
[2022-03-23 08:11:15,793] {scheduler_job.py:153} INFO - Started process (PID=5354) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:15,799] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:15,801] {logging_mixin.py:112} INFO - [2022-03-23 08:11:15,801] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:15,840] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:15,844] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:15,847] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:15,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:16,078] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:16,159] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:10:49.846461+00:00: manual__2022-03-23T08:10:49.846461+00:00, externally triggered: True>
[2022-03-23 08:11:16,454] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:16,473] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.680 seconds
[2022-03-23 08:11:19,796] {scheduler_job.py:153} INFO - Started process (PID=5359) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:19,802] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:19,804] {logging_mixin.py:112} INFO - [2022-03-23 08:11:19,804] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:19,835] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:19,840] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:19,843] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:19,855] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:20,133] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:20,213] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:10:49.846461+00:00: manual__2022-03-23T08:10:49.846461+00:00, externally triggered: True>
[2022-03-23 08:11:20,251] {logging_mixin.py:112} INFO - [2022-03-23 08:11:20,250] {dagrun.py:309} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 08:10:49.846461+00:00: manual__2022-03-23T08:10:49.846461+00:00, externally triggered: True> failed
[2022-03-23 08:11:20,331] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:20,353] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.558 seconds
[2022-03-23 08:11:23,768] {scheduler_job.py:153} INFO - Started process (PID=5364) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:23,774] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:23,777] {logging_mixin.py:112} INFO - [2022-03-23 08:11:23,777] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:23,816] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:23,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:23,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:23,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:24,161] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:24,244] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:24,269] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.500 seconds
[2022-03-23 08:11:27,869] {scheduler_job.py:153} INFO - Started process (PID=5372) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:27,882] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:27,885] {logging_mixin.py:112} INFO - [2022-03-23 08:11:27,885] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:28,052] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:28,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:28,073] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:28,104] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:30,050] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:30,136] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:30,159] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.290 seconds
[2022-03-23 08:11:31,837] {scheduler_job.py:153} INFO - Started process (PID=5377) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:31,851] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:31,854] {logging_mixin.py:112} INFO - [2022-03-23 08:11:31,854] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:32,003] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:32,017] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:32,029] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:32,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:33,262] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:33,439] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:33,471] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.635 seconds
[2022-03-23 08:11:36,212] {scheduler_job.py:153} INFO - Started process (PID=5386) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:36,228] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:36,234] {logging_mixin.py:112} INFO - [2022-03-23 08:11:36,234] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:36,287] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:36,296] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:36,308] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:36,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:37,596] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:37,964] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:39,563] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.351 seconds
[2022-03-23 08:11:42,222] {scheduler_job.py:153} INFO - Started process (PID=5391) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:42,230] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:42,232] {logging_mixin.py:112} INFO - [2022-03-23 08:11:42,231] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:42,269] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:42,274] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:42,276] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:42,284] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:42,699] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:42,783] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:42,806] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.583 seconds
[2022-03-23 08:11:46,246] {scheduler_job.py:153} INFO - Started process (PID=5399) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:46,251] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:46,253] {logging_mixin.py:112} INFO - [2022-03-23 08:11:46,252] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:46,279] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:46,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:46,285] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:46,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:46,578] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:46,646] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:46,664] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.418 seconds
[2022-03-23 08:11:50,263] {scheduler_job.py:153} INFO - Started process (PID=5404) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:50,270] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:50,272] {logging_mixin.py:112} INFO - [2022-03-23 08:11:50,271] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:50,311] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:50,316] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:50,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:50,328] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:50,617] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:50,697] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:50,727] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.465 seconds
[2022-03-23 08:11:54,674] {scheduler_job.py:153} INFO - Started process (PID=5409) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:54,704] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:54,706] {logging_mixin.py:112} INFO - [2022-03-23 08:11:54,706] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:54,950] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:54,958] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:54,969] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:55,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:55,587] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:55,782] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:55,820] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.146 seconds
[2022-03-23 08:11:58,282] {scheduler_job.py:153} INFO - Started process (PID=5417) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:58,293] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:11:58,304] {logging_mixin.py:112} INFO - [2022-03-23 08:11:58,303] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:58,389] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:11:58,399] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:58,407] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:11:58,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:11:58,747] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:11:58,865] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:11:58,906] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.624 seconds
[2022-03-23 08:12:02,430] {scheduler_job.py:153} INFO - Started process (PID=5422) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:02,438] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:02,448] {logging_mixin.py:112} INFO - [2022-03-23 08:12:02,448] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:02,510] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:02,517] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:02,519] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:02,531] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:03,002] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:03,398] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:03,456] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.029 seconds
[2022-03-23 08:12:06,253] {scheduler_job.py:153} INFO - Started process (PID=5427) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:06,288] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:06,291] {logging_mixin.py:112} INFO - [2022-03-23 08:12:06,291] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:06,403] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:06,412] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:06,415] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:06,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:06,741] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:06,852] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:06,880] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.627 seconds
[2022-03-23 08:12:10,276] {scheduler_job.py:153} INFO - Started process (PID=5436) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:10,291] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:10,294] {logging_mixin.py:112} INFO - [2022-03-23 08:12:10,294] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:10,345] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:10,351] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:10,354] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:10,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:10,637] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:10,797] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:10,847] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.571 seconds
[2022-03-23 08:12:14,301] {scheduler_job.py:153} INFO - Started process (PID=5441) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:14,307] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:14,308] {logging_mixin.py:112} INFO - [2022-03-23 08:12:14,308] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:14,338] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:14,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:14,347] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:14,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:14,600] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:14,689] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:14,715] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.414 seconds
[2022-03-23 08:12:18,267] {scheduler_job.py:153} INFO - Started process (PID=5446) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:18,277] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:18,278] {logging_mixin.py:112} INFO - [2022-03-23 08:12:18,278] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:18,314] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:18,320] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:18,338] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:18,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:19,252] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:19,369] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:19,410] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.143 seconds
[2022-03-23 08:12:22,290] {scheduler_job.py:153} INFO - Started process (PID=5454) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:22,300] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:22,302] {logging_mixin.py:112} INFO - [2022-03-23 08:12:22,302] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:22,348] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:22,355] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:22,360] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:22,376] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:22,679] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:22,780] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:22,810] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.521 seconds
[2022-03-23 08:12:26,296] {scheduler_job.py:153} INFO - Started process (PID=5459) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:26,302] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:26,305] {logging_mixin.py:112} INFO - [2022-03-23 08:12:26,305] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:26,366] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:26,376] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:26,380] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:26,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:26,718] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:26,832] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:26,859] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.563 seconds
[2022-03-23 08:12:30,291] {scheduler_job.py:153} INFO - Started process (PID=5464) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:30,299] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:30,300] {logging_mixin.py:112} INFO - [2022-03-23 08:12:30,300] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:30,348] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:30,354] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:30,357] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:30,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:30,727] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:30,916] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:30,951] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.660 seconds
[2022-03-23 08:12:34,313] {scheduler_job.py:153} INFO - Started process (PID=5472) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:34,320] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:34,321] {logging_mixin.py:112} INFO - [2022-03-23 08:12:34,321] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:34,395] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:34,401] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:34,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:34,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:34,844] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:35,242] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:12:34.687858+00:00: manual__2022-03-23T08:12:34.687858+00:00, externally triggered: True>
[2022-03-23 08:12:35,446] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:35,486] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 08:12:34.687858+00:00 [scheduled]> in ORM
[2022-03-23 08:12:35,745] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.432 seconds
[2022-03-23 08:12:56,183] {scheduler_job.py:153} INFO - Started process (PID=5502) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:56,189] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:12:56,191] {logging_mixin.py:112} INFO - [2022-03-23 08:12:56,191] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:56,225] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:12:56,231] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:56,233] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:12:56,243] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:12:56,458] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:12:56,540] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:12:34.687858+00:00: manual__2022-03-23T08:12:34.687858+00:00, externally triggered: True>
[2022-03-23 08:12:56,754] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:12:56,775] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.592 seconds
[2022-03-23 08:13:00,146] {scheduler_job.py:153} INFO - Started process (PID=5507) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:00,153] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:00,163] {logging_mixin.py:112} INFO - [2022-03-23 08:13:00,163] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:00,216] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:00,221] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:00,223] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:00,231] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:00,576] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:00,660] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:12:34.687858+00:00: manual__2022-03-23T08:12:34.687858+00:00, externally triggered: True>
[2022-03-23 08:13:00,751] {logging_mixin.py:112} INFO - [2022-03-23 08:13:00,751] {dagrun.py:309} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 08:12:34.687858+00:00: manual__2022-03-23T08:12:34.687858+00:00, externally triggered: True> failed
[2022-03-23 08:13:00,889] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:00,921] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.775 seconds
[2022-03-23 08:13:04,150] {scheduler_job.py:153} INFO - Started process (PID=5515) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:04,157] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:04,158] {logging_mixin.py:112} INFO - [2022-03-23 08:13:04,158] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:04,188] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:04,195] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:04,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:04,207] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:04,446] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:04,529] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:04,552] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.402 seconds
[2022-03-23 08:13:08,173] {scheduler_job.py:153} INFO - Started process (PID=5520) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:08,178] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:08,180] {logging_mixin.py:112} INFO - [2022-03-23 08:13:08,180] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:08,217] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:08,223] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:08,225] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:08,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:08,484] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:08,567] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:08,591] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.418 seconds
[2022-03-23 08:13:12,157] {scheduler_job.py:153} INFO - Started process (PID=5525) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:12,168] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:12,170] {logging_mixin.py:112} INFO - [2022-03-23 08:13:12,170] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:12,199] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:12,205] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:12,207] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:12,215] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:12,615] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:12,725] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:12,753] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.596 seconds
[2022-03-23 08:13:16,163] {scheduler_job.py:153} INFO - Started process (PID=5534) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:16,171] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:16,174] {logging_mixin.py:112} INFO - [2022-03-23 08:13:16,173] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:16,229] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:16,236] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:16,238] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:16,254] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:16,551] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:16,687] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:16,747] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.584 seconds
[2022-03-23 08:13:20,189] {scheduler_job.py:153} INFO - Started process (PID=5539) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:20,202] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:20,204] {logging_mixin.py:112} INFO - [2022-03-23 08:13:20,204] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:20,233] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:20,237] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:20,240] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:20,247] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:20,672] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:20,885] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:20,939] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.751 seconds
[2022-03-23 08:13:24,173] {scheduler_job.py:153} INFO - Started process (PID=5544) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:24,194] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:24,197] {logging_mixin.py:112} INFO - [2022-03-23 08:13:24,196] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:24,264] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:24,271] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:24,278] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:24,288] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:25,085] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:25,216] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:25,252] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.079 seconds
[2022-03-23 08:13:28,168] {scheduler_job.py:153} INFO - Started process (PID=5552) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:28,176] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:28,181] {logging_mixin.py:112} INFO - [2022-03-23 08:13:28,181] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:28,233] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:28,239] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:28,242] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:28,252] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:28,517] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:28,625] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:28,649] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.481 seconds
[2022-03-23 08:13:32,195] {scheduler_job.py:153} INFO - Started process (PID=5557) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:32,201] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:32,203] {logging_mixin.py:112} INFO - [2022-03-23 08:13:32,203] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:32,244] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:32,250] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:32,252] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:32,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:32,480] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:32,565] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:32,595] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.400 seconds
[2022-03-23 08:13:36,946] {scheduler_job.py:153} INFO - Started process (PID=5562) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:36,973] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:36,998] {logging_mixin.py:112} INFO - [2022-03-23 08:13:36,998] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:37,171] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:37,179] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:37,181] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:37,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:37,887] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:38,182] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:38,232] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.287 seconds
[2022-03-23 08:13:40,644] {scheduler_job.py:153} INFO - Started process (PID=5570) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:40,651] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:40,652] {logging_mixin.py:112} INFO - [2022-03-23 08:13:40,652] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:40,731] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:40,738] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:40,744] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:40,754] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:41,188] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:41,388] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:41,426] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.782 seconds
[2022-03-23 08:13:45,229] {scheduler_job.py:153} INFO - Started process (PID=5575) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:45,244] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:45,255] {logging_mixin.py:112} INFO - [2022-03-23 08:13:45,247] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:45,701] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:45,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:45,718] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:45,740] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:46,494] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:46,600] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:46,630] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.401 seconds
[2022-03-23 08:13:48,672] {scheduler_job.py:153} INFO - Started process (PID=5580) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:48,681] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:48,683] {logging_mixin.py:112} INFO - [2022-03-23 08:13:48,683] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:48,727] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:48,733] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:48,735] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:48,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:49,307] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:49,453] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:49,546] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.874 seconds
[2022-03-23 08:13:52,780] {scheduler_job.py:153} INFO - Started process (PID=5589) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:52,797] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:52,801] {logging_mixin.py:112} INFO - [2022-03-23 08:13:52,800] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:52,889] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:52,897] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:52,900] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:52,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:53,495] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:53,814] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:53,847] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.068 seconds
[2022-03-23 08:13:58,265] {scheduler_job.py:153} INFO - Started process (PID=5594) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:58,271] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:13:58,274] {logging_mixin.py:112} INFO - [2022-03-23 08:13:58,273] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:58,305] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:13:58,313] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:58,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:13:58,328] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:13:58,629] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:13:58,702] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:13:58,721] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.457 seconds
[2022-03-23 08:14:02,673] {scheduler_job.py:153} INFO - Started process (PID=5602) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:02,700] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:02,710] {logging_mixin.py:112} INFO - [2022-03-23 08:14:02,710] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:02,772] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:02,779] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:02,781] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:02,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:03,386] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:03,471] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:03,494] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.821 seconds
[2022-03-23 08:14:06,273] {scheduler_job.py:153} INFO - Started process (PID=5607) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:06,278] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:06,280] {logging_mixin.py:112} INFO - [2022-03-23 08:14:06,280] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:06,309] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:06,314] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:06,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:06,324] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:06,534] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:06,615] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:06,637] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.364 seconds
[2022-03-23 08:14:10,283] {scheduler_job.py:153} INFO - Started process (PID=5613) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:10,291] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:10,293] {logging_mixin.py:112} INFO - [2022-03-23 08:14:10,292] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:10,342] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:10,351] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:10,353] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:10,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:10,633] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:10,721] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:10,745] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.462 seconds
[2022-03-23 08:14:14,288] {scheduler_job.py:153} INFO - Started process (PID=5620) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:14,302] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:14,304] {logging_mixin.py:112} INFO - [2022-03-23 08:14:14,304] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:14,364] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:14,371] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:14,382] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:14,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:14,702] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:14,811] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:14,839] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.551 seconds
[2022-03-23 08:14:18,290] {scheduler_job.py:153} INFO - Started process (PID=5625) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:18,297] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:18,298] {logging_mixin.py:112} INFO - [2022-03-23 08:14:18,298] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:18,329] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:18,333] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:18,335] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:18,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:18,577] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:18,685] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:18,712] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.421 seconds
[2022-03-23 08:14:22,292] {scheduler_job.py:153} INFO - Started process (PID=5633) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:22,304] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:22,306] {logging_mixin.py:112} INFO - [2022-03-23 08:14:22,306] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:22,336] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:22,342] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:22,344] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:22,353] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:22,663] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:22,810] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:22,843] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.551 seconds
[2022-03-23 08:14:26,325] {scheduler_job.py:153} INFO - Started process (PID=5639) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:26,340] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:26,342] {logging_mixin.py:112} INFO - [2022-03-23 08:14:26,342] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:26,388] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:26,395] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:26,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:26,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:26,752] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:26,845] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:26,868] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.544 seconds
[2022-03-23 08:14:30,292] {scheduler_job.py:153} INFO - Started process (PID=5644) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:30,300] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:30,301] {logging_mixin.py:112} INFO - [2022-03-23 08:14:30,301] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:30,332] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:30,336] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:30,338] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:30,346] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:30,579] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:30,662] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:30,692] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.400 seconds
[2022-03-23 08:14:34,528] {scheduler_job.py:153} INFO - Started process (PID=5652) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:34,554] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:34,556] {logging_mixin.py:112} INFO - [2022-03-23 08:14:34,555] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:34,620] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:34,634] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:34,638] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:34,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:35,328] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:35,660] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:35,704] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.177 seconds
[2022-03-23 08:14:38,525] {scheduler_job.py:153} INFO - Started process (PID=5657) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:38,547] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:38,596] {logging_mixin.py:112} INFO - [2022-03-23 08:14:38,596] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:38,731] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:38,737] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:38,740] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:38,769] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:44,402] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1582, in process_file
    dag.sync_to_db()
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 1495, in sync_to_db
    orm_dag = session.query(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3429, in first
    ret = list(self[0:1])
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3203, in __getitem__
    return list(res)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT dag.dag_id AS dag_dag_id, dag.root_dag_id AS dag_root_dag_id, dag.is_paused AS dag_is_paused, dag.is_subdag AS dag_is_subdag, dag.is_active AS dag_is_active, dag.last_scheduler_run AS dag_last_scheduler_run, dag.last_pickled AS dag_last_pickled, dag.last_expired AS dag_last_expired, dag.scheduler_lock AS dag_scheduler_lock, dag.pickle_id AS dag_pickle_id, dag.fileloc AS dag_fileloc, dag.owners AS dag_owners, dag.description AS dag_description, dag.default_view AS dag_default_view, dag.schedule_interval AS dag_schedule_interval 
FROM dag 
WHERE dag.dag_id = ?
 LIMIT ? OFFSET ?]
[parameters: ('bigquery_data_load', 1, 0)]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-03-23 08:14:49,119] {scheduler_job.py:153} INFO - Started process (PID=5668) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:49,135] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:49,137] {logging_mixin.py:112} INFO - [2022-03-23 08:14:49,137] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:49,184] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:49,191] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:49,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:49,222] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:49,676] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:49,785] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:49,814] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.696 seconds
[2022-03-23 08:14:53,096] {scheduler_job.py:153} INFO - Started process (PID=5676) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:53,108] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:53,113] {logging_mixin.py:112} INFO - [2022-03-23 08:14:53,112] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:53,197] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:53,203] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:53,206] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:53,229] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:53,545] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:53,662] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:53,695] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.599 seconds
[2022-03-23 08:14:57,804] {scheduler_job.py:153} INFO - Started process (PID=5682) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:57,816] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:14:57,818] {logging_mixin.py:112} INFO - [2022-03-23 08:14:57,818] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:57,871] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:14:57,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:57,888] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:14:57,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:14:58,408] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:14:58,951] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:14:58,991] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.187 seconds
[2022-03-23 08:15:01,107] {scheduler_job.py:153} INFO - Started process (PID=5687) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:01,114] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:01,120] {logging_mixin.py:112} INFO - [2022-03-23 08:15:01,120] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:01,178] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:01,184] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:01,186] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:01,203] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:02,047] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:02,148] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:02,178] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.073 seconds
[2022-03-23 08:15:05,091] {scheduler_job.py:153} INFO - Started process (PID=5695) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:05,096] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:05,098] {logging_mixin.py:112} INFO - [2022-03-23 08:15:05,098] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:05,128] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:05,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:05,135] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:05,145] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:05,434] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:05,521] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:05,545] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-03-23 08:15:09,140] {scheduler_job.py:153} INFO - Started process (PID=5700) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:09,156] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:09,206] {logging_mixin.py:112} INFO - [2022-03-23 08:15:09,206] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:09,285] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:09,291] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:09,293] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:09,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:09,657] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:09,751] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:09,776] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.637 seconds
[2022-03-23 08:15:13,132] {scheduler_job.py:153} INFO - Started process (PID=5705) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:13,140] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:13,144] {logging_mixin.py:112} INFO - [2022-03-23 08:15:13,144] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:13,232] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:13,238] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:13,242] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:13,252] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:13,575] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:13,692] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:13,723] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.593 seconds
[2022-03-23 08:15:24,738] {scheduler_job.py:153} INFO - Started process (PID=5719) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:24,748] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:24,750] {logging_mixin.py:112} INFO - [2022-03-23 08:15:24,750] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:24,811] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:24,818] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:24,825] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:24,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:25,141] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:25,238] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:25,263] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.525 seconds
[2022-03-23 08:15:25,740] {scheduler_job.py:153} INFO - Started process (PID=5721) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:25,746] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:25,748] {logging_mixin.py:112} INFO - [2022-03-23 08:15:25,748] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:25,786] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:25,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:25,793] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:25,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:26,166] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:26,254] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:26,276] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.536 seconds
[2022-03-23 08:15:27,610] {scheduler_job.py:153} INFO - Started process (PID=5726) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:27,618] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:27,620] {logging_mixin.py:112} INFO - [2022-03-23 08:15:27,620] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:27,657] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:27,661] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:27,664] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:27,672] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:27,964] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:28,048] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:28,070] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.460 seconds
[2022-03-23 08:15:31,620] {scheduler_job.py:153} INFO - Started process (PID=5732) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:31,629] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:31,631] {logging_mixin.py:112} INFO - [2022-03-23 08:15:31,631] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:31,692] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:31,709] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:31,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:31,723] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:32,228] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:32,351] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:32,405] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.784 seconds
[2022-03-23 08:15:35,831] {scheduler_job.py:153} INFO - Started process (PID=5740) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:35,846] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:35,848] {logging_mixin.py:112} INFO - [2022-03-23 08:15:35,848] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:35,899] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:35,904] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:35,907] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:35,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:36,609] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:36,864] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:36,914] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.083 seconds
[2022-03-23 08:15:39,605] {scheduler_job.py:153} INFO - Started process (PID=5745) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:39,616] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:39,617] {logging_mixin.py:112} INFO - [2022-03-23 08:15:39,617] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:39,668] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:39,674] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:39,678] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:39,692] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:40,075] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:40,196] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:40,238] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.633 seconds
[2022-03-23 08:15:43,881] {scheduler_job.py:153} INFO - Started process (PID=5750) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:43,896] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:43,897] {logging_mixin.py:112} INFO - [2022-03-23 08:15:43,897] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:43,932] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:43,936] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:43,938] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:43,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:44,308] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:44,554] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:44,679] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.798 seconds
[2022-03-23 08:15:47,902] {scheduler_job.py:153} INFO - Started process (PID=5758) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:47,909] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:47,911] {logging_mixin.py:112} INFO - [2022-03-23 08:15:47,911] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:47,939] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:47,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:47,946] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:47,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:49,528] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:49,628] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:49,655] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.753 seconds
[2022-03-23 08:15:51,995] {scheduler_job.py:153} INFO - Started process (PID=5763) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:52,002] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:52,004] {logging_mixin.py:112} INFO - [2022-03-23 08:15:52,003] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:52,036] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:52,043] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:52,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:52,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:52,332] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:52,422] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:52,445] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.450 seconds
[2022-03-23 08:15:56,032] {scheduler_job.py:153} INFO - Started process (PID=5768) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:56,038] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:15:56,040] {logging_mixin.py:112} INFO - [2022-03-23 08:15:56,040] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:56,082] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:15:56,089] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:56,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:15:56,111] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:15:56,479] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:15:56,834] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:15:56,869] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.838 seconds
[2022-03-23 08:16:00,025] {scheduler_job.py:153} INFO - Started process (PID=5776) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:00,034] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:00,040] {logging_mixin.py:112} INFO - [2022-03-23 08:16:00,036] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:00,133] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:00,138] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:00,142] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:00,167] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:00,561] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:00,696] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:00,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.705 seconds
[2022-03-23 08:16:04,046] {scheduler_job.py:153} INFO - Started process (PID=5782) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:04,054] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:04,056] {logging_mixin.py:112} INFO - [2022-03-23 08:16:04,055] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:04,103] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:04,111] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:04,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:04,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:04,576] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:04,730] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:04,761] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.715 seconds
[2022-03-23 08:16:08,483] {scheduler_job.py:153} INFO - Started process (PID=5787) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:08,508] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:08,515] {logging_mixin.py:112} INFO - [2022-03-23 08:16:08,514] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:09,580] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:09,588] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:09,596] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:09,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:10,671] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:10,816] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:10,847] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.364 seconds
[2022-03-23 08:16:12,051] {scheduler_job.py:153} INFO - Started process (PID=5792) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:12,062] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:12,064] {logging_mixin.py:112} INFO - [2022-03-23 08:16:12,063] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:12,112] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:12,123] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:12,126] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:12,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:12,525] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:12,614] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:12,635] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.585 seconds
[2022-03-23 08:16:16,047] {scheduler_job.py:153} INFO - Started process (PID=5800) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:16,061] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:16,072] {logging_mixin.py:112} INFO - [2022-03-23 08:16:16,071] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:16,284] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:16,300] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:16,303] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:16,326] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:16,622] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:16,713] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:16,737] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.690 seconds
[2022-03-23 08:16:20,043] {scheduler_job.py:153} INFO - Started process (PID=5805) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:20,049] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:20,050] {logging_mixin.py:112} INFO - [2022-03-23 08:16:20,050] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:20,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:20,090] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:20,093] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:20,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:20,351] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:20,452] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:20,477] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-03-23 08:16:24,048] {scheduler_job.py:153} INFO - Started process (PID=5810) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:24,057] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:24,058] {logging_mixin.py:112} INFO - [2022-03-23 08:16:24,058] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:24,085] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:24,090] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:24,093] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:24,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:24,413] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:24,540] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:24,567] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.520 seconds
[2022-03-23 08:16:28,140] {scheduler_job.py:153} INFO - Started process (PID=5818) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:28,156] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:28,168] {logging_mixin.py:112} INFO - [2022-03-23 08:16:28,168] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:28,296] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:28,301] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:28,303] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:28,314] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:28,537] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:28,622] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:28,645] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.504 seconds
[2022-03-23 08:16:32,085] {scheduler_job.py:153} INFO - Started process (PID=5823) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:32,093] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:32,095] {logging_mixin.py:112} INFO - [2022-03-23 08:16:32,095] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:32,157] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:32,163] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:32,166] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:32,180] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:32,485] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:32,589] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:32,611] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.526 seconds
[2022-03-23 08:16:36,171] {scheduler_job.py:153} INFO - Started process (PID=5828) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:36,187] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:36,192] {logging_mixin.py:112} INFO - [2022-03-23 08:16:36,192] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:36,630] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:36,646] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:36,661] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:36,687] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:38,178] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:38,293] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:38,324] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.153 seconds
[2022-03-23 08:16:40,818] {scheduler_job.py:153} INFO - Started process (PID=5837) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:40,825] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:40,834] {logging_mixin.py:112} INFO - [2022-03-23 08:16:40,834] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:40,897] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:40,904] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:40,907] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:40,921] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:41,314] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:41,463] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:41,511] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.694 seconds
[2022-03-23 08:16:48,507] {scheduler_job.py:153} INFO - Started process (PID=5845) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:48,513] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:48,514] {logging_mixin.py:112} INFO - [2022-03-23 08:16:48,514] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:48,553] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:48,559] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:48,561] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:48,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:48,817] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:48,914] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:48,937] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.430 seconds
[2022-03-23 08:16:52,529] {scheduler_job.py:153} INFO - Started process (PID=5853) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:52,537] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:52,538] {logging_mixin.py:112} INFO - [2022-03-23 08:16:52,538] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:52,569] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:52,574] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:52,576] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:52,586] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:52,872] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:52,974] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:52,996] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.467 seconds
[2022-03-23 08:16:56,610] {scheduler_job.py:153} INFO - Started process (PID=5858) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:56,617] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:16:56,619] {logging_mixin.py:112} INFO - [2022-03-23 08:16:56,619] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:56,680] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:16:56,685] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:56,688] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:16:56,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:16:57,029] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:16:57,115] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:16:57,138] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.528 seconds
[2022-03-23 08:17:00,526] {scheduler_job.py:153} INFO - Started process (PID=5863) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:00,532] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:00,533] {logging_mixin.py:112} INFO - [2022-03-23 08:17:00,533] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:00,571] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:00,576] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:00,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:00,587] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:00,866] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:00,948] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:00,971] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.445 seconds
[2022-03-23 08:17:04,543] {scheduler_job.py:153} INFO - Started process (PID=5871) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:04,562] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:04,564] {logging_mixin.py:112} INFO - [2022-03-23 08:17:04,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:04,612] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:04,618] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:04,624] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:04,638] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:04,963] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:05,081] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:05,123] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.580 seconds
[2022-03-23 08:17:08,543] {scheduler_job.py:153} INFO - Started process (PID=5876) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:08,549] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:08,550] {logging_mixin.py:112} INFO - [2022-03-23 08:17:08,550] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:08,579] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:08,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:08,585] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:08,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:08,827] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:08,911] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:08,994] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.452 seconds
[2022-03-23 08:17:12,554] {scheduler_job.py:153} INFO - Started process (PID=5882) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:12,568] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:12,570] {logging_mixin.py:112} INFO - [2022-03-23 08:17:12,569] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:12,611] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:12,617] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:12,619] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:12,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:12,872] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:12,958] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:12,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.425 seconds
[2022-03-23 08:17:16,571] {scheduler_job.py:153} INFO - Started process (PID=5890) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:16,586] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:16,589] {logging_mixin.py:112} INFO - [2022-03-23 08:17:16,588] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:16,631] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:16,636] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:16,639] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:16,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:16,987] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:17,122] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:17,156] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.586 seconds
[2022-03-23 08:17:20,570] {scheduler_job.py:153} INFO - Started process (PID=5895) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:20,578] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:20,580] {logging_mixin.py:112} INFO - [2022-03-23 08:17:20,580] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:20,621] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:20,628] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:20,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:20,643] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:21,010] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:21,131] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:21,159] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.589 seconds
[2022-03-23 08:17:24,598] {scheduler_job.py:153} INFO - Started process (PID=5900) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:24,609] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:24,611] {logging_mixin.py:112} INFO - [2022-03-23 08:17:24,611] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:24,648] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:24,652] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:24,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:24,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:24,903] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:25,034] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:25,132] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.535 seconds
[2022-03-23 08:17:28,606] {scheduler_job.py:153} INFO - Started process (PID=5905) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:28,618] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:28,620] {logging_mixin.py:112} INFO - [2022-03-23 08:17:28,620] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:28,684] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:28,696] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:28,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:28,712] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:29,665] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:30,046] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:30,202] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.596 seconds
[2022-03-23 08:17:32,665] {scheduler_job.py:153} INFO - Started process (PID=5913) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:32,679] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:32,681] {logging_mixin.py:112} INFO - [2022-03-23 08:17:32,681] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:32,788] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:32,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:32,804] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:32,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:33,206] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:33,397] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:33,443] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.778 seconds
[2022-03-23 08:17:36,582] {scheduler_job.py:153} INFO - Started process (PID=5918) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:36,592] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:36,597] {logging_mixin.py:112} INFO - [2022-03-23 08:17:36,596] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:36,646] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:36,652] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:36,655] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:36,680] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:37,139] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:37,451] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:37,635] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.053 seconds
[2022-03-23 08:17:40,600] {scheduler_job.py:153} INFO - Started process (PID=5923) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:40,609] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:17:40,611] {logging_mixin.py:112} INFO - [2022-03-23 08:17:40,611] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:40,681] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:17:40,687] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:40,693] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:17:40,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:17:41,322] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:17:41,567] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:17:40.616387+00:00: manual__2022-03-23T08:17:40.616387+00:00, externally triggered: True>
[2022-03-23 08:17:41,703] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:17:41,901] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 08:17:40.616387+00:00 [scheduled]> in ORM
[2022-03-23 08:17:42,279] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.679 seconds
[2022-03-23 08:18:01,744] {scheduler_job.py:153} INFO - Started process (PID=5953) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:01,749] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:01,751] {logging_mixin.py:112} INFO - [2022-03-23 08:18:01,751] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:01,778] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:01,782] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:01,784] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:01,792] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:01,994] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:02,077] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:17:40.616387+00:00: manual__2022-03-23T08:17:40.616387+00:00, externally triggered: True>
[2022-03-23 08:18:02,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:02,320] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.576 seconds
[2022-03-23 08:18:05,747] {scheduler_job.py:153} INFO - Started process (PID=5961) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:05,755] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:05,758] {logging_mixin.py:112} INFO - [2022-03-23 08:18:05,758] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:05,794] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:05,798] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:05,800] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:05,810] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:06,096] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:06,176] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:17:40.616387+00:00: manual__2022-03-23T08:17:40.616387+00:00, externally triggered: True>
[2022-03-23 08:18:06,224] {logging_mixin.py:112} INFO - [2022-03-23 08:18:06,223] {dagrun.py:309} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 08:17:40.616387+00:00: manual__2022-03-23T08:17:40.616387+00:00, externally triggered: True> failed
[2022-03-23 08:18:06,318] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:06,337] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.591 seconds
[2022-03-23 08:18:09,718] {scheduler_job.py:153} INFO - Started process (PID=5966) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:09,728] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:09,730] {logging_mixin.py:112} INFO - [2022-03-23 08:18:09,730] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:09,779] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:09,785] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:09,787] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:09,804] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:10,093] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:10,182] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:10,203] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.485 seconds
[2022-03-23 08:18:13,760] {scheduler_job.py:153} INFO - Started process (PID=5971) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:13,768] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:13,772] {logging_mixin.py:112} INFO - [2022-03-23 08:18:13,772] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:13,810] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:13,816] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:13,818] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:13,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:14,062] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:14,147] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:14,169] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.409 seconds
[2022-03-23 08:18:17,745] {scheduler_job.py:153} INFO - Started process (PID=5976) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:17,751] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:17,753] {logging_mixin.py:112} INFO - [2022-03-23 08:18:17,752] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:17,822] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:17,829] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:17,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:17,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:18,111] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:18,198] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:18,223] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.479 seconds
[2022-03-23 08:18:21,750] {scheduler_job.py:153} INFO - Started process (PID=5985) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:21,758] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:21,760] {logging_mixin.py:112} INFO - [2022-03-23 08:18:21,760] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:21,827] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:21,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:21,835] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:21,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:22,312] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:22,487] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:22,534] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.784 seconds
[2022-03-23 08:18:25,768] {scheduler_job.py:153} INFO - Started process (PID=5990) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:25,776] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:25,778] {logging_mixin.py:112} INFO - [2022-03-23 08:18:25,777] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:25,816] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:25,821] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:25,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:25,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:26,068] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:26,155] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:26,176] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.407 seconds
[2022-03-23 08:18:29,768] {scheduler_job.py:153} INFO - Started process (PID=5995) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:29,774] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:29,776] {logging_mixin.py:112} INFO - [2022-03-23 08:18:29,776] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:29,822] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:29,828] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:29,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:29,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:30,109] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:30,194] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:30,218] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.450 seconds
[2022-03-23 08:18:33,753] {scheduler_job.py:153} INFO - Started process (PID=6003) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:33,759] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:33,760] {logging_mixin.py:112} INFO - [2022-03-23 08:18:33,760] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:33,801] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:33,806] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:33,809] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:33,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:34,062] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:34,147] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:34,169] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.416 seconds
[2022-03-23 08:18:37,931] {scheduler_job.py:153} INFO - Started process (PID=6008) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:37,941] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:37,944] {logging_mixin.py:112} INFO - [2022-03-23 08:18:37,944] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:37,981] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:37,986] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:37,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:38,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:38,416] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:38,566] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:38,605] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.674 seconds
[2022-03-23 08:18:41,777] {scheduler_job.py:153} INFO - Started process (PID=6013) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:41,789] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:41,793] {logging_mixin.py:112} INFO - [2022-03-23 08:18:41,792] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:41,833] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:41,841] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:41,845] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:41,863] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:42,177] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:42,326] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:42,349] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.572 seconds
[2022-03-23 08:18:45,810] {scheduler_job.py:153} INFO - Started process (PID=6021) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:45,821] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:45,822] {logging_mixin.py:112} INFO - [2022-03-23 08:18:45,822] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:45,911] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:45,921] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:45,924] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:45,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:46,244] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:46,331] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:46,353] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.543 seconds
[2022-03-23 08:18:49,802] {scheduler_job.py:153} INFO - Started process (PID=6026) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:49,812] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:49,814] {logging_mixin.py:112} INFO - [2022-03-23 08:18:49,814] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:49,863] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:49,869] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:49,871] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:49,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:50,145] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:50,233] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:50,260] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.458 seconds
[2022-03-23 08:18:53,816] {scheduler_job.py:153} INFO - Started process (PID=6032) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:53,825] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:53,827] {logging_mixin.py:112} INFO - [2022-03-23 08:18:53,826] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:54,035] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:54,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:54,054] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:54,076] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:54,492] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:54,776] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:54,833] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.017 seconds
[2022-03-23 08:18:57,780] {scheduler_job.py:153} INFO - Started process (PID=6040) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:57,790] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:18:57,792] {logging_mixin.py:112} INFO - [2022-03-23 08:18:57,791] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:57,835] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:18:57,841] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:57,844] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:18:57,853] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:18:58,118] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:18:58,311] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:18:58,344] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.565 seconds
[2022-03-23 08:19:02,266] {scheduler_job.py:153} INFO - Started process (PID=6045) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:02,270] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:02,272] {logging_mixin.py:112} INFO - [2022-03-23 08:19:02,272] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:02,309] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:02,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:02,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:02,327] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:02,604] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:02,727] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:02,763] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.498 seconds
[2022-03-23 08:19:06,300] {scheduler_job.py:153} INFO - Started process (PID=6050) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:06,309] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:06,311] {logging_mixin.py:112} INFO - [2022-03-23 08:19:06,310] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:06,368] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:06,375] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:06,378] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:06,393] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:06,602] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:06,683] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:06,705] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.404 seconds
[2022-03-23 08:19:10,284] {scheduler_job.py:153} INFO - Started process (PID=6058) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:10,297] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:10,298] {logging_mixin.py:112} INFO - [2022-03-23 08:19:10,298] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:10,339] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:10,347] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:10,350] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:10,366] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:10,814] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:10,977] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:11,012] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.729 seconds
[2022-03-23 08:19:15,350] {scheduler_job.py:153} INFO - Started process (PID=6063) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:15,359] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:15,361] {logging_mixin.py:112} INFO - [2022-03-23 08:19:15,361] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:15,400] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:15,407] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:15,412] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:15,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:15,689] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:15,765] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:15,786] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.436 seconds
[2022-03-23 08:19:19,309] {scheduler_job.py:153} INFO - Started process (PID=6068) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:19,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:19,319] {logging_mixin.py:112} INFO - [2022-03-23 08:19:19,319] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:19,347] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:19,353] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:19,355] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:19,364] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:19,822] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:19,910] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:19,933] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.624 seconds
[2022-03-23 08:19:23,304] {scheduler_job.py:153} INFO - Started process (PID=6076) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:23,312] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:23,314] {logging_mixin.py:112} INFO - [2022-03-23 08:19:23,313] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:23,354] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:23,361] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:23,365] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:23,380] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:23,806] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:23,889] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:23,910] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.606 seconds
[2022-03-23 08:19:27,394] {scheduler_job.py:153} INFO - Started process (PID=6082) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:27,401] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:27,403] {logging_mixin.py:112} INFO - [2022-03-23 08:19:27,403] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:27,453] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:27,460] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:27,462] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:27,473] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:27,829] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:28,236] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:28,288] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.894 seconds
[2022-03-23 08:19:31,327] {scheduler_job.py:153} INFO - Started process (PID=6087) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:31,344] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:31,354] {logging_mixin.py:112} INFO - [2022-03-23 08:19:31,354] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:31,531] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:31,552] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:31,555] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:31,579] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:32,793] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:32,902] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:32,935] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.608 seconds
[2022-03-23 08:19:35,355] {scheduler_job.py:153} INFO - Started process (PID=6093) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:35,366] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:35,368] {logging_mixin.py:112} INFO - [2022-03-23 08:19:35,367] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:35,438] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:35,448] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:35,450] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:35,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:35,822] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:35,944] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:35,972] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.618 seconds
[2022-03-23 08:19:39,372] {scheduler_job.py:153} INFO - Started process (PID=6100) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:39,384] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:39,386] {logging_mixin.py:112} INFO - [2022-03-23 08:19:39,386] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:39,433] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:39,439] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:39,444] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:39,455] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:39,783] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:39,882] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:39,906] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.534 seconds
[2022-03-23 08:19:43,364] {scheduler_job.py:153} INFO - Started process (PID=6105) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:43,371] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:43,373] {logging_mixin.py:112} INFO - [2022-03-23 08:19:43,373] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:43,425] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:43,431] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:43,433] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:43,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:44,419] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:44,527] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:44,563] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.200 seconds
[2022-03-23 08:19:47,321] {scheduler_job.py:153} INFO - Started process (PID=6110) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:47,329] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:47,330] {logging_mixin.py:112} INFO - [2022-03-23 08:19:47,330] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:47,361] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:47,367] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:47,368] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:47,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:47,865] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:48,029] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:48,066] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.745 seconds
[2022-03-23 08:19:51,833] {scheduler_job.py:153} INFO - Started process (PID=6118) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:51,850] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:51,863] {logging_mixin.py:112} INFO - [2022-03-23 08:19:51,863] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:51,915] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:51,921] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:51,923] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:51,951] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:52,826] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:52,956] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:52,988] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.156 seconds
[2022-03-23 08:19:55,350] {scheduler_job.py:153} INFO - Started process (PID=6123) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:55,359] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:55,366] {logging_mixin.py:112} INFO - [2022-03-23 08:19:55,366] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:55,417] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:55,424] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:55,428] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:55,440] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:56,165] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:19:56,300] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:19:56,601] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.251 seconds
[2022-03-23 08:19:59,360] {scheduler_job.py:153} INFO - Started process (PID=6129) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:59,382] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:19:59,385] {logging_mixin.py:112} INFO - [2022-03-23 08:19:59,385] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:19:59,441] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:19:59,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:59,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:19:59,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:00,237] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:00,493] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:00,747] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.387 seconds
[2022-03-23 08:20:04,494] {scheduler_job.py:153} INFO - Started process (PID=6137) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:04,501] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:04,502] {logging_mixin.py:112} INFO - [2022-03-23 08:20:04,502] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:04,537] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:04,543] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:04,546] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:04,558] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:04,904] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:05,015] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:05,040] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.547 seconds
[2022-03-23 08:20:08,485] {scheduler_job.py:153} INFO - Started process (PID=6142) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:08,492] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:08,497] {logging_mixin.py:112} INFO - [2022-03-23 08:20:08,497] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:08,566] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:08,571] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:08,577] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:08,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:09,160] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:09,262] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:09,288] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.803 seconds
[2022-03-23 08:20:12,538] {scheduler_job.py:153} INFO - Started process (PID=6147) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:12,555] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:12,557] {logging_mixin.py:112} INFO - [2022-03-23 08:20:12,557] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:12,680] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:12,687] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:12,690] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:12,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:13,553] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:13,669] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:20:12.576188+00:00: manual__2022-03-23T08:20:12.576188+00:00, externally triggered: True>
[2022-03-23 08:20:13,799] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:13,836] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 08:20:12.576188+00:00 [scheduled]> in ORM
[2022-03-23 08:20:14,264] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.726 seconds
[2022-03-23 08:20:33,499] {scheduler_job.py:153} INFO - Started process (PID=6177) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:33,505] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:33,508] {logging_mixin.py:112} INFO - [2022-03-23 08:20:33,508] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:33,556] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:33,562] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:33,564] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:33,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:33,880] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:34,013] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:20:12.576188+00:00: manual__2022-03-23T08:20:12.576188+00:00, externally triggered: True>
[2022-03-23 08:20:34,339] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:34,368] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.869 seconds
[2022-03-23 08:20:37,468] {scheduler_job.py:153} INFO - Started process (PID=6182) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:37,478] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:37,480] {logging_mixin.py:112} INFO - [2022-03-23 08:20:37,480] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:37,681] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:37,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:37,701] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:37,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:38,044] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:38,188] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:20:12.576188+00:00: manual__2022-03-23T08:20:12.576188+00:00, externally triggered: True>
[2022-03-23 08:20:38,249] {logging_mixin.py:112} INFO - [2022-03-23 08:20:38,248] {dagrun.py:309} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 08:20:12.576188+00:00: manual__2022-03-23T08:20:12.576188+00:00, externally triggered: True> failed
[2022-03-23 08:20:38,341] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:38,362] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.895 seconds
[2022-03-23 08:20:41,467] {scheduler_job.py:153} INFO - Started process (PID=6190) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:41,476] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:41,487] {logging_mixin.py:112} INFO - [2022-03-23 08:20:41,486] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:41,528] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:41,533] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:41,535] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:41,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:41,813] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:41,911] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:41,940] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.473 seconds
[2022-03-23 08:20:45,491] {scheduler_job.py:153} INFO - Started process (PID=6195) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:45,497] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:45,498] {logging_mixin.py:112} INFO - [2022-03-23 08:20:45,498] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:45,532] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:45,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:45,539] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:45,547] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:45,754] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:45,846] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:45,871] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.380 seconds
[2022-03-23 08:20:49,501] {scheduler_job.py:153} INFO - Started process (PID=6200) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:49,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:49,520] {logging_mixin.py:112} INFO - [2022-03-23 08:20:49,520] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:49,604] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:49,611] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:49,617] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:49,633] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:49,975] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:50,069] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:50,094] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.593 seconds
[2022-03-23 08:20:53,482] {scheduler_job.py:153} INFO - Started process (PID=6208) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:53,493] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:53,494] {logging_mixin.py:112} INFO - [2022-03-23 08:20:53,494] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:53,531] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:53,536] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:53,538] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:53,550] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:53,829] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:53,918] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:53,950] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.468 seconds
[2022-03-23 08:20:57,552] {scheduler_job.py:153} INFO - Started process (PID=6213) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:57,561] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:20:57,566] {logging_mixin.py:112} INFO - [2022-03-23 08:20:57,566] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:57,648] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:20:57,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:57,656] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:20:57,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:20:57,998] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:20:58,104] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:20:58,136] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.584 seconds
[2022-03-23 08:21:01,503] {scheduler_job.py:153} INFO - Started process (PID=6218) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:01,511] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:01,512] {logging_mixin.py:112} INFO - [2022-03-23 08:21:01,512] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:01,542] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:01,546] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:01,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:01,558] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:01,817] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:01,911] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:01,933] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.431 seconds
[2022-03-23 08:21:05,498] {scheduler_job.py:153} INFO - Started process (PID=6223) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:05,510] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:05,512] {logging_mixin.py:112} INFO - [2022-03-23 08:21:05,512] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:05,561] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:05,567] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:05,570] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:05,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:05,958] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:06,130] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:06,184] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.685 seconds
[2022-03-23 08:21:09,595] {scheduler_job.py:153} INFO - Started process (PID=6232) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:09,602] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:09,604] {logging_mixin.py:112} INFO - [2022-03-23 08:21:09,604] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:09,656] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:09,670] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:09,673] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:09,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:10,485] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:10,599] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:10,633] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.039 seconds
[2022-03-23 08:21:13,588] {scheduler_job.py:153} INFO - Started process (PID=6237) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:13,606] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:13,617] {logging_mixin.py:112} INFO - [2022-03-23 08:21:13,617] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:13,712] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:13,719] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:13,722] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:13,752] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:16,801] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:17,028] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:17,088] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.500 seconds
[2022-03-23 08:21:19,708] {scheduler_job.py:153} INFO - Started process (PID=6245) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:19,715] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:19,717] {logging_mixin.py:112} INFO - [2022-03-23 08:21:19,716] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:19,752] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:19,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:19,760] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:19,768] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:20,035] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:20,120] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:20,142] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-03-23 08:21:23,696] {scheduler_job.py:153} INFO - Started process (PID=6250) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:23,704] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:23,706] {logging_mixin.py:112} INFO - [2022-03-23 08:21:23,705] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:23,749] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:23,756] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:23,761] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:23,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:24,070] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:24,167] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:24,190] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.495 seconds
[2022-03-23 08:21:27,692] {scheduler_job.py:153} INFO - Started process (PID=6255) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:27,700] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:27,702] {logging_mixin.py:112} INFO - [2022-03-23 08:21:27,701] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:27,738] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:27,744] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:27,746] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:27,755] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:28,042] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:28,165] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:28,188] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.497 seconds
[2022-03-23 08:21:31,729] {scheduler_job.py:153} INFO - Started process (PID=6263) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:31,735] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:31,736] {logging_mixin.py:112} INFO - [2022-03-23 08:21:31,736] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:31,773] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:31,780] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:31,782] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:31,792] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:32,232] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:32,435] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:32,507] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.779 seconds
[2022-03-23 08:21:35,711] {scheduler_job.py:153} INFO - Started process (PID=6268) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:35,716] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:35,717] {logging_mixin.py:112} INFO - [2022-03-23 08:21:35,717] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:35,747] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:35,751] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:35,753] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:35,761] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:36,018] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:36,103] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:36,130] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-03-23 08:21:39,805] {scheduler_job.py:153} INFO - Started process (PID=6274) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:39,818] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:39,821] {logging_mixin.py:112} INFO - [2022-03-23 08:21:39,821] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:39,905] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:39,919] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:39,934] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:39,958] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:40,522] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:40,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:40,733] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.929 seconds
[2022-03-23 08:21:43,911] {scheduler_job.py:153} INFO - Started process (PID=6282) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:43,921] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:43,923] {logging_mixin.py:112} INFO - [2022-03-23 08:21:43,922] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:44,016] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:44,024] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:44,027] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:44,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:45,030] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:45,383] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:45,437] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.526 seconds
[2022-03-23 08:21:48,253] {scheduler_job.py:153} INFO - Started process (PID=6287) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:48,280] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:48,284] {logging_mixin.py:112} INFO - [2022-03-23 08:21:48,283] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:48,402] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:48,409] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:48,412] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:48,432] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:49,130] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:49,453] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:49,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.245 seconds
[2022-03-23 08:21:52,121] {scheduler_job.py:153} INFO - Started process (PID=6292) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:52,138] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:52,151] {logging_mixin.py:112} INFO - [2022-03-23 08:21:52,150] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:53,822] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:53,828] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:53,840] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:53,870] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:54,541] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:54,680] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:54,705] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.585 seconds
[2022-03-23 08:21:57,329] {scheduler_job.py:153} INFO - Started process (PID=6300) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:57,335] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:21:57,341] {logging_mixin.py:112} INFO - [2022-03-23 08:21:57,341] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:57,375] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:21:57,381] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:57,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:21:57,392] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:21:57,611] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:21:57,699] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:21:57,731] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.402 seconds
[2022-03-23 08:22:01,241] {scheduler_job.py:153} INFO - Started process (PID=6305) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:01,247] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:01,248] {logging_mixin.py:112} INFO - [2022-03-23 08:22:01,248] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:01,278] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:01,282] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:01,286] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:01,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:01,811] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:01,904] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:01,930] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.689 seconds
[2022-03-23 08:22:05,254] {scheduler_job.py:153} INFO - Started process (PID=6310) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:05,265] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:05,267] {logging_mixin.py:112} INFO - [2022-03-23 08:22:05,267] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:05,298] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:05,303] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:05,305] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:05,316] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:05,666] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:05,751] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:05,772] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.519 seconds
[2022-03-23 08:22:09,250] {scheduler_job.py:153} INFO - Started process (PID=6318) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:09,257] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:09,259] {logging_mixin.py:112} INFO - [2022-03-23 08:22:09,259] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:09,302] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:09,308] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:09,312] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:09,323] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:09,780] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:09,892] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:09,913] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.663 seconds
[2022-03-23 08:22:13,401] {scheduler_job.py:153} INFO - Started process (PID=6324) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:13,415] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:13,419] {logging_mixin.py:112} INFO - [2022-03-23 08:22:13,418] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:13,503] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:13,509] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:13,522] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:13,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:13,899] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:14,113] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:14,143] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.743 seconds
[2022-03-23 08:22:17,282] {scheduler_job.py:153} INFO - Started process (PID=6329) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:17,289] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:17,294] {logging_mixin.py:112} INFO - [2022-03-23 08:22:17,294] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:17,396] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:17,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:17,406] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:17,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:17,761] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:17,844] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:17,865] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.584 seconds
[2022-03-23 08:22:21,287] {scheduler_job.py:153} INFO - Started process (PID=6337) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:21,296] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:21,298] {logging_mixin.py:112} INFO - [2022-03-23 08:22:21,297] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:21,347] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:21,353] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:21,356] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:21,370] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:21,620] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:21,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:21,739] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-03-23 08:22:25,315] {scheduler_job.py:153} INFO - Started process (PID=6342) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:25,321] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:25,326] {logging_mixin.py:112} INFO - [2022-03-23 08:22:25,326] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:25,398] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:25,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:25,415] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:25,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:25,822] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:25,919] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:25,942] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.627 seconds
[2022-03-23 08:22:29,810] {scheduler_job.py:153} INFO - Started process (PID=6347) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:29,826] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:29,831] {logging_mixin.py:112} INFO - [2022-03-23 08:22:29,831] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:29,964] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:29,970] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:29,973] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:29,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:30,402] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:30,516] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:30,547] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.737 seconds
[2022-03-23 08:22:33,266] {scheduler_job.py:153} INFO - Started process (PID=6352) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:33,273] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:33,276] {logging_mixin.py:112} INFO - [2022-03-23 08:22:33,275] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:33,337] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:33,343] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:33,346] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:33,357] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:33,809] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:33,951] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:34,020] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.756 seconds
[2022-03-23 08:22:37,428] {scheduler_job.py:153} INFO - Started process (PID=6360) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:37,433] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:37,434] {logging_mixin.py:112} INFO - [2022-03-23 08:22:37,434] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:37,465] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:37,469] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:37,471] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:37,480] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:37,782] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:37,866] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:37,888] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.461 seconds
[2022-03-23 08:22:41,482] {scheduler_job.py:153} INFO - Started process (PID=6365) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:41,488] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:41,490] {logging_mixin.py:112} INFO - [2022-03-23 08:22:41,489] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:41,522] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:41,527] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:41,529] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:41,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:41,910] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:41,995] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:42,017] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.535 seconds
[2022-03-23 08:22:45,432] {scheduler_job.py:153} INFO - Started process (PID=6370) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:45,437] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:45,438] {logging_mixin.py:112} INFO - [2022-03-23 08:22:45,438] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:45,470] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:45,475] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:45,477] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:45,488] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:45,746] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:45,833] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:45,856] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.424 seconds
[2022-03-23 08:22:49,449] {scheduler_job.py:153} INFO - Started process (PID=6379) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:49,454] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:49,455] {logging_mixin.py:112} INFO - [2022-03-23 08:22:49,455] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:49,521] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:49,525] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:49,527] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:49,535] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:49,764] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:49,844] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:49,864] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.416 seconds
[2022-03-23 08:22:53,541] {scheduler_job.py:153} INFO - Started process (PID=6384) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:53,551] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:53,553] {logging_mixin.py:112} INFO - [2022-03-23 08:22:53,552] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:53,631] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:53,638] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:53,641] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:53,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:54,294] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:54,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:54,751] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.210 seconds
[2022-03-23 08:22:57,447] {scheduler_job.py:153} INFO - Started process (PID=6389) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:57,454] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:22:57,455] {logging_mixin.py:112} INFO - [2022-03-23 08:22:57,455] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:57,490] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:22:57,495] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:57,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:22:57,508] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:22:57,750] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:22:57,842] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:22:57,868] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.421 seconds
[2022-03-23 08:23:01,463] {scheduler_job.py:153} INFO - Started process (PID=6394) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:01,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:01,585] {logging_mixin.py:112} INFO - [2022-03-23 08:23:01,585] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:02,001] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:02,007] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:02,018] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:02,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:02,346] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.884 seconds
[2022-03-23 08:23:05,652] {scheduler_job.py:153} INFO - Started process (PID=6402) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:05,668] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:05,670] {logging_mixin.py:112} INFO - [2022-03-23 08:23:05,670] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:05,778] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:05,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:05,802] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:05,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:06,267] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.615 seconds
[2022-03-23 08:23:09,478] {scheduler_job.py:153} INFO - Started process (PID=6407) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:09,485] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:09,488] {logging_mixin.py:112} INFO - [2022-03-23 08:23:09,487] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:09,602] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:09,609] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:09,615] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:09,635] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:10,011] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.534 seconds
[2022-03-23 08:23:13,459] {scheduler_job.py:153} INFO - Started process (PID=6412) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:13,463] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:13,465] {logging_mixin.py:112} INFO - [2022-03-23 08:23:13,465] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:13,492] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:13,496] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:13,498] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:13,506] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:13,647] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.188 seconds
[2022-03-23 08:23:17,512] {scheduler_job.py:153} INFO - Started process (PID=6417) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:17,519] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:17,521] {logging_mixin.py:112} INFO - [2022-03-23 08:23:17,520] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:17,576] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:17,580] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:17,582] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:17,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:17,905] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.394 seconds
[2022-03-23 08:23:21,493] {scheduler_job.py:153} INFO - Started process (PID=6426) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:21,499] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:21,500] {logging_mixin.py:112} INFO - [2022-03-23 08:23:21,500] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:21,538] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:21,543] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:21,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:21,559] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:21,820] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:23:25,504] {scheduler_job.py:153} INFO - Started process (PID=6431) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:25,510] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:25,511] {logging_mixin.py:112} INFO - [2022-03-23 08:23:25,511] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:25,541] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:25,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:25,547] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:25,555] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:25,718] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.214 seconds
[2022-03-23 08:23:29,552] {scheduler_job.py:153} INFO - Started process (PID=6436) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:29,561] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:29,563] {logging_mixin.py:112} INFO - [2022-03-23 08:23:29,563] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:29,607] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:29,613] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:29,616] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:29,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:29,815] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.264 seconds
[2022-03-23 08:23:33,526] {scheduler_job.py:153} INFO - Started process (PID=6444) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:33,536] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:33,538] {logging_mixin.py:112} INFO - [2022-03-23 08:23:33,538] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:33,606] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:33,614] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:33,616] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:33,631] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:33,834] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.308 seconds
[2022-03-23 08:23:37,514] {scheduler_job.py:153} INFO - Started process (PID=6449) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:37,521] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:37,524] {logging_mixin.py:112} INFO - [2022-03-23 08:23:37,522] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:37,571] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:37,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:37,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:37,593] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:37,788] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.275 seconds
[2022-03-23 08:23:41,592] {scheduler_job.py:153} INFO - Started process (PID=6454) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:41,599] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:41,601] {logging_mixin.py:112} INFO - [2022-03-23 08:23:41,601] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:41,650] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:41,655] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:41,659] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:41,671] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:42,150] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.558 seconds
[2022-03-23 08:23:45,527] {scheduler_job.py:153} INFO - Started process (PID=6462) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:45,533] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:45,535] {logging_mixin.py:112} INFO - [2022-03-23 08:23:45,534] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:45,567] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:45,571] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:45,574] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:45,582] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:45,894] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.367 seconds
[2022-03-23 08:23:49,542] {scheduler_job.py:153} INFO - Started process (PID=6467) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:49,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:49,550] {logging_mixin.py:112} INFO - [2022-03-23 08:23:49,550] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:49,596] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:49,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:49,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:49,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:49,882] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.341 seconds
[2022-03-23 08:23:53,803] {scheduler_job.py:153} INFO - Started process (PID=6473) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:53,819] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:53,822] {logging_mixin.py:112} INFO - [2022-03-23 08:23:53,821] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:53,862] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:53,868] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:53,872] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:53,888] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:54,143] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.341 seconds
[2022-03-23 08:23:57,547] {scheduler_job.py:153} INFO - Started process (PID=6478) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:57,554] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:23:57,555] {logging_mixin.py:112} INFO - [2022-03-23 08:23:57,555] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:57,586] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:23:57,591] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:57,593] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:23:57,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:23:57,752] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.205 seconds
[2022-03-23 08:24:01,552] {scheduler_job.py:153} INFO - Started process (PID=6486) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:01,565] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:01,567] {logging_mixin.py:112} INFO - [2022-03-23 08:24:01,567] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:01,629] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:01,635] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:01,638] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:01,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:01,917] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.366 seconds
[2022-03-23 08:24:05,585] {scheduler_job.py:153} INFO - Started process (PID=6491) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:05,590] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:05,592] {logging_mixin.py:112} INFO - [2022-03-23 08:24:05,592] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:05,651] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:05,655] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:05,658] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:05,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:05,853] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.268 seconds
[2022-03-23 08:24:09,561] {scheduler_job.py:153} INFO - Started process (PID=6496) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:09,568] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:09,576] {logging_mixin.py:112} INFO - [2022-03-23 08:24:09,576] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:09,620] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:09,626] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:09,628] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:09,638] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:09,818] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.257 seconds
[2022-03-23 08:24:13,555] {scheduler_job.py:153} INFO - Started process (PID=6504) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:13,563] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:13,565] {logging_mixin.py:112} INFO - [2022-03-23 08:24:13,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:13,598] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:13,603] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:13,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:13,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:13,844] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.289 seconds
[2022-03-23 08:24:17,677] {scheduler_job.py:153} INFO - Started process (PID=6509) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:17,685] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:17,687] {logging_mixin.py:112} INFO - [2022-03-23 08:24:17,686] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:17,749] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:17,756] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:17,761] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:17,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:17,962] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.285 seconds
[2022-03-23 08:24:21,569] {scheduler_job.py:153} INFO - Started process (PID=6514) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:21,574] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:21,576] {logging_mixin.py:112} INFO - [2022-03-23 08:24:21,576] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:21,603] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:21,608] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:21,611] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:21,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:21,805] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.236 seconds
[2022-03-23 08:24:25,795] {scheduler_job.py:153} INFO - Started process (PID=6523) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:25,812] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:25,816] {logging_mixin.py:112} INFO - [2022-03-23 08:24:25,816] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:25,888] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:25,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:25,903] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:25,921] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:26,715] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.920 seconds
[2022-03-23 08:24:29,733] {scheduler_job.py:153} INFO - Started process (PID=6528) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:29,740] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:29,742] {logging_mixin.py:112} INFO - [2022-03-23 08:24:29,742] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:29,774] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:29,779] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:29,781] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:29,791] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:30,049] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.317 seconds
[2022-03-23 08:24:33,636] {scheduler_job.py:153} INFO - Started process (PID=6533) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:33,651] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:33,677] {logging_mixin.py:112} INFO - [2022-03-23 08:24:33,677] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:33,755] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:33,764] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:33,769] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:33,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:34,052] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.416 seconds
[2022-03-23 08:24:37,613] {scheduler_job.py:153} INFO - Started process (PID=6538) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:37,620] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:37,622] {logging_mixin.py:112} INFO - [2022-03-23 08:24:37,622] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:37,655] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:37,661] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:37,663] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:37,671] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:37,878] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.266 seconds
[2022-03-23 08:24:41,657] {scheduler_job.py:153} INFO - Started process (PID=6543) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:41,663] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:41,664] {logging_mixin.py:112} INFO - [2022-03-23 08:24:41,664] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:41,729] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:41,740] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:41,742] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:41,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:42,205] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.548 seconds
[2022-03-23 08:24:45,633] {scheduler_job.py:153} INFO - Started process (PID=6551) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:45,643] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:45,644] {logging_mixin.py:112} INFO - [2022-03-23 08:24:45,644] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:45,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:45,706] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:45,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:45,726] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:46,219] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.586 seconds
[2022-03-23 08:24:49,616] {scheduler_job.py:153} INFO - Started process (PID=6556) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:49,626] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:49,628] {logging_mixin.py:112} INFO - [2022-03-23 08:24:49,627] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:49,665] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:49,670] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:49,672] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:49,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:49,972] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.357 seconds
[2022-03-23 08:24:53,666] {scheduler_job.py:153} INFO - Started process (PID=6561) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:53,671] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:53,675] {logging_mixin.py:112} INFO - [2022-03-23 08:24:53,675] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:53,728] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:53,733] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:53,748] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:53,769] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:54,062] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.396 seconds
[2022-03-23 08:24:57,631] {scheduler_job.py:153} INFO - Started process (PID=6569) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:57,639] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:24:57,649] {logging_mixin.py:112} INFO - [2022-03-23 08:24:57,648] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:57,703] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:24:57,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:57,714] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:24:57,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:24:57,981] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.350 seconds
[2022-03-23 08:25:03,303] {scheduler_job.py:153} INFO - Started process (PID=6575) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:03,311] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:03,323] {logging_mixin.py:112} INFO - [2022-03-23 08:25:03,322] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:03,479] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:03,484] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:03,489] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:03,500] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:03,823] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.521 seconds
[2022-03-23 08:25:07,302] {scheduler_job.py:153} INFO - Started process (PID=6580) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:07,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:07,319] {logging_mixin.py:112} INFO - [2022-03-23 08:25:07,319] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:07,389] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:07,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:07,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:07,420] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:07,703] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.401 seconds
[2022-03-23 08:25:11,284] {scheduler_job.py:153} INFO - Started process (PID=6588) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:11,289] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:11,291] {logging_mixin.py:112} INFO - [2022-03-23 08:25:11,291] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:11,323] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:11,330] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:11,332] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:11,342] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:11,529] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.246 seconds
[2022-03-23 08:25:15,280] {scheduler_job.py:153} INFO - Started process (PID=6593) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:15,285] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:15,287] {logging_mixin.py:112} INFO - [2022-03-23 08:25:15,287] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:15,314] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:15,319] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:15,321] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:15,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:15,495] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.215 seconds
[2022-03-23 08:25:19,295] {scheduler_job.py:153} INFO - Started process (PID=6598) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:19,301] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:19,303] {logging_mixin.py:112} INFO - [2022-03-23 08:25:19,303] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:19,379] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:19,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:19,388] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:19,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:19,625] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.330 seconds
[2022-03-23 08:25:23,303] {scheduler_job.py:153} INFO - Started process (PID=6603) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:23,316] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:23,318] {logging_mixin.py:112} INFO - [2022-03-23 08:25:23,318] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:23,447] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:23,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:23,485] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:23,503] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:23,902] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.599 seconds
[2022-03-23 08:25:27,333] {scheduler_job.py:153} INFO - Started process (PID=6611) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:27,339] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:27,344] {logging_mixin.py:112} INFO - [2022-03-23 08:25:27,343] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:27,422] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:27,434] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:27,436] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:27,451] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:27,667] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.334 seconds
[2022-03-23 08:25:31,330] {scheduler_job.py:153} INFO - Started process (PID=6616) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:31,340] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:31,348] {logging_mixin.py:112} INFO - [2022-03-23 08:25:31,348] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:31,396] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:31,402] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:31,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:31,419] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:31,668] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.339 seconds
[2022-03-23 08:25:36,576] {scheduler_job.py:153} INFO - Started process (PID=6622) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:36,593] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:36,596] {logging_mixin.py:112} INFO - [2022-03-23 08:25:36,596] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:36,647] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:36,663] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:36,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:36,982] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:37,839] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.263 seconds
[2022-03-23 08:25:39,323] {scheduler_job.py:153} INFO - Started process (PID=6627) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:39,332] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:39,335] {logging_mixin.py:112} INFO - [2022-03-23 08:25:39,334] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:39,404] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:39,411] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:39,414] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:39,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:40,040] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.718 seconds
[2022-03-23 08:25:43,341] {scheduler_job.py:153} INFO - Started process (PID=6632) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:43,353] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:43,354] {logging_mixin.py:112} INFO - [2022-03-23 08:25:43,354] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:43,399] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:43,405] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:43,408] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:43,419] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:43,597] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.256 seconds
[2022-03-23 08:25:47,331] {scheduler_job.py:153} INFO - Started process (PID=6640) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:47,337] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:47,339] {logging_mixin.py:112} INFO - [2022-03-23 08:25:47,338] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:47,371] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:47,378] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:47,381] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:47,391] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:47,604] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.274 seconds
[2022-03-23 08:25:51,320] {scheduler_job.py:153} INFO - Started process (PID=6645) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:51,328] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:51,329] {logging_mixin.py:112} INFO - [2022-03-23 08:25:51,329] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:51,379] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:51,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:51,387] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:51,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:51,582] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:25:55,354] {scheduler_job.py:153} INFO - Started process (PID=6650) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:55,371] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:55,373] {logging_mixin.py:112} INFO - [2022-03-23 08:25:55,373] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:55,484] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:55,491] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:55,494] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:55,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:55,819] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.465 seconds
[2022-03-23 08:25:59,395] {scheduler_job.py:153} INFO - Started process (PID=6655) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:59,425] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:25:59,427] {logging_mixin.py:112} INFO - [2022-03-23 08:25:59,427] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:25:59,591] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:25:59,612] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:59,634] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:25:59,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:00,490] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.095 seconds
[2022-03-23 08:26:03,390] {scheduler_job.py:153} INFO - Started process (PID=6663) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:03,406] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:03,418] {logging_mixin.py:112} INFO - [2022-03-23 08:26:03,418] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:03,519] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:03,532] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:03,535] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:03,558] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:03,887] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.497 seconds
[2022-03-23 08:26:07,361] {scheduler_job.py:153} INFO - Started process (PID=6668) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:07,371] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:07,373] {logging_mixin.py:112} INFO - [2022-03-23 08:26:07,373] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:07,619] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:07,626] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:07,629] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:07,638] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:08,114] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.753 seconds
[2022-03-23 08:26:12,760] {scheduler_job.py:153} INFO - Started process (PID=6674) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:12,779] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:12,795] {logging_mixin.py:112} INFO - [2022-03-23 08:26:12,795] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:13,038] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:13,057] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:13,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:13,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:14,183] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.423 seconds
[2022-03-23 08:26:15,411] {scheduler_job.py:153} INFO - Started process (PID=6679) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:15,426] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:15,435] {logging_mixin.py:112} INFO - [2022-03-23 08:26:15,435] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:15,600] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:15,616] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:15,619] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:15,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:16,948] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.538 seconds
[2022-03-23 08:26:19,389] {scheduler_job.py:153} INFO - Started process (PID=6687) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:19,406] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:19,418] {logging_mixin.py:112} INFO - [2022-03-23 08:26:19,412] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:19,477] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:19,483] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:19,486] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:19,506] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:20,119] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:26:20,304] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:26:20,380] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.991 seconds
[2022-03-23 08:26:23,404] {scheduler_job.py:153} INFO - Started process (PID=6692) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:23,413] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:23,415] {logging_mixin.py:112} INFO - [2022-03-23 08:26:23,415] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:23,464] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:23,471] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:23,474] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:23,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:24,240] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:26:24,387] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:26:24,423] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.020 seconds
[2022-03-23 08:26:27,426] {scheduler_job.py:153} INFO - Started process (PID=6697) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:27,443] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:27,452] {logging_mixin.py:112} INFO - [2022-03-23 08:26:27,452] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:27,539] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:27,554] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:27,557] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:27,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:27,861] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:26:27,975] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:26:25.721646+00:00: manual__2022-03-23T08:26:25.721646+00:00, externally triggered: True>
[2022-03-23 08:26:28,080] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:26:28,124] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 08:26:25.721646+00:00 [scheduled]> in ORM
[2022-03-23 08:26:28,277] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.851 seconds
[2022-03-23 08:26:46,530] {scheduler_job.py:153} INFO - Started process (PID=6723) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:46,536] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:26:46,538] {logging_mixin.py:112} INFO - [2022-03-23 08:26:46,537] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:46,577] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:26:46,582] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:46,584] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:26:46,595] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:26:46,803] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:26:46,871] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:26:25.721646+00:00: manual__2022-03-23T08:26:25.721646+00:00, externally triggered: True>
[2022-03-23 08:26:46,952] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:26:46,970] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.create_table 2022-03-23 08:26:25.721646+00:00 [scheduled]> in ORM
[2022-03-23 08:26:47,112] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.582 seconds
[2022-03-23 08:27:06,132] {scheduler_job.py:153} INFO - Started process (PID=6750) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:06,144] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:06,148] {logging_mixin.py:112} INFO - [2022-03-23 08:27:06,146] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:06,214] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:06,223] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:06,229] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:06,239] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:06,485] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:06,572] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:26:25.721646+00:00: manual__2022-03-23T08:26:25.721646+00:00, externally triggered: True>
[2022-03-23 08:27:06,634] {logging_mixin.py:112} INFO - [2022-03-23 08:27:06,634] {dagrun.py:309} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 08:26:25.721646+00:00: manual__2022-03-23T08:26:25.721646+00:00, externally triggered: True> failed
[2022-03-23 08:27:06,737] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:06,770] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.638 seconds
[2022-03-23 08:27:09,985] {scheduler_job.py:153} INFO - Started process (PID=6758) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:09,994] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:09,996] {logging_mixin.py:112} INFO - [2022-03-23 08:27:09,995] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:10,027] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:10,033] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:10,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:10,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:10,329] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:10,430] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:10,451] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.465 seconds
[2022-03-23 08:27:13,986] {scheduler_job.py:153} INFO - Started process (PID=6763) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:13,993] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:13,995] {logging_mixin.py:112} INFO - [2022-03-23 08:27:13,994] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:14,027] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:14,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:14,033] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:14,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:14,265] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:14,361] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:14,391] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.406 seconds
[2022-03-23 08:27:18,032] {scheduler_job.py:153} INFO - Started process (PID=6768) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:18,038] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:18,040] {logging_mixin.py:112} INFO - [2022-03-23 08:27:18,040] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:18,070] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:18,074] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:18,076] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:18,084] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:18,321] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:18,423] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:18,447] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-03-23 08:27:22,020] {scheduler_job.py:153} INFO - Started process (PID=6777) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:22,028] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:22,030] {logging_mixin.py:112} INFO - [2022-03-23 08:27:22,029] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:22,056] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:22,061] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:22,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:22,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:22,384] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:22,484] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:22,505] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.485 seconds
[2022-03-23 08:27:26,022] {scheduler_job.py:153} INFO - Started process (PID=6782) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:26,031] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:26,032] {logging_mixin.py:112} INFO - [2022-03-23 08:27:26,032] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:26,064] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:26,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:26,070] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:26,078] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:26,299] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:26,388] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:26,411] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.388 seconds
[2022-03-23 08:27:30,054] {scheduler_job.py:153} INFO - Started process (PID=6787) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:30,063] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:30,064] {logging_mixin.py:112} INFO - [2022-03-23 08:27:30,064] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:30,097] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:30,102] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:30,104] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:30,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:30,347] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:30,437] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:30,464] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.410 seconds
[2022-03-23 08:27:34,051] {scheduler_job.py:153} INFO - Started process (PID=6792) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:34,057] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:34,059] {logging_mixin.py:112} INFO - [2022-03-23 08:27:34,059] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:34,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:34,089] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:34,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:34,099] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:34,609] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:34,734] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:34,761] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.710 seconds
[2022-03-23 08:27:38,049] {scheduler_job.py:153} INFO - Started process (PID=6800) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:38,057] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:38,060] {logging_mixin.py:112} INFO - [2022-03-23 08:27:38,060] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:38,133] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:38,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:38,155] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:38,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:38,493] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:38,586] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:38,632] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.583 seconds
[2022-03-23 08:27:42,122] {scheduler_job.py:153} INFO - Started process (PID=6805) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:42,137] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:42,139] {logging_mixin.py:112} INFO - [2022-03-23 08:27:42,138] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:42,712] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:42,740] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:42,758] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:42,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:46,926] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:47,047] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:47,080] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.958 seconds
[2022-03-23 08:27:47,848] {scheduler_job.py:153} INFO - Started process (PID=6813) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:47,858] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:47,859] {logging_mixin.py:112} INFO - [2022-03-23 08:27:47,859] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:47,892] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:47,897] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:47,899] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:47,909] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:48,297] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:48,497] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:48,549] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.701 seconds
[2022-03-23 08:27:50,797] {scheduler_job.py:153} INFO - Started process (PID=6815) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:50,828] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:50,915] {logging_mixin.py:112} INFO - [2022-03-23 08:27:50,911] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:51,000] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:51,007] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:51,019] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:51,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:51,402] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:51,554] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:51,600] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.803 seconds
[2022-03-23 08:27:54,187] {scheduler_job.py:153} INFO - Started process (PID=6824) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:54,202] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:54,212] {logging_mixin.py:112} INFO - [2022-03-23 08:27:54,212] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:54,346] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:54,352] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:54,364] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:54,397] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:54,828] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:55,060] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:55,098] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.912 seconds
[2022-03-23 08:27:58,080] {scheduler_job.py:153} INFO - Started process (PID=6829) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:58,086] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:27:58,088] {logging_mixin.py:112} INFO - [2022-03-23 08:27:58,088] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:58,132] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:27:58,138] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:58,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:27:58,151] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:27:58,396] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:27:58,477] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:27:58,499] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-03-23 08:28:02,251] {scheduler_job.py:153} INFO - Started process (PID=6834) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:02,259] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:02,261] {logging_mixin.py:112} INFO - [2022-03-23 08:28:02,261] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:02,315] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:02,321] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:02,325] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:02,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:02,684] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:02,804] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:02,826] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.576 seconds
[2022-03-23 08:28:06,270] {scheduler_job.py:153} INFO - Started process (PID=6839) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:06,283] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:06,284] {logging_mixin.py:112} INFO - [2022-03-23 08:28:06,284] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:06,494] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:06,500] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:06,503] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:06,532] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:06,939] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:07,081] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:07,112] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.842 seconds
[2022-03-23 08:28:10,268] {scheduler_job.py:153} INFO - Started process (PID=6847) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:10,276] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:10,277] {logging_mixin.py:112} INFO - [2022-03-23 08:28:10,277] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:10,310] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:10,316] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:10,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:10,325] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:10,632] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:10,708] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:10,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.462 seconds
[2022-03-23 08:28:14,271] {scheduler_job.py:153} INFO - Started process (PID=6852) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:14,278] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:14,280] {logging_mixin.py:112} INFO - [2022-03-23 08:28:14,280] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:14,333] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:14,339] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:14,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:14,357] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:14,668] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:14,804] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:14,832] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.561 seconds
[2022-03-23 08:28:18,266] {scheduler_job.py:153} INFO - Started process (PID=6857) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:18,274] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:18,275] {logging_mixin.py:112} INFO - [2022-03-23 08:28:18,275] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:18,313] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:18,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:18,320] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:18,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:18,561] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:18,659] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:18,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-03-23 08:28:22,300] {scheduler_job.py:153} INFO - Started process (PID=6862) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:22,316] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:22,319] {logging_mixin.py:112} INFO - [2022-03-23 08:28:22,318] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:22,383] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:22,391] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:22,394] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:22,421] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:22,688] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:22,773] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:22,796] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.497 seconds
[2022-03-23 08:28:27,043] {scheduler_job.py:153} INFO - Started process (PID=6870) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:27,059] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:27,081] {logging_mixin.py:112} INFO - [2022-03-23 08:28:27,080] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:27,701] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:27,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:27,720] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:27,738] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:28,688] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:28,811] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:28,861] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.818 seconds
[2022-03-23 08:28:30,597] {scheduler_job.py:153} INFO - Started process (PID=6876) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:30,613] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:30,616] {logging_mixin.py:112} INFO - [2022-03-23 08:28:30,616] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:30,971] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:30,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:30,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:30,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:31,552] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:31,704] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:31,756] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.159 seconds
[2022-03-23 08:28:34,297] {scheduler_job.py:153} INFO - Started process (PID=6881) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:34,303] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:34,305] {logging_mixin.py:112} INFO - [2022-03-23 08:28:34,304] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:34,342] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:34,347] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:34,349] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:34,366] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:36,221] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:36,686] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:36,708] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.411 seconds
[2022-03-23 08:28:38,328] {scheduler_job.py:153} INFO - Started process (PID=6889) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:38,343] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:38,348] {logging_mixin.py:112} INFO - [2022-03-23 08:28:38,347] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:38,393] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:38,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:38,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:38,411] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:38,797] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:38,881] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:38,902] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.574 seconds
[2022-03-23 08:28:42,995] {scheduler_job.py:153} INFO - Started process (PID=6894) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:43,011] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:43,019] {logging_mixin.py:112} INFO - [2022-03-23 08:28:43,018] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:43,750] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:43,756] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:43,762] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:43,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:45,823] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:46,030] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:46,115] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.121 seconds
[2022-03-23 08:28:48,421] {scheduler_job.py:153} INFO - Started process (PID=6902) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:48,430] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:48,442] {logging_mixin.py:112} INFO - [2022-03-23 08:28:48,442] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:48,494] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:48,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:48,501] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:48,514] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:49,144] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:49,284] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:49,346] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.936 seconds
[2022-03-23 08:28:53,398] {scheduler_job.py:153} INFO - Started process (PID=6907) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:53,412] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:53,417] {logging_mixin.py:112} INFO - [2022-03-23 08:28:53,416] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:54,017] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:54,022] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:54,032] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:54,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:55,861] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:56,366] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:56,399] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.001 seconds
[2022-03-23 08:28:57,300] {scheduler_job.py:153} INFO - Started process (PID=6912) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:57,307] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:28:57,319] {logging_mixin.py:112} INFO - [2022-03-23 08:28:57,319] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:57,389] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:57,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:57,409] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:28:57,428] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:28:58,218] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:28:58,304] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:28:58,450] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:28:58,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.198 seconds
[2022-03-23 08:29:00,046] {scheduler_job.py:153} INFO - Started process (PID=6917) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:00,063] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:00,075] {logging_mixin.py:112} INFO - [2022-03-23 08:29:00,075] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:00,138] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:00,144] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:00,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:00,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:01,290] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:01,439] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:01,486] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.439 seconds
[2022-03-23 08:29:04,556] {scheduler_job.py:153} INFO - Started process (PID=6926) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:04,573] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:04,587] {logging_mixin.py:112} INFO - [2022-03-23 08:29:04,587] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:04,738] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:04,751] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:04,764] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:04,814] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:05,366] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:05,544] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:29:02.653740+00:00: manual__2022-03-23T08:29:02.653740+00:00, externally triggered: True>
[2022-03-23 08:29:05,932] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:05,986] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.load_data 2022-03-23 08:29:02.653740+00:00 [scheduled]> in ORM
[2022-03-23 08:29:06,585] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.030 seconds
[2022-03-23 08:29:08,232] {scheduler_job.py:153} INFO - Started process (PID=6931) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:08,241] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:08,247] {logging_mixin.py:112} INFO - [2022-03-23 08:29:08,246] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:08,315] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:08,329] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:08,336] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:08,359] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:09,682] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:09,819] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:29:02.653740+00:00: manual__2022-03-23T08:29:02.653740+00:00, externally triggered: True>
[2022-03-23 08:29:09,964] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:10,010] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.779 seconds
[2022-03-23 08:29:27,583] {scheduler_job.py:153} INFO - Started process (PID=6957) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:27,590] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:27,592] {logging_mixin.py:112} INFO - [2022-03-23 08:29:27,592] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:27,619] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:27,623] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:27,625] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:27,633] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:27,852] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:27,934] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:29:02.653740+00:00: manual__2022-03-23T08:29:02.653740+00:00, externally triggered: True>
[2022-03-23 08:29:28,027] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:28,046] {scheduler_job.py:1640} INFO - Creating / updating <TaskInstance: bigquery_data_load.create_table 2022-03-23 08:29:02.653740+00:00 [scheduled]> in ORM
[2022-03-23 08:29:28,209] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.626 seconds
[2022-03-23 08:29:46,934] {scheduler_job.py:153} INFO - Started process (PID=6984) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:46,939] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:46,941] {logging_mixin.py:112} INFO - [2022-03-23 08:29:46,941] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:46,978] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:46,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:46,985] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:46,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:47,343] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:47,434] {scheduler_job.py:759} INFO - Examining DAG run <DagRun bigquery_data_load @ 2022-03-23 08:29:02.653740+00:00: manual__2022-03-23T08:29:02.653740+00:00, externally triggered: True>
[2022-03-23 08:29:47,468] {logging_mixin.py:112} INFO - [2022-03-23 08:29:47,468] {dagrun.py:318} INFO - Marking run <DagRun bigquery_data_load @ 2022-03-23 08:29:02.653740+00:00: manual__2022-03-23T08:29:02.653740+00:00, externally triggered: True> successful
[2022-03-23 08:29:47,606] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:47,631] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.698 seconds
[2022-03-23 08:29:50,919] {scheduler_job.py:153} INFO - Started process (PID=6989) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:50,928] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:50,929] {logging_mixin.py:112} INFO - [2022-03-23 08:29:50,929] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:50,959] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:50,963] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:50,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:50,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:51,595] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:51,686] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:51,712] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.793 seconds
[2022-03-23 08:29:54,918] {scheduler_job.py:153} INFO - Started process (PID=6997) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:54,924] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:54,925] {logging_mixin.py:112} INFO - [2022-03-23 08:29:54,925] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:54,958] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:54,962] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:54,964] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:54,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:55,262] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:55,350] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:55,373] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.455 seconds
[2022-03-23 08:29:58,964] {scheduler_job.py:153} INFO - Started process (PID=7002) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:58,970] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:29:58,971] {logging_mixin.py:112} INFO - [2022-03-23 08:29:58,971] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:58,998] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:29:59,002] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:59,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:29:59,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:29:59,302] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:29:59,389] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:29:59,412] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.448 seconds
[2022-03-23 08:30:02,937] {scheduler_job.py:153} INFO - Started process (PID=7007) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:02,952] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:02,955] {logging_mixin.py:112} INFO - [2022-03-23 08:30:02,954] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:02,986] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:02,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:02,993] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:03,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:03,391] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:30:03,463] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:30:03,482] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.545 seconds
[2022-03-23 08:30:06,945] {scheduler_job.py:153} INFO - Started process (PID=7015) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:06,951] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:06,953] {logging_mixin.py:112} INFO - [2022-03-23 08:30:06,952] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:06,983] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:06,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:06,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:06,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:07,450] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:30:07,537] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:30:07,564] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.619 seconds
[2022-03-23 08:30:10,969] {scheduler_job.py:153} INFO - Started process (PID=7021) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:10,975] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:10,976] {logging_mixin.py:112} INFO - [2022-03-23 08:30:10,976] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:11,004] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:11,008] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:11,010] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:11,018] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:11,220] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:30:11,301] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:30:11,329] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.360 seconds
[2022-03-23 08:30:14,948] {scheduler_job.py:153} INFO - Started process (PID=7026) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:14,954] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:14,955] {logging_mixin.py:112} INFO - [2022-03-23 08:30:14,955] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:14,986] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:14,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:14,993] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:15,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:15,251] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:30:15,343] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:30:15,371] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.423 seconds
[2022-03-23 08:30:18,958] {scheduler_job.py:153} INFO - Started process (PID=7031) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:18,963] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:18,965] {logging_mixin.py:112} INFO - [2022-03-23 08:30:18,964] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:18,999] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:19,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:19,008] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:19,018] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:19,280] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:30:19,358] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:30:19,383] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.425 seconds
[2022-03-23 08:30:23,082] {scheduler_job.py:153} INFO - Started process (PID=7039) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:23,088] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:23,090] {logging_mixin.py:112} INFO - [2022-03-23 08:30:23,089] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:23,123] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:23,129] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:23,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:23,141] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:23,371] {scheduler_job.py:1284} INFO - Processing bigquery_data_load
[2022-03-23 08:30:23,470] {scheduler_job.py:447} INFO - Skipping SLA check for <DAG: bigquery_data_load> because no tasks in DAG have SLAs
[2022-03-23 08:30:23,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-03-23 08:30:26,997] {scheduler_job.py:153} INFO - Started process (PID=7044) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:27,006] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:27,011] {logging_mixin.py:112} INFO - [2022-03-23 08:30:27,010] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:27,087] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:27,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:27,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:27,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:27,324] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-03-23 08:30:30,971] {scheduler_job.py:153} INFO - Started process (PID=7049) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:30,980] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:30,981] {logging_mixin.py:112} INFO - [2022-03-23 08:30:30,981] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:31,010] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:31,015] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:31,017] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:31,027] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:31,185] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.214 seconds
[2022-03-23 08:30:35,000] {scheduler_job.py:153} INFO - Started process (PID=7054) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:35,005] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:35,007] {logging_mixin.py:112} INFO - [2022-03-23 08:30:35,007] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:35,057] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:35,062] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:35,065] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:35,078] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:35,281] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-03-23 08:30:38,995] {scheduler_job.py:153} INFO - Started process (PID=7062) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:39,007] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:39,009] {logging_mixin.py:112} INFO - [2022-03-23 08:30:39,008] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:39,055] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:39,062] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:39,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:39,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:39,534] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.541 seconds
[2022-03-23 08:30:43,017] {scheduler_job.py:153} INFO - Started process (PID=7068) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:43,026] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:43,028] {logging_mixin.py:112} INFO - [2022-03-23 08:30:43,027] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:43,128] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:43,134] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:43,137] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:43,150] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:43,372] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.355 seconds
[2022-03-23 08:30:47,031] {scheduler_job.py:153} INFO - Started process (PID=7073) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:47,038] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:47,039] {logging_mixin.py:112} INFO - [2022-03-23 08:30:47,039] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:47,086] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:47,093] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:47,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:47,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:47,285] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.253 seconds
[2022-03-23 08:30:51,022] {scheduler_job.py:153} INFO - Started process (PID=7081) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:51,037] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:51,038] {logging_mixin.py:112} INFO - [2022-03-23 08:30:51,038] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:51,096] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:51,102] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:51,104] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:51,119] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:51,331] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.310 seconds
[2022-03-23 08:30:55,021] {scheduler_job.py:153} INFO - Started process (PID=7086) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:55,031] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:55,033] {logging_mixin.py:112} INFO - [2022-03-23 08:30:55,033] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:55,089] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:55,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:55,100] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:55,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:55,356] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-03-23 08:30:59,085] {scheduler_job.py:153} INFO - Started process (PID=7091) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:59,092] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:30:59,093] {logging_mixin.py:112} INFO - [2022-03-23 08:30:59,093] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:59,123] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:30:59,128] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:59,130] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:30:59,139] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:30:59,425] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.340 seconds
[2022-03-23 08:31:03,025] {scheduler_job.py:153} INFO - Started process (PID=7096) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:03,035] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:03,037] {logging_mixin.py:112} INFO - [2022-03-23 08:31:03,037] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:03,081] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:03,086] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:03,088] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:03,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:03,316] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.292 seconds
[2022-03-23 08:31:07,023] {scheduler_job.py:153} INFO - Started process (PID=7104) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:07,036] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:07,038] {logging_mixin.py:112} INFO - [2022-03-23 08:31:07,038] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:07,105] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:07,111] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:07,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:07,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:07,411] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.388 seconds
[2022-03-23 08:31:11,061] {scheduler_job.py:153} INFO - Started process (PID=7109) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:11,076] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:11,078] {logging_mixin.py:112} INFO - [2022-03-23 08:31:11,078] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:11,129] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:11,134] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:11,136] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:11,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:11,437] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.376 seconds
[2022-03-23 08:31:15,070] {scheduler_job.py:153} INFO - Started process (PID=7114) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:15,079] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:15,082] {logging_mixin.py:112} INFO - [2022-03-23 08:31:15,082] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:15,160] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:15,168] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:15,170] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:15,191] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:15,596] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.536 seconds
[2022-03-23 08:31:19,068] {scheduler_job.py:153} INFO - Started process (PID=7120) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:19,083] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:19,097] {logging_mixin.py:112} INFO - [2022-03-23 08:31:19,096] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:19,997] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:20,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:20,006] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:20,039] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:20,436] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.367 seconds
[2022-03-23 08:31:23,081] {scheduler_job.py:153} INFO - Started process (PID=7125) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:23,086] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:23,087] {logging_mixin.py:112} INFO - [2022-03-23 08:31:23,087] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:23,123] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:23,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:23,135] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:23,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:23,407] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-03-23 08:31:27,135] {scheduler_job.py:153} INFO - Started process (PID=7133) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:27,150] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:27,153] {logging_mixin.py:112} INFO - [2022-03-23 08:31:27,153] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:27,235] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:27,240] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:27,245] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:27,256] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:27,472] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.338 seconds
[2022-03-23 08:31:31,050] {scheduler_job.py:153} INFO - Started process (PID=7138) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:31,057] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:31,062] {logging_mixin.py:112} INFO - [2022-03-23 08:31:31,062] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:31,104] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:31,109] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:31,115] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:31,126] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:31,318] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.269 seconds
[2022-03-23 08:31:35,465] {scheduler_job.py:153} INFO - Started process (PID=7143) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:35,473] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:35,479] {logging_mixin.py:112} INFO - [2022-03-23 08:31:35,478] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:35,534] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:35,540] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:35,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:35,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:35,857] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.392 seconds
[2022-03-23 08:31:39,615] {scheduler_job.py:153} INFO - Started process (PID=7151) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:39,639] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:39,645] {logging_mixin.py:112} INFO - [2022-03-23 08:31:39,645] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:39,867] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:39,873] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:39,884] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:39,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:41,604] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.989 seconds
[2022-03-23 08:31:43,487] {scheduler_job.py:153} INFO - Started process (PID=7156) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:43,495] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:43,497] {logging_mixin.py:112} INFO - [2022-03-23 08:31:43,497] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:43,559] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:43,565] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:43,576] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:43,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:43,871] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.384 seconds
[2022-03-23 08:31:47,488] {scheduler_job.py:153} INFO - Started process (PID=7161) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:47,496] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:47,498] {logging_mixin.py:112} INFO - [2022-03-23 08:31:47,498] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:47,544] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:47,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:47,555] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:47,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:47,800] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-03-23 08:31:51,540] {scheduler_job.py:153} INFO - Started process (PID=7167) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:51,570] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:51,572] {logging_mixin.py:112} INFO - [2022-03-23 08:31:51,572] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:51,635] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:51,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:51,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:51,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:53,733] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.193 seconds
[2022-03-23 08:31:57,326] {scheduler_job.py:153} INFO - Started process (PID=7175) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:57,342] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:31:57,345] {logging_mixin.py:112} INFO - [2022-03-23 08:31:57,344] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:57,470] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:31:57,485] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:57,525] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:31:57,552] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:31:58,097] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.771 seconds
[2022-03-23 08:32:00,709] {scheduler_job.py:153} INFO - Started process (PID=7180) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:00,721] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:00,729] {logging_mixin.py:112} INFO - [2022-03-23 08:32:00,729] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:00,795] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:00,813] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:00,820] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:00,844] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:01,231] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.522 seconds
[2022-03-23 08:32:04,738] {scheduler_job.py:153} INFO - Started process (PID=7185) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:04,755] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:04,768] {logging_mixin.py:112} INFO - [2022-03-23 08:32:04,767] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:04,904] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:04,921] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:04,924] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:04,956] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:05,655] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.917 seconds
[2022-03-23 08:32:08,691] {scheduler_job.py:153} INFO - Started process (PID=7190) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:08,697] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:08,698] {logging_mixin.py:112} INFO - [2022-03-23 08:32:08,698] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:08,730] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:08,735] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:08,737] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:08,746] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:08,912] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.221 seconds
[2022-03-23 08:32:12,705] {scheduler_job.py:153} INFO - Started process (PID=7198) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:12,712] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:12,714] {logging_mixin.py:112} INFO - [2022-03-23 08:32:12,713] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:12,749] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:12,754] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:12,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:12,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:12,923] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.218 seconds
[2022-03-23 08:32:16,735] {scheduler_job.py:153} INFO - Started process (PID=7203) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:16,741] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:16,743] {logging_mixin.py:112} INFO - [2022-03-23 08:32:16,743] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:16,785] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:16,792] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:16,795] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:16,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:16,965] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.231 seconds
[2022-03-23 08:32:20,718] {scheduler_job.py:153} INFO - Started process (PID=7208) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:20,724] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:20,725] {logging_mixin.py:112} INFO - [2022-03-23 08:32:20,725] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:20,751] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:20,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:20,759] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:20,766] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:20,944] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.226 seconds
[2022-03-23 08:32:24,734] {scheduler_job.py:153} INFO - Started process (PID=7214) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:24,742] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:24,743] {logging_mixin.py:112} INFO - [2022-03-23 08:32:24,743] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:24,776] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:24,782] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:24,784] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:24,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:24,994] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.259 seconds
[2022-03-23 08:32:28,730] {scheduler_job.py:153} INFO - Started process (PID=7222) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:28,735] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:28,737] {logging_mixin.py:112} INFO - [2022-03-23 08:32:28,737] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:28,775] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:28,780] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:28,782] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:28,792] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:28,971] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.241 seconds
[2022-03-23 08:32:32,734] {scheduler_job.py:153} INFO - Started process (PID=7227) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:32,739] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:32,741] {logging_mixin.py:112} INFO - [2022-03-23 08:32:32,741] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:32,768] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:32,773] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:32,775] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:32,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:32,923] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.189 seconds
[2022-03-23 08:32:36,737] {scheduler_job.py:153} INFO - Started process (PID=7232) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:36,745] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:36,746] {logging_mixin.py:112} INFO - [2022-03-23 08:32:36,746] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:36,776] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:36,781] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:36,783] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:36,792] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:36,959] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.222 seconds
[2022-03-23 08:32:40,742] {scheduler_job.py:153} INFO - Started process (PID=7240) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:40,748] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:40,749] {logging_mixin.py:112} INFO - [2022-03-23 08:32:40,749] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:40,824] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:40,829] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:40,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:40,839] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:41,015] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.273 seconds
[2022-03-23 08:32:44,764] {scheduler_job.py:153} INFO - Started process (PID=7245) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:44,779] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:44,786] {logging_mixin.py:112} INFO - [2022-03-23 08:32:44,785] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:44,853] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:44,861] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:44,864] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:44,879] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:45,103] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.340 seconds
[2022-03-23 08:32:48,763] {scheduler_job.py:153} INFO - Started process (PID=7250) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:48,829] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:48,839] {logging_mixin.py:112} INFO - [2022-03-23 08:32:48,839] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:48,905] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:48,920] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:48,924] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:48,937] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:49,353] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.590 seconds
[2022-03-23 08:32:52,763] {scheduler_job.py:153} INFO - Started process (PID=7255) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:52,776] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:52,779] {logging_mixin.py:112} INFO - [2022-03-23 08:32:52,779] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:52,822] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:52,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:52,835] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:52,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:53,620] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.857 seconds
[2022-03-23 08:32:56,877] {scheduler_job.py:153} INFO - Started process (PID=7264) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:56,895] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:32:56,907] {logging_mixin.py:112} INFO - [2022-03-23 08:32:56,907] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:56,993] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:32:57,003] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:57,006] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:32:57,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:32:57,347] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.470 seconds
[2022-03-23 08:33:00,762] {scheduler_job.py:153} INFO - Started process (PID=7269) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:00,769] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:00,771] {logging_mixin.py:112} INFO - [2022-03-23 08:33:00,771] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:00,829] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:00,835] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:00,838] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:00,851] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:01,117] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.355 seconds
[2022-03-23 08:33:04,788] {scheduler_job.py:153} INFO - Started process (PID=7274) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:04,801] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:04,803] {logging_mixin.py:112} INFO - [2022-03-23 08:33:04,803] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:04,861] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:04,867] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:04,870] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:04,895] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:05,118] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.330 seconds
[2022-03-23 08:33:08,771] {scheduler_job.py:153} INFO - Started process (PID=7279) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:08,783] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:08,785] {logging_mixin.py:112} INFO - [2022-03-23 08:33:08,784] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:08,838] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:08,844] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:08,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:08,860] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:09,054] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.283 seconds
[2022-03-23 08:33:12,774] {scheduler_job.py:153} INFO - Started process (PID=7287) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:12,787] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:12,789] {logging_mixin.py:112} INFO - [2022-03-23 08:33:12,788] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:12,832] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:12,837] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:12,839] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:12,860] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:13,041] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.267 seconds
[2022-03-23 08:33:16,789] {scheduler_job.py:153} INFO - Started process (PID=7292) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:16,802] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:16,804] {logging_mixin.py:112} INFO - [2022-03-23 08:33:16,803] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:16,849] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:16,853] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:16,855] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:16,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:17,071] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.282 seconds
[2022-03-23 08:33:20,786] {scheduler_job.py:153} INFO - Started process (PID=7297) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:20,793] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:20,796] {logging_mixin.py:112} INFO - [2022-03-23 08:33:20,796] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:20,837] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:20,842] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:20,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:20,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:21,123] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.337 seconds
[2022-03-23 08:33:24,803] {scheduler_job.py:153} INFO - Started process (PID=7302) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:24,818] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:24,820] {logging_mixin.py:112} INFO - [2022-03-23 08:33:24,820] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:24,878] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:24,884] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:24,886] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:24,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:25,118] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-03-23 08:33:28,816] {scheduler_job.py:153} INFO - Started process (PID=7310) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:28,828] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:28,829] {logging_mixin.py:112} INFO - [2022-03-23 08:33:28,829] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:28,870] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:28,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:28,884] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:28,898] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:29,317] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.502 seconds
[2022-03-23 08:33:32,815] {scheduler_job.py:153} INFO - Started process (PID=7316) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:32,822] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:32,823] {logging_mixin.py:112} INFO - [2022-03-23 08:33:32,823] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:32,869] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:32,873] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:32,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:32,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:33,090] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.275 seconds
[2022-03-23 08:33:36,815] {scheduler_job.py:153} INFO - Started process (PID=7321) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:36,822] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:36,827] {logging_mixin.py:112} INFO - [2022-03-23 08:33:36,826] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:36,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:36,886] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:36,888] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:36,901] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:37,123] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.308 seconds
[2022-03-23 08:33:40,839] {scheduler_job.py:153} INFO - Started process (PID=7326) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:40,852] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:40,853] {logging_mixin.py:112} INFO - [2022-03-23 08:33:40,853] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:40,902] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:40,907] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:40,915] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:40,939] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:41,214] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.376 seconds
[2022-03-23 08:33:44,820] {scheduler_job.py:153} INFO - Started process (PID=7334) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:44,830] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:44,831] {logging_mixin.py:112} INFO - [2022-03-23 08:33:44,831] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:44,887] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:44,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:44,898] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:44,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:45,133] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-03-23 08:33:48,819] {scheduler_job.py:153} INFO - Started process (PID=7339) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:48,831] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:48,833] {logging_mixin.py:112} INFO - [2022-03-23 08:33:48,832] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:48,879] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:48,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:48,888] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:48,902] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:49,100] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-03-23 08:33:52,845] {scheduler_job.py:153} INFO - Started process (PID=7344) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:52,855] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:52,862] {logging_mixin.py:112} INFO - [2022-03-23 08:33:52,861] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:52,904] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:52,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:52,915] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:52,935] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:53,155] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.310 seconds
[2022-03-23 08:33:56,837] {scheduler_job.py:153} INFO - Started process (PID=7349) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:56,849] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:33:56,851] {logging_mixin.py:112} INFO - [2022-03-23 08:33:56,851] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:56,914] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:33:56,921] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:56,930] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:33:56,950] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:33:57,195] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.359 seconds
[2022-03-23 08:34:00,833] {scheduler_job.py:153} INFO - Started process (PID=7357) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:00,842] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:00,846] {logging_mixin.py:112} INFO - [2022-03-23 08:34:00,845] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:00,886] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:00,893] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:00,897] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:00,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:01,118] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.285 seconds
[2022-03-23 08:34:04,892] {scheduler_job.py:153} INFO - Started process (PID=7363) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:04,918] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:04,923] {logging_mixin.py:112} INFO - [2022-03-23 08:34:04,922] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:05,001] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:05,017] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:05,021] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:05,056] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:05,406] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.514 seconds
[2022-03-23 08:34:08,853] {scheduler_job.py:153} INFO - Started process (PID=7368) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:08,864] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:08,865] {logging_mixin.py:112} INFO - [2022-03-23 08:34:08,865] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:08,905] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:08,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:08,915] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:08,927] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:09,149] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.295 seconds
[2022-03-23 08:34:12,903] {scheduler_job.py:153} INFO - Started process (PID=7373) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:12,915] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:12,918] {logging_mixin.py:112} INFO - [2022-03-23 08:34:12,917] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:12,989] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:13,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:13,007] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:13,028] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:13,223] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-03-23 08:34:16,885] {scheduler_job.py:153} INFO - Started process (PID=7381) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:16,899] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:16,900] {logging_mixin.py:112} INFO - [2022-03-23 08:34:16,900] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:16,951] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:16,956] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:16,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:16,982] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:17,189] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-03-23 08:34:20,859] {scheduler_job.py:153} INFO - Started process (PID=7386) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:20,873] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:20,876] {logging_mixin.py:112} INFO - [2022-03-23 08:34:20,875] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:20,934] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:20,940] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:20,948] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:20,961] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:21,181] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.323 seconds
[2022-03-23 08:34:24,864] {scheduler_job.py:153} INFO - Started process (PID=7391) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:24,873] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:24,879] {logging_mixin.py:112} INFO - [2022-03-23 08:34:24,878] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:24,922] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:24,929] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:24,932] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:24,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:25,141] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.277 seconds
[2022-03-23 08:34:28,877] {scheduler_job.py:153} INFO - Started process (PID=7399) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:28,885] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:28,886] {logging_mixin.py:112} INFO - [2022-03-23 08:34:28,886] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:28,930] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:28,939] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:28,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:28,953] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:29,145] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.269 seconds
[2022-03-23 08:34:32,872] {scheduler_job.py:153} INFO - Started process (PID=7404) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:32,881] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:32,882] {logging_mixin.py:112} INFO - [2022-03-23 08:34:32,882] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:32,922] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:32,931] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:32,935] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:32,952] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:33,141] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.269 seconds
[2022-03-23 08:34:36,901] {scheduler_job.py:153} INFO - Started process (PID=7410) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:36,907] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:36,911] {logging_mixin.py:112} INFO - [2022-03-23 08:34:36,910] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:36,963] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:36,972] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:36,977] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:36,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:37,174] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.273 seconds
[2022-03-23 08:34:40,910] {scheduler_job.py:153} INFO - Started process (PID=7415) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:40,923] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:40,929] {logging_mixin.py:112} INFO - [2022-03-23 08:34:40,929] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:40,972] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:40,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:40,982] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:40,994] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:41,695] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.785 seconds
[2022-03-23 08:34:44,888] {scheduler_job.py:153} INFO - Started process (PID=7423) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:44,899] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:44,900] {logging_mixin.py:112} INFO - [2022-03-23 08:34:44,900] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:44,942] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:44,947] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:44,949] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:44,961] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:45,220] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.332 seconds
[2022-03-23 08:34:48,909] {scheduler_job.py:153} INFO - Started process (PID=7428) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:48,918] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:48,919] {logging_mixin.py:112} INFO - [2022-03-23 08:34:48,919] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:48,970] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:48,975] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:48,980] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:48,990] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:49,257] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.348 seconds
[2022-03-23 08:34:52,964] {scheduler_job.py:153} INFO - Started process (PID=7433) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:52,980] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:52,984] {logging_mixin.py:112} INFO - [2022-03-23 08:34:52,983] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:53,039] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:53,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:53,054] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:53,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:53,472] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.508 seconds
[2022-03-23 08:34:56,990] {scheduler_job.py:153} INFO - Started process (PID=7438) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:57,001] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:34:57,002] {logging_mixin.py:112} INFO - [2022-03-23 08:34:57,002] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:57,090] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:34:57,100] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:57,103] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:34:57,119] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:34:57,483] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.493 seconds
[2022-03-23 08:35:00,915] {scheduler_job.py:153} INFO - Started process (PID=7446) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:00,928] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:00,930] {logging_mixin.py:112} INFO - [2022-03-23 08:35:00,930] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:00,989] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:00,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:01,000] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:01,013] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:01,338] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.423 seconds
[2022-03-23 08:35:04,931] {scheduler_job.py:153} INFO - Started process (PID=7451) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:04,938] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:04,940] {logging_mixin.py:112} INFO - [2022-03-23 08:35:04,940] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:04,984] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:04,989] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:04,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:05,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:05,337] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.406 seconds
[2022-03-23 08:35:08,958] {scheduler_job.py:153} INFO - Started process (PID=7457) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:08,969] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:08,970] {logging_mixin.py:112} INFO - [2022-03-23 08:35:08,970] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:09,048] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:09,055] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:09,062] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:09,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:09,355] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.397 seconds
[2022-03-23 08:35:12,922] {scheduler_job.py:153} INFO - Started process (PID=7462) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:12,931] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:12,933] {logging_mixin.py:112} INFO - [2022-03-23 08:35:12,933] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:12,980] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:12,985] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:12,987] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:13,000] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:13,201] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.279 seconds
[2022-03-23 08:35:16,943] {scheduler_job.py:153} INFO - Started process (PID=7470) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:16,955] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:16,956] {logging_mixin.py:112} INFO - [2022-03-23 08:35:16,956] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:17,017] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:17,022] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:17,029] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:17,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:17,279] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-03-23 08:35:20,940] {scheduler_job.py:153} INFO - Started process (PID=7475) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:20,949] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:20,950] {logging_mixin.py:112} INFO - [2022-03-23 08:35:20,950] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:20,989] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:20,994] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:20,998] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:21,011] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:21,214] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.274 seconds
[2022-03-23 08:35:24,943] {scheduler_job.py:153} INFO - Started process (PID=7480) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:24,951] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:24,953] {logging_mixin.py:112} INFO - [2022-03-23 08:35:24,953] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:25,002] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:25,009] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:25,013] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:25,024] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:25,255] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-03-23 08:35:28,971] {scheduler_job.py:153} INFO - Started process (PID=7485) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:28,983] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:28,985] {logging_mixin.py:112} INFO - [2022-03-23 08:35:28,985] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:29,035] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:29,040] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:29,044] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:29,064] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:29,319] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.348 seconds
[2022-03-23 08:35:32,953] {scheduler_job.py:153} INFO - Started process (PID=7493) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:32,965] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:32,967] {logging_mixin.py:112} INFO - [2022-03-23 08:35:32,967] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:33,011] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:33,016] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:33,018] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:33,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:33,235] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.283 seconds
[2022-03-23 08:35:36,975] {scheduler_job.py:153} INFO - Started process (PID=7498) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:36,985] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:36,987] {logging_mixin.py:112} INFO - [2022-03-23 08:35:36,987] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:37,039] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:37,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:37,047] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:37,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:37,254] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.279 seconds
[2022-03-23 08:35:40,984] {scheduler_job.py:153} INFO - Started process (PID=7503) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:41,000] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:41,001] {logging_mixin.py:112} INFO - [2022-03-23 08:35:41,001] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:41,057] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:41,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:41,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:41,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:41,359] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.375 seconds
[2022-03-23 08:35:45,014] {scheduler_job.py:153} INFO - Started process (PID=7509) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:45,053] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:45,055] {logging_mixin.py:112} INFO - [2022-03-23 08:35:45,055] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:45,123] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:45,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:45,135] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:45,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:45,451] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.437 seconds
[2022-03-23 08:35:48,971] {scheduler_job.py:153} INFO - Started process (PID=7517) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:48,981] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:48,983] {logging_mixin.py:112} INFO - [2022-03-23 08:35:48,982] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:49,038] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:49,044] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:49,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:49,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:49,254] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.283 seconds
[2022-03-23 08:35:52,989] {scheduler_job.py:153} INFO - Started process (PID=7522) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:53,007] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:53,010] {logging_mixin.py:112} INFO - [2022-03-23 08:35:53,010] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:53,072] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:53,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:53,088] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:53,119] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:53,676] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.687 seconds
[2022-03-23 08:35:56,980] {scheduler_job.py:153} INFO - Started process (PID=7527) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:56,987] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:35:56,989] {logging_mixin.py:112} INFO - [2022-03-23 08:35:56,988] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:57,040] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:35:57,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:57,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:35:57,063] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:35:57,267] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.286 seconds
[2022-03-23 08:36:00,988] {scheduler_job.py:153} INFO - Started process (PID=7532) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:00,999] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:01,000] {logging_mixin.py:112} INFO - [2022-03-23 08:36:01,000] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:01,045] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:01,050] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:01,052] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:01,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:01,324] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.337 seconds
[2022-03-23 08:36:05,011] {scheduler_job.py:153} INFO - Started process (PID=7540) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:05,020] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:05,022] {logging_mixin.py:112} INFO - [2022-03-23 08:36:05,021] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:05,078] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:05,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:05,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:05,102] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:05,322] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.310 seconds
[2022-03-23 08:36:08,996] {scheduler_job.py:153} INFO - Started process (PID=7545) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:09,004] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:09,005] {logging_mixin.py:112} INFO - [2022-03-23 08:36:09,005] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:09,054] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:09,061] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:09,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:09,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:09,300] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-03-23 08:36:13,012] {scheduler_job.py:153} INFO - Started process (PID=7550) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:13,029] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:13,035] {logging_mixin.py:112} INFO - [2022-03-23 08:36:13,034] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:13,098] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:13,107] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:13,111] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:13,134] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:13,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.486 seconds
[2022-03-23 08:36:17,053] {scheduler_job.py:153} INFO - Started process (PID=7559) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:17,061] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:17,067] {logging_mixin.py:112} INFO - [2022-03-23 08:36:17,066] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:17,122] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:17,133] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:17,136] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:17,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:17,468] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-03-23 08:36:21,012] {scheduler_job.py:153} INFO - Started process (PID=7564) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:21,017] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:21,018] {logging_mixin.py:112} INFO - [2022-03-23 08:36:21,018] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:21,071] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:21,079] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:21,081] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:21,095] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:21,289] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.277 seconds
[2022-03-23 08:36:25,024] {scheduler_job.py:153} INFO - Started process (PID=7569) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:25,034] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:25,035] {logging_mixin.py:112} INFO - [2022-03-23 08:36:25,035] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:25,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:25,089] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:25,095] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:25,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:25,313] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.289 seconds
[2022-03-23 08:36:29,052] {scheduler_job.py:153} INFO - Started process (PID=7574) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:29,063] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:29,065] {logging_mixin.py:112} INFO - [2022-03-23 08:36:29,065] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:29,120] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:29,127] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:29,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:29,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:29,368] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-03-23 08:36:33,035] {scheduler_job.py:153} INFO - Started process (PID=7582) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:33,044] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:33,046] {logging_mixin.py:112} INFO - [2022-03-23 08:36:33,046] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:33,095] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:33,100] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:33,103] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:33,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:33,361] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:36:37,040] {scheduler_job.py:153} INFO - Started process (PID=7587) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:37,049] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:37,051] {logging_mixin.py:112} INFO - [2022-03-23 08:36:37,050] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:37,103] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:37,113] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:37,116] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:37,132] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:37,332] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.292 seconds
[2022-03-23 08:36:41,063] {scheduler_job.py:153} INFO - Started process (PID=7592) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:41,071] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:41,073] {logging_mixin.py:112} INFO - [2022-03-23 08:36:41,072] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:41,122] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:41,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:41,135] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:41,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:41,389] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-03-23 08:36:45,103] {scheduler_job.py:153} INFO - Started process (PID=7597) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:45,112] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:45,115] {logging_mixin.py:112} INFO - [2022-03-23 08:36:45,115] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:45,270] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:45,297] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:45,309] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:45,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:45,635] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.533 seconds
[2022-03-23 08:36:49,089] {scheduler_job.py:153} INFO - Started process (PID=7606) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:49,101] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:49,103] {logging_mixin.py:112} INFO - [2022-03-23 08:36:49,102] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:49,180] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:49,185] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:49,188] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:49,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:49,535] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.446 seconds
[2022-03-23 08:36:53,061] {scheduler_job.py:153} INFO - Started process (PID=7611) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:53,075] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:53,078] {logging_mixin.py:112} INFO - [2022-03-23 08:36:53,077] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:53,123] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:53,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:53,133] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:53,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:53,391] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.330 seconds
[2022-03-23 08:36:57,059] {scheduler_job.py:153} INFO - Started process (PID=7616) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:57,069] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:36:57,071] {logging_mixin.py:112} INFO - [2022-03-23 08:36:57,070] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:57,136] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:36:57,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:57,148] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:36:57,161] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:36:57,383] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-03-23 08:37:01,064] {scheduler_job.py:153} INFO - Started process (PID=7621) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:01,082] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:01,084] {logging_mixin.py:112} INFO - [2022-03-23 08:37:01,083] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:01,177] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:01,184] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:01,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:01,217] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:01,449] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.385 seconds
[2022-03-23 08:37:05,079] {scheduler_job.py:153} INFO - Started process (PID=7629) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:05,093] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:05,097] {logging_mixin.py:112} INFO - [2022-03-23 08:37:05,096] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:05,140] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:05,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:05,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:05,173] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:05,431] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.353 seconds
[2022-03-23 08:37:09,078] {scheduler_job.py:153} INFO - Started process (PID=7634) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:09,085] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:09,087] {logging_mixin.py:112} INFO - [2022-03-23 08:37:09,087] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:09,143] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:09,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:09,151] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:09,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:09,403] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-03-23 08:37:13,081] {scheduler_job.py:153} INFO - Started process (PID=7639) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:13,088] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:13,089] {logging_mixin.py:112} INFO - [2022-03-23 08:37:13,089] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:13,134] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:13,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:13,144] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:13,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:13,341] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.260 seconds
[2022-03-23 08:37:17,142] {scheduler_job.py:153} INFO - Started process (PID=7647) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:17,153] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:17,155] {logging_mixin.py:112} INFO - [2022-03-23 08:37:17,155] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:17,216] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:17,221] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:17,227] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:17,238] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:17,454] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-03-23 08:37:21,084] {scheduler_job.py:153} INFO - Started process (PID=7652) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:21,089] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:21,095] {logging_mixin.py:112} INFO - [2022-03-23 08:37:21,095] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:21,146] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:21,151] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:21,153] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:21,169] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:21,407] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-03-23 08:37:25,103] {scheduler_job.py:153} INFO - Started process (PID=7658) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:25,113] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:25,114] {logging_mixin.py:112} INFO - [2022-03-23 08:37:25,114] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:25,165] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:25,170] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:25,173] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:25,186] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:25,403] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.300 seconds
[2022-03-23 08:37:29,114] {scheduler_job.py:153} INFO - Started process (PID=7663) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:29,121] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:29,123] {logging_mixin.py:112} INFO - [2022-03-23 08:37:29,122] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:29,172] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:29,179] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:29,189] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:29,205] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:29,444] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.331 seconds
[2022-03-23 08:37:33,101] {scheduler_job.py:153} INFO - Started process (PID=7671) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:33,108] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:33,110] {logging_mixin.py:112} INFO - [2022-03-23 08:37:33,110] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:33,168] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:33,173] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:33,181] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:33,196] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:33,401] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.300 seconds
[2022-03-23 08:37:37,123] {scheduler_job.py:153} INFO - Started process (PID=7676) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:37,134] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:37,135] {logging_mixin.py:112} INFO - [2022-03-23 08:37:37,135] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:37,195] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:37,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:37,204] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:37,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:37,431] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.309 seconds
[2022-03-23 08:37:41,136] {scheduler_job.py:153} INFO - Started process (PID=7681) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:41,146] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:41,147] {logging_mixin.py:112} INFO - [2022-03-23 08:37:41,147] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:41,189] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:41,195] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:41,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:41,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:41,446] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.310 seconds
[2022-03-23 08:37:45,128] {scheduler_job.py:153} INFO - Started process (PID=7686) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:45,135] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:45,137] {logging_mixin.py:112} INFO - [2022-03-23 08:37:45,136] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:45,178] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:45,183] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:45,185] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:45,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:45,435] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.308 seconds
[2022-03-23 08:37:49,136] {scheduler_job.py:153} INFO - Started process (PID=7694) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:49,145] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:49,147] {logging_mixin.py:112} INFO - [2022-03-23 08:37:49,146] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:49,185] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:49,193] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:49,196] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:49,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:49,419] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.283 seconds
[2022-03-23 08:37:53,164] {scheduler_job.py:153} INFO - Started process (PID=7699) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:53,173] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:53,175] {logging_mixin.py:112} INFO - [2022-03-23 08:37:53,175] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:53,224] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:53,232] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:53,235] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:53,250] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:53,485] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.321 seconds
[2022-03-23 08:37:57,842] {scheduler_job.py:153} INFO - Started process (PID=7705) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:57,915] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:37:57,919] {logging_mixin.py:112} INFO - [2022-03-23 08:37:57,919] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:58,103] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:37:58,111] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:58,124] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:37:58,146] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:37:58,533] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.692 seconds
[2022-03-23 08:38:01,158] {scheduler_job.py:153} INFO - Started process (PID=7710) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:01,166] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:01,168] {logging_mixin.py:112} INFO - [2022-03-23 08:38:01,167] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:01,245] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:01,252] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:01,255] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:01,270] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:01,522] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.365 seconds
[2022-03-23 08:38:05,165] {scheduler_job.py:153} INFO - Started process (PID=7718) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:05,172] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:05,174] {logging_mixin.py:112} INFO - [2022-03-23 08:38:05,174] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:05,218] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:05,223] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:05,229] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:05,239] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:05,437] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.272 seconds
[2022-03-23 08:38:09,198] {scheduler_job.py:153} INFO - Started process (PID=7723) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:09,211] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:09,214] {logging_mixin.py:112} INFO - [2022-03-23 08:38:09,214] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:09,299] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:09,306] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:09,317] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:09,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:09,699] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.502 seconds
[2022-03-23 08:38:13,214] {scheduler_job.py:153} INFO - Started process (PID=7728) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:13,221] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:13,223] {logging_mixin.py:112} INFO - [2022-03-23 08:38:13,223] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:13,316] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:13,323] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:13,327] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:13,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:13,718] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.504 seconds
[2022-03-23 08:38:17,203] {scheduler_job.py:153} INFO - Started process (PID=7733) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:17,221] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:17,223] {logging_mixin.py:112} INFO - [2022-03-23 08:38:17,223] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:17,290] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:17,300] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:17,312] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:17,342] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:17,714] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.511 seconds
[2022-03-23 08:38:21,174] {scheduler_job.py:153} INFO - Started process (PID=7741) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:21,179] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:21,181] {logging_mixin.py:112} INFO - [2022-03-23 08:38:21,181] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:21,215] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:21,221] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:21,225] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:21,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:21,423] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.249 seconds
[2022-03-23 08:38:25,290] {scheduler_job.py:153} INFO - Started process (PID=7746) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:25,308] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:25,325] {logging_mixin.py:112} INFO - [2022-03-23 08:38:25,324] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:25,487] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:25,521] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:25,524] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:25,542] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:26,340] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.050 seconds
[2022-03-23 08:38:29,422] {scheduler_job.py:153} INFO - Started process (PID=7752) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:29,483] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:29,488] {logging_mixin.py:112} INFO - [2022-03-23 08:38:29,488] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:29,594] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:29,603] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:29,618] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:29,648] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:30,049] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.627 seconds
[2022-03-23 08:38:33,248] {scheduler_job.py:153} INFO - Started process (PID=7757) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:33,270] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:33,279] {logging_mixin.py:112} INFO - [2022-03-23 08:38:33,279] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:33,380] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:33,388] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:33,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:33,422] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:33,738] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.490 seconds
[2022-03-23 08:38:37,240] {scheduler_job.py:153} INFO - Started process (PID=7765) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:37,250] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:37,253] {logging_mixin.py:112} INFO - [2022-03-23 08:38:37,252] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:37,310] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:37,332] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:37,334] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:37,349] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:37,770] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.530 seconds
[2022-03-23 08:38:41,814] {scheduler_job.py:153} INFO - Started process (PID=7770) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:41,838] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:41,871] {logging_mixin.py:112} INFO - [2022-03-23 08:38:41,871] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:42,879] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:42,910] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:42,913] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:42,989] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:43,771] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.956 seconds
[2022-03-23 08:38:45,967] {scheduler_job.py:153} INFO - Started process (PID=7775) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:46,017] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:46,029] {logging_mixin.py:112} INFO - [2022-03-23 08:38:46,029] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:46,124] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:46,167] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:46,172] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:46,204] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:46,745] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.778 seconds
[2022-03-23 08:38:49,980] {scheduler_job.py:153} INFO - Started process (PID=7783) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:50,017] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:50,033] {logging_mixin.py:112} INFO - [2022-03-23 08:38:50,033] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:50,100] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:50,119] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:50,122] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:50,150] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:50,540] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.560 seconds
[2022-03-23 08:38:53,973] {scheduler_job.py:153} INFO - Started process (PID=7788) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:53,994] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:53,996] {logging_mixin.py:112} INFO - [2022-03-23 08:38:53,995] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:54,104] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:54,123] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:54,138] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:54,171] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:54,629] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.656 seconds
[2022-03-23 08:38:57,924] {scheduler_job.py:153} INFO - Started process (PID=7793) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:57,936] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:38:57,938] {logging_mixin.py:112} INFO - [2022-03-23 08:38:57,937] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:57,998] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:38:58,006] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:58,015] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:38:58,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:38:58,319] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.395 seconds
[2022-03-23 08:39:02,103] {scheduler_job.py:153} INFO - Started process (PID=7798) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:02,114] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:02,116] {logging_mixin.py:112} INFO - [2022-03-23 08:39:02,116] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:02,188] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:02,200] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:02,203] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:02,229] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:04,978] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.874 seconds
[2022-03-23 08:39:08,612] {scheduler_job.py:153} INFO - Started process (PID=7807) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:08,676] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:08,818] {logging_mixin.py:112} INFO - [2022-03-23 08:39:08,818] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:08,997] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:09,030] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:09,049] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:09,086] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:09,885] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.273 seconds
[2022-03-23 08:39:10,565] {scheduler_job.py:153} INFO - Started process (PID=7812) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:10,574] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:10,579] {logging_mixin.py:112} INFO - [2022-03-23 08:39:10,579] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:10,707] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:10,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:10,741] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:10,773] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:11,020] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.455 seconds
[2022-03-23 08:39:14,262] {scheduler_job.py:153} INFO - Started process (PID=7817) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:14,269] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:14,272] {logging_mixin.py:112} INFO - [2022-03-23 08:39:14,271] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:14,315] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:14,321] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:14,324] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:14,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:14,589] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:39:18,321] {scheduler_job.py:153} INFO - Started process (PID=7822) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:18,331] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:18,333] {logging_mixin.py:112} INFO - [2022-03-23 08:39:18,332] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:18,445] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:18,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:18,456] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:18,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:18,668] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.348 seconds
[2022-03-23 08:39:22,280] {scheduler_job.py:153} INFO - Started process (PID=7827) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:22,289] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:22,294] {logging_mixin.py:112} INFO - [2022-03-23 08:39:22,293] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:22,356] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:22,371] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:22,376] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:22,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:22,625] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.345 seconds
[2022-03-23 08:39:26,282] {scheduler_job.py:153} INFO - Started process (PID=7835) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:26,288] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:26,289] {logging_mixin.py:112} INFO - [2022-03-23 08:39:26,289] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:26,318] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:26,323] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:26,326] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:26,333] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:26,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.215 seconds
[2022-03-23 08:39:30,310] {scheduler_job.py:153} INFO - Started process (PID=7840) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:30,315] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:30,317] {logging_mixin.py:112} INFO - [2022-03-23 08:39:30,317] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:30,353] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:30,358] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:30,360] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:30,369] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:30,526] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.216 seconds
[2022-03-23 08:39:34,284] {scheduler_job.py:153} INFO - Started process (PID=7845) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:34,294] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:34,295] {logging_mixin.py:112} INFO - [2022-03-23 08:39:34,295] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:34,335] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:34,340] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:34,343] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:34,354] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:34,556] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.272 seconds
[2022-03-23 08:39:38,408] {scheduler_job.py:153} INFO - Started process (PID=7853) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:38,419] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:38,425] {logging_mixin.py:112} INFO - [2022-03-23 08:39:38,425] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:38,499] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:38,504] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:38,506] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:38,516] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:38,735] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.328 seconds
[2022-03-23 08:39:42,319] {scheduler_job.py:153} INFO - Started process (PID=7858) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:42,328] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:42,329] {logging_mixin.py:112} INFO - [2022-03-23 08:39:42,329] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:42,374] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:42,379] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:42,381] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:42,397] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:42,605] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.285 seconds
[2022-03-23 08:39:46,314] {scheduler_job.py:153} INFO - Started process (PID=7864) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:46,322] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:46,325] {logging_mixin.py:112} INFO - [2022-03-23 08:39:46,325] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:46,399] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:46,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:46,411] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:46,424] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:46,667] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.353 seconds
[2022-03-23 08:39:50,368] {scheduler_job.py:153} INFO - Started process (PID=7869) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:50,378] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:50,389] {logging_mixin.py:112} INFO - [2022-03-23 08:39:50,389] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:50,441] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:50,447] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:50,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:50,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:50,914] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.546 seconds
[2022-03-23 08:39:54,899] {scheduler_job.py:153} INFO - Started process (PID=7878) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:54,907] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:54,910] {logging_mixin.py:112} INFO - [2022-03-23 08:39:54,910] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:54,960] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:54,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:54,967] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:54,978] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:55,163] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.264 seconds
[2022-03-23 08:39:58,320] {scheduler_job.py:153} INFO - Started process (PID=7898) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:58,327] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:39:58,329] {logging_mixin.py:112} INFO - [2022-03-23 08:39:58,329] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:58,358] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:39:58,362] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:58,364] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:39:58,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:39:58,528] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.208 seconds
[2022-03-23 08:40:02,337] {scheduler_job.py:153} INFO - Started process (PID=7918) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:02,345] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:02,347] {logging_mixin.py:112} INFO - [2022-03-23 08:40:02,347] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:02,381] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:02,386] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:02,389] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:02,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:02,566] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.229 seconds
[2022-03-23 08:40:06,401] {scheduler_job.py:153} INFO - Started process (PID=7923) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:06,411] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:06,415] {logging_mixin.py:112} INFO - [2022-03-23 08:40:06,415] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:06,499] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:06,511] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:06,516] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:06,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:06,726] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.325 seconds
[2022-03-23 08:40:10,360] {scheduler_job.py:153} INFO - Started process (PID=7931) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:10,369] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:10,371] {logging_mixin.py:112} INFO - [2022-03-23 08:40:10,371] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:10,397] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:10,401] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:10,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:10,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:10,562] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.202 seconds
[2022-03-23 08:40:14,359] {scheduler_job.py:153} INFO - Started process (PID=7936) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:14,370] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:14,373] {logging_mixin.py:112} INFO - [2022-03-23 08:40:14,373] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:14,415] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:14,419] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:14,422] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:14,431] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:14,597] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.239 seconds
[2022-03-23 08:40:18,405] {scheduler_job.py:153} INFO - Started process (PID=7942) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:18,412] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:18,414] {logging_mixin.py:112} INFO - [2022-03-23 08:40:18,413] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:18,451] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:18,454] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:18,456] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:18,464] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:18,640] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.236 seconds
[2022-03-23 08:40:22,416] {scheduler_job.py:153} INFO - Started process (PID=7947) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:22,428] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:22,431] {logging_mixin.py:112} INFO - [2022-03-23 08:40:22,431] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:22,503] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:22,510] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:22,512] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:22,522] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:22,747] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.331 seconds
[2022-03-23 08:40:26,405] {scheduler_job.py:153} INFO - Started process (PID=7955) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:26,422] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:26,434] {logging_mixin.py:112} INFO - [2022-03-23 08:40:26,433] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:26,488] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:26,493] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:26,508] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:26,523] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:26,901] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.495 seconds
[2022-03-23 08:40:30,431] {scheduler_job.py:153} INFO - Started process (PID=7960) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:30,438] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:30,440] {logging_mixin.py:112} INFO - [2022-03-23 08:40:30,439] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:30,482] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:30,486] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:30,488] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:30,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:30,701] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.271 seconds
[2022-03-23 08:40:34,455] {scheduler_job.py:153} INFO - Started process (PID=7965) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:34,468] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:34,470] {logging_mixin.py:112} INFO - [2022-03-23 08:40:34,470] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:34,526] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:34,532] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:34,535] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:34,548] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:34,952] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.497 seconds
[2022-03-23 08:40:38,411] {scheduler_job.py:153} INFO - Started process (PID=7970) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:38,429] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:38,459] {logging_mixin.py:112} INFO - [2022-03-23 08:40:38,459] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:38,569] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:38,579] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:38,582] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:38,606] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:38,950] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.539 seconds
[2022-03-23 08:40:42,499] {scheduler_job.py:153} INFO - Started process (PID=7978) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:42,509] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:42,511] {logging_mixin.py:112} INFO - [2022-03-23 08:40:42,511] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:42,638] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:42,644] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:42,648] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:42,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:42,945] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.446 seconds
[2022-03-23 08:40:46,423] {scheduler_job.py:153} INFO - Started process (PID=7983) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:46,433] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:46,435] {logging_mixin.py:112} INFO - [2022-03-23 08:40:46,435] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:46,471] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:46,477] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:46,479] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:46,489] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:46,666] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.244 seconds
[2022-03-23 08:40:50,505] {scheduler_job.py:153} INFO - Started process (PID=7989) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:50,536] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:50,539] {logging_mixin.py:112} INFO - [2022-03-23 08:40:50,538] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:50,642] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:50,649] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:50,661] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:50,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:51,000] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.494 seconds
[2022-03-23 08:40:54,511] {scheduler_job.py:153} INFO - Started process (PID=7994) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:54,525] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:54,527] {logging_mixin.py:112} INFO - [2022-03-23 08:40:54,527] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:54,601] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:54,613] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:54,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:54,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:54,961] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.450 seconds
[2022-03-23 08:40:58,462] {scheduler_job.py:153} INFO - Started process (PID=8002) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:58,472] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:40:58,475] {logging_mixin.py:112} INFO - [2022-03-23 08:40:58,474] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:58,527] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:40:58,534] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:58,536] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:40:58,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:40:58,931] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.469 seconds
[2022-03-23 08:41:02,455] {scheduler_job.py:153} INFO - Started process (PID=8007) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:02,465] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:02,467] {logging_mixin.py:112} INFO - [2022-03-23 08:41:02,466] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:02,512] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:02,517] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:02,519] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:02,530] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:02,695] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.239 seconds
[2022-03-23 08:41:06,805] {scheduler_job.py:153} INFO - Started process (PID=8012) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:06,819] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:06,832] {logging_mixin.py:112} INFO - [2022-03-23 08:41:06,832] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:06,932] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:06,940] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:06,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:06,959] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:08,156] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.351 seconds
[2022-03-23 08:41:10,454] {scheduler_job.py:153} INFO - Started process (PID=8017) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:10,465] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:10,466] {logging_mixin.py:112} INFO - [2022-03-23 08:41:10,466] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:10,513] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:10,518] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:10,521] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:10,536] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:10,849] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.394 seconds
[2022-03-23 08:41:14,617] {scheduler_job.py:153} INFO - Started process (PID=8023) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:14,638] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:14,640] {logging_mixin.py:112} INFO - [2022-03-23 08:41:14,639] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:14,801] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:14,807] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:14,811] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:14,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:15,134] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.517 seconds
[2022-03-23 08:41:18,519] {scheduler_job.py:153} INFO - Started process (PID=8030) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:18,525] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:18,527] {logging_mixin.py:112} INFO - [2022-03-23 08:41:18,527] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:18,559] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:18,565] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:18,568] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:18,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:18,904] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.385 seconds
[2022-03-23 08:41:22,462] {scheduler_job.py:153} INFO - Started process (PID=8035) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:22,468] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:22,470] {logging_mixin.py:112} INFO - [2022-03-23 08:41:22,469] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:22,498] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:22,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:22,504] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:22,512] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:22,745] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.283 seconds
[2022-03-23 08:41:26,508] {scheduler_job.py:153} INFO - Started process (PID=8041) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:26,522] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:26,537] {logging_mixin.py:112} INFO - [2022-03-23 08:41:26,537] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:26,595] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:26,604] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:26,612] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:26,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:26,988] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.474 seconds
[2022-03-23 08:41:30,639] {scheduler_job.py:153} INFO - Started process (PID=8046) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:30,646] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:30,648] {logging_mixin.py:112} INFO - [2022-03-23 08:41:30,648] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:30,703] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:30,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:30,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:30,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:30,927] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.288 seconds
[2022-03-23 08:41:34,500] {scheduler_job.py:153} INFO - Started process (PID=8051) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:34,515] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:34,518] {logging_mixin.py:112} INFO - [2022-03-23 08:41:34,517] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:34,561] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:34,565] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:34,567] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:34,579] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:34,779] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.279 seconds
[2022-03-23 08:41:38,493] {scheduler_job.py:153} INFO - Started process (PID=8059) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:38,501] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:38,504] {logging_mixin.py:112} INFO - [2022-03-23 08:41:38,504] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:38,540] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:38,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:38,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:38,558] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:38,705] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.212 seconds
[2022-03-23 08:41:42,537] {scheduler_job.py:153} INFO - Started process (PID=8064) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:42,544] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:42,545] {logging_mixin.py:112} INFO - [2022-03-23 08:41:42,545] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:42,585] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:42,590] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:42,592] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:42,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:42,835] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.298 seconds
[2022-03-23 08:41:46,501] {scheduler_job.py:153} INFO - Started process (PID=8069) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:46,516] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:46,518] {logging_mixin.py:112} INFO - [2022-03-23 08:41:46,518] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:46,564] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:46,568] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:46,571] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:46,588] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:46,855] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.355 seconds
[2022-03-23 08:41:50,896] {scheduler_job.py:153} INFO - Started process (PID=8074) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:50,911] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:50,922] {logging_mixin.py:112} INFO - [2022-03-23 08:41:50,918] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:50,981] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:50,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:50,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:51,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:51,378] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.483 seconds
[2022-03-23 08:41:54,564] {scheduler_job.py:153} INFO - Started process (PID=8082) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:54,572] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:54,573] {logging_mixin.py:112} INFO - [2022-03-23 08:41:54,573] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:54,610] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:54,615] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:54,620] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:54,636] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:54,829] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.266 seconds
[2022-03-23 08:41:58,532] {scheduler_job.py:153} INFO - Started process (PID=8088) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:58,541] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:41:58,543] {logging_mixin.py:112} INFO - [2022-03-23 08:41:58,543] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:58,591] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:41:58,597] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:58,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:41:58,613] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:41:58,862] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.331 seconds
[2022-03-23 08:42:03,138] {scheduler_job.py:153} INFO - Started process (PID=8093) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:03,148] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:03,150] {logging_mixin.py:112} INFO - [2022-03-23 08:42:03,150] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:03,197] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:03,201] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:03,204] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:03,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:03,895] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.757 seconds
[2022-03-23 08:42:06,930] {scheduler_job.py:153} INFO - Started process (PID=8098) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:06,938] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:06,939] {logging_mixin.py:112} INFO - [2022-03-23 08:42:06,939] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:06,991] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:06,998] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:07,000] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:07,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:07,269] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.339 seconds
[2022-03-23 08:42:10,913] {scheduler_job.py:153} INFO - Started process (PID=8106) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:10,919] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:10,920] {logging_mixin.py:112} INFO - [2022-03-23 08:42:10,920] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:10,950] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:10,955] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:10,957] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:10,965] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:11,165] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.252 seconds
[2022-03-23 08:42:14,931] {scheduler_job.py:153} INFO - Started process (PID=8111) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:14,937] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:14,939] {logging_mixin.py:112} INFO - [2022-03-23 08:42:14,939] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:14,967] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:14,971] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:14,974] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:14,983] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:15,154] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.222 seconds
[2022-03-23 08:42:18,961] {scheduler_job.py:153} INFO - Started process (PID=8116) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:18,976] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:18,978] {logging_mixin.py:112} INFO - [2022-03-23 08:42:18,978] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:19,187] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:19,195] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:19,201] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:19,215] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:19,505] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.544 seconds
[2022-03-23 08:42:22,931] {scheduler_job.py:153} INFO - Started process (PID=8124) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:22,937] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:22,938] {logging_mixin.py:112} INFO - [2022-03-23 08:42:22,938] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:22,969] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:22,975] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:22,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:22,992] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:23,262] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.332 seconds
[2022-03-23 08:42:27,014] {scheduler_job.py:153} INFO - Started process (PID=8129) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:27,033] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:27,038] {logging_mixin.py:112} INFO - [2022-03-23 08:42:27,038] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:27,300] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:27,328] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:27,332] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:27,382] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:27,796] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.782 seconds
[2022-03-23 08:42:30,978] {scheduler_job.py:153} INFO - Started process (PID=8134) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:30,983] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:30,984] {logging_mixin.py:112} INFO - [2022-03-23 08:42:30,984] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:31,029] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:31,034] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:31,036] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:31,050] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:31,252] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.274 seconds
[2022-03-23 08:42:34,968] {scheduler_job.py:153} INFO - Started process (PID=8140) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:34,975] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:34,976] {logging_mixin.py:112} INFO - [2022-03-23 08:42:34,976] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:35,018] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:35,022] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:35,025] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:35,035] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:35,198] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.230 seconds
[2022-03-23 08:42:38,969] {scheduler_job.py:153} INFO - Started process (PID=8145) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:38,978] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:38,979] {logging_mixin.py:112} INFO - [2022-03-23 08:42:38,979] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:39,072] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:39,082] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:39,084] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:39,095] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:39,368] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.399 seconds
[2022-03-23 08:42:43,016] {scheduler_job.py:153} INFO - Started process (PID=8153) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:43,024] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:43,026] {logging_mixin.py:112} INFO - [2022-03-23 08:42:43,026] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:43,174] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:43,180] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:43,185] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:43,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:43,554] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.538 seconds
[2022-03-23 08:42:46,990] {scheduler_job.py:153} INFO - Started process (PID=8158) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:46,996] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:46,998] {logging_mixin.py:112} INFO - [2022-03-23 08:42:46,997] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:47,027] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:47,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:47,032] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:47,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:47,214] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.225 seconds
[2022-03-23 08:42:50,988] {scheduler_job.py:153} INFO - Started process (PID=8163) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:51,000] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:51,007] {logging_mixin.py:112} INFO - [2022-03-23 08:42:51,006] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:51,047] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:51,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:51,053] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:51,066] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:51,284] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.297 seconds
[2022-03-23 08:42:55,089] {scheduler_job.py:153} INFO - Started process (PID=8168) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:55,115] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:55,120] {logging_mixin.py:112} INFO - [2022-03-23 08:42:55,120] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:55,256] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:55,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:55,267] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:55,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:55,515] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.426 seconds
[2022-03-23 08:42:59,007] {scheduler_job.py:153} INFO - Started process (PID=8176) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:59,015] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:42:59,017] {logging_mixin.py:112} INFO - [2022-03-23 08:42:59,017] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:59,050] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:42:59,055] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:59,058] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:42:59,068] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:42:59,243] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.236 seconds
[2022-03-23 08:43:03,017] {scheduler_job.py:153} INFO - Started process (PID=8181) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:03,024] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:03,026] {logging_mixin.py:112} INFO - [2022-03-23 08:43:03,026] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:03,056] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:03,061] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:03,063] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:03,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:03,245] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.228 seconds
[2022-03-23 08:43:07,054] {scheduler_job.py:153} INFO - Started process (PID=8187) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:07,066] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:07,068] {logging_mixin.py:112} INFO - [2022-03-23 08:43:07,067] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:07,262] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:07,269] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:07,282] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:07,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:07,535] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.482 seconds
[2022-03-23 08:43:11,038] {scheduler_job.py:153} INFO - Started process (PID=8192) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:11,044] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:11,046] {logging_mixin.py:112} INFO - [2022-03-23 08:43:11,046] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:11,072] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:11,076] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:11,078] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:11,089] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:11,281] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.244 seconds
[2022-03-23 08:43:15,319] {scheduler_job.py:153} INFO - Started process (PID=8201) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:15,344] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:15,354] {logging_mixin.py:112} INFO - [2022-03-23 08:43:15,354] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:15,467] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:15,473] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:15,479] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:15,491] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:15,703] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.384 seconds
[2022-03-23 08:43:19,053] {scheduler_job.py:153} INFO - Started process (PID=8206) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:19,061] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:19,062] {logging_mixin.py:112} INFO - [2022-03-23 08:43:19,062] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:19,097] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:19,101] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:19,103] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:19,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:19,487] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-03-23 08:43:23,099] {scheduler_job.py:153} INFO - Started process (PID=8211) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:23,112] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:23,115] {logging_mixin.py:112} INFO - [2022-03-23 08:43:23,115] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:23,255] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:23,261] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:23,266] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:23,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:23,593] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.495 seconds
[2022-03-23 08:43:27,088] {scheduler_job.py:153} INFO - Started process (PID=8219) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:27,095] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:27,097] {logging_mixin.py:112} INFO - [2022-03-23 08:43:27,097] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:27,140] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:27,147] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:27,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:27,161] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:27,355] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.268 seconds
[2022-03-23 08:43:31,078] {scheduler_job.py:153} INFO - Started process (PID=8224) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:31,083] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:31,085] {logging_mixin.py:112} INFO - [2022-03-23 08:43:31,085] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:31,132] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:31,137] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:31,139] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:31,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:31,351] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.273 seconds
[2022-03-23 08:43:35,068] {scheduler_job.py:153} INFO - Started process (PID=8229) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:35,077] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:35,078] {logging_mixin.py:112} INFO - [2022-03-23 08:43:35,078] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:35,112] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:35,117] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:35,119] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:35,133] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:35,467] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.399 seconds
[2022-03-23 08:43:39,169] {scheduler_job.py:153} INFO - Started process (PID=8235) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:39,180] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:39,188] {logging_mixin.py:112} INFO - [2022-03-23 08:43:39,187] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:39,241] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:39,246] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:39,258] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:39,279] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:39,622] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-03-23 08:43:43,133] {scheduler_job.py:153} INFO - Started process (PID=8243) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:43,149] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:43,183] {logging_mixin.py:112} INFO - [2022-03-23 08:43:43,182] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:43,257] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:43,275] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:43,288] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:43,357] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:43,722] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.589 seconds
[2022-03-23 08:43:47,106] {scheduler_job.py:153} INFO - Started process (PID=8248) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:47,115] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:47,117] {logging_mixin.py:112} INFO - [2022-03-23 08:43:47,117] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:47,149] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:47,153] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:47,155] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:47,164] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:47,318] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.213 seconds
[2022-03-23 08:43:51,150] {scheduler_job.py:153} INFO - Started process (PID=8253) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:51,158] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:51,160] {logging_mixin.py:112} INFO - [2022-03-23 08:43:51,159] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:51,247] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:51,253] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:51,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:51,288] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:51,572] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.422 seconds
[2022-03-23 08:43:55,164] {scheduler_job.py:153} INFO - Started process (PID=8259) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:55,173] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:55,176] {logging_mixin.py:112} INFO - [2022-03-23 08:43:55,175] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:55,288] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:55,293] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:55,295] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:55,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:55,636] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.472 seconds
[2022-03-23 08:43:59,204] {scheduler_job.py:153} INFO - Started process (PID=8283) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:59,216] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:43:59,218] {logging_mixin.py:112} INFO - [2022-03-23 08:43:59,218] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:59,273] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:43:59,284] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:59,287] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:43:59,297] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:43:59,525] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.322 seconds
[2022-03-23 08:44:03,155] {scheduler_job.py:153} INFO - Started process (PID=8306) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:03,163] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:03,164] {logging_mixin.py:112} INFO - [2022-03-23 08:44:03,164] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:03,206] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:03,212] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:03,216] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:03,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:03,455] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.301 seconds
[2022-03-23 08:44:08,010] {scheduler_job.py:153} INFO - Started process (PID=8311) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:08,029] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:08,069] {logging_mixin.py:112} INFO - [2022-03-23 08:44:08,069] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:08,340] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:08,350] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:08,353] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:08,372] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:08,674] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.664 seconds
[2022-03-23 08:44:11,561] {scheduler_job.py:153} INFO - Started process (PID=8316) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:11,573] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:11,581] {logging_mixin.py:112} INFO - [2022-03-23 08:44:11,581] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:11,655] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:11,661] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:11,674] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:12,046] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:12,859] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.298 seconds
[2022-03-23 08:44:16,660] {scheduler_job.py:153} INFO - Started process (PID=8322) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:16,696] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:16,738] {logging_mixin.py:112} INFO - [2022-03-23 08:44:16,738] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:16,828] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:16,848] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:16,851] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:16,879] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:17,484] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.825 seconds
[2022-03-23 08:44:19,573] {scheduler_job.py:153} INFO - Started process (PID=8330) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:19,589] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:19,602] {logging_mixin.py:112} INFO - [2022-03-23 08:44:19,601] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:20,114] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:20,133] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:20,136] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:20,161] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:20,495] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.923 seconds
[2022-03-23 08:44:23,553] {scheduler_job.py:153} INFO - Started process (PID=8335) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:23,562] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:23,564] {logging_mixin.py:112} INFO - [2022-03-23 08:44:23,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:23,600] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:23,609] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:23,611] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:23,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:23,801] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.248 seconds
[2022-03-23 08:44:27,624] {scheduler_job.py:153} INFO - Started process (PID=8340) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:27,646] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:27,652] {logging_mixin.py:112} INFO - [2022-03-23 08:44:27,652] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:27,722] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:27,739] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:27,744] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:27,784] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:28,227] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.604 seconds
[2022-03-23 08:44:31,622] {scheduler_job.py:153} INFO - Started process (PID=8345) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:31,632] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:31,639] {logging_mixin.py:112} INFO - [2022-03-23 08:44:31,638] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:31,833] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:31,855] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:31,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:31,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:32,215] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.593 seconds
[2022-03-23 08:44:35,586] {scheduler_job.py:153} INFO - Started process (PID=8350) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:35,595] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:35,615] {logging_mixin.py:112} INFO - [2022-03-23 08:44:35,614] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:35,673] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:35,689] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:35,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:35,720] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:36,336] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.751 seconds
[2022-03-23 08:44:39,584] {scheduler_job.py:153} INFO - Started process (PID=8358) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:39,592] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:39,594] {logging_mixin.py:112} INFO - [2022-03-23 08:44:39,594] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:39,654] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:39,683] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:39,686] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:39,712] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:39,954] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.370 seconds
[2022-03-23 08:44:43,649] {scheduler_job.py:153} INFO - Started process (PID=8363) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:43,658] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:43,660] {logging_mixin.py:112} INFO - [2022-03-23 08:44:43,659] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:43,722] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:43,737] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:43,740] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:43,771] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:44,049] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.401 seconds
[2022-03-23 08:44:47,577] {scheduler_job.py:153} INFO - Started process (PID=8369) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:47,583] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:47,584] {logging_mixin.py:112} INFO - [2022-03-23 08:44:47,584] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:47,612] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:47,619] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:47,621] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:47,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:47,770] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.194 seconds
[2022-03-23 08:44:51,622] {scheduler_job.py:153} INFO - Started process (PID=8374) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:51,643] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:51,645] {logging_mixin.py:112} INFO - [2022-03-23 08:44:51,644] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:51,703] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:51,714] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:51,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:51,753] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:52,061] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.439 seconds
[2022-03-23 08:44:55,613] {scheduler_job.py:153} INFO - Started process (PID=8382) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:55,619] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:55,654] {logging_mixin.py:112} INFO - [2022-03-23 08:44:55,653] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:55,711] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:55,718] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:55,720] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:55,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:55,960] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.347 seconds
[2022-03-23 08:44:59,634] {scheduler_job.py:153} INFO - Started process (PID=8387) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:59,655] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:44:59,657] {logging_mixin.py:112} INFO - [2022-03-23 08:44:59,656] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:59,712] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:44:59,723] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:59,725] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:44:59,738] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:44:59,977] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.344 seconds
[2022-03-23 08:45:03,731] {scheduler_job.py:153} INFO - Started process (PID=8392) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:03,745] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:03,747] {logging_mixin.py:112} INFO - [2022-03-23 08:45:03,747] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:03,803] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:03,820] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:03,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:03,841] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:04,093] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.363 seconds
[2022-03-23 08:45:07,779] {scheduler_job.py:153} INFO - Started process (PID=8397) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:07,828] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:07,831] {logging_mixin.py:112} INFO - [2022-03-23 08:45:07,831] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:08,018] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:08,028] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:08,033] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:08,050] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:08,278] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.501 seconds
[2022-03-23 08:45:11,766] {scheduler_job.py:153} INFO - Started process (PID=8402) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:11,773] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:11,775] {logging_mixin.py:112} INFO - [2022-03-23 08:45:11,775] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:11,814] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:11,822] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:11,825] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:11,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:12,031] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.265 seconds
[2022-03-23 08:45:15,775] {scheduler_job.py:153} INFO - Started process (PID=8407) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:15,790] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:15,805] {logging_mixin.py:112} INFO - [2022-03-23 08:45:15,805] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:15,906] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:15,931] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:15,934] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:15,966] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:16,482] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.707 seconds
[2022-03-23 08:45:19,805] {scheduler_job.py:153} INFO - Started process (PID=8416) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:19,854] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:19,870] {logging_mixin.py:112} INFO - [2022-03-23 08:45:19,869] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:19,961] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:19,975] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:20,006] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:20,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:20,361] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.556 seconds
[2022-03-23 08:45:23,867] {scheduler_job.py:153} INFO - Started process (PID=8421) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:23,883] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:23,885] {logging_mixin.py:112} INFO - [2022-03-23 08:45:23,885] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:23,964] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:23,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:23,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:23,998] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:24,395] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.528 seconds
[2022-03-23 08:45:27,756] {scheduler_job.py:153} INFO - Started process (PID=8426) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:27,766] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:27,767] {logging_mixin.py:112} INFO - [2022-03-23 08:45:27,767] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:27,816] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:27,827] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:27,830] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:27,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:28,069] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-03-23 08:45:31,850] {scheduler_job.py:153} INFO - Started process (PID=8431) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:31,872] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:31,874] {logging_mixin.py:112} INFO - [2022-03-23 08:45:31,874] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:31,939] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:31,953] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:31,956] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:31,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:32,303] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-03-23 08:45:36,429] {scheduler_job.py:153} INFO - Started process (PID=8436) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:36,497] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:36,513] {logging_mixin.py:112} INFO - [2022-03-23 08:45:36,513] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:36,918] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:36,936] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:36,948] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:37,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:37,404] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.975 seconds
[2022-03-23 08:45:40,191] {scheduler_job.py:153} INFO - Started process (PID=8441) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:40,286] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:40,306] {logging_mixin.py:112} INFO - [2022-03-23 08:45:40,306] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:40,680] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:40,723] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:40,734] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:40,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:41,512] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.322 seconds
[2022-03-23 08:45:44,083] {scheduler_job.py:153} INFO - Started process (PID=8449) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:44,093] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:44,105] {logging_mixin.py:112} INFO - [2022-03-23 08:45:44,102] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:44,201] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:44,210] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:44,214] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:44,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:45,220] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.138 seconds
[2022-03-23 08:45:48,252] {scheduler_job.py:153} INFO - Started process (PID=8454) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:48,296] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:48,298] {logging_mixin.py:112} INFO - [2022-03-23 08:45:48,298] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:48,450] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:48,480] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:48,501] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:48,550] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:50,076] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.823 seconds
[2022-03-23 08:45:52,175] {scheduler_job.py:153} INFO - Started process (PID=8459) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:52,215] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:52,230] {logging_mixin.py:112} INFO - [2022-03-23 08:45:52,230] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:52,340] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:52,368] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:52,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:52,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:53,172] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.998 seconds
[2022-03-23 08:45:56,156] {scheduler_job.py:153} INFO - Started process (PID=8465) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:56,180] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:45:56,184] {logging_mixin.py:112} INFO - [2022-03-23 08:45:56,183] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:57,878] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:45:57,936] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:57,970] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:45:58,033] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:45:59,562] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.407 seconds
[2022-03-23 08:46:02,515] {scheduler_job.py:153} INFO - Started process (PID=8473) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:02,577] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:02,608] {logging_mixin.py:112} INFO - [2022-03-23 08:46:02,608] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:03,781] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:03,827] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:03,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:03,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:04,762] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.247 seconds
[2022-03-23 08:46:06,222] {scheduler_job.py:153} INFO - Started process (PID=8478) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:06,242] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:06,252] {logging_mixin.py:112} INFO - [2022-03-23 08:46:06,252] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:06,401] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:06,438] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:06,442] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:06,493] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:06,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.757 seconds
[2022-03-23 08:46:09,381] {scheduler_job.py:153} INFO - Started process (PID=8483) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:09,404] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:09,420] {logging_mixin.py:112} INFO - [2022-03-23 08:46:09,420] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:09,590] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:09,600] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:09,603] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:09,619] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:09,953] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.572 seconds
[2022-03-23 08:46:13,275] {scheduler_job.py:153} INFO - Started process (PID=8488) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:13,289] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:13,291] {logging_mixin.py:112} INFO - [2022-03-23 08:46:13,291] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:13,350] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:13,361] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:13,364] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:13,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:13,750] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.476 seconds
[2022-03-23 08:46:17,262] {scheduler_job.py:153} INFO - Started process (PID=8493) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:17,267] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:17,269] {logging_mixin.py:112} INFO - [2022-03-23 08:46:17,269] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:17,311] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:17,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:17,320] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:17,330] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:17,578] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-03-23 08:46:21,318] {scheduler_job.py:153} INFO - Started process (PID=8498) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:21,334] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:21,347] {logging_mixin.py:112} INFO - [2022-03-23 08:46:21,347] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:21,446] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:21,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:21,465] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:21,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:21,906] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.588 seconds
[2022-03-23 08:46:25,293] {scheduler_job.py:153} INFO - Started process (PID=8503) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:25,302] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:25,303] {logging_mixin.py:112} INFO - [2022-03-23 08:46:25,303] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:25,388] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:25,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:25,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:25,412] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:25,704] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.412 seconds
[2022-03-23 08:46:29,291] {scheduler_job.py:153} INFO - Started process (PID=8511) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:29,302] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:29,304] {logging_mixin.py:112} INFO - [2022-03-23 08:46:29,303] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:29,352] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:29,361] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:29,365] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:29,377] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:29,597] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.306 seconds
[2022-03-23 08:46:33,311] {scheduler_job.py:153} INFO - Started process (PID=8516) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:33,322] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:33,323] {logging_mixin.py:112} INFO - [2022-03-23 08:46:33,323] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:33,354] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:33,364] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:33,367] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:33,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:33,605] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.294 seconds
[2022-03-23 08:46:37,321] {scheduler_job.py:153} INFO - Started process (PID=8522) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:37,331] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:37,332] {logging_mixin.py:112} INFO - [2022-03-23 08:46:37,332] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:37,372] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:37,384] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:37,396] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:37,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:37,669] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.348 seconds
[2022-03-23 08:46:41,320] {scheduler_job.py:153} INFO - Started process (PID=8527) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:41,327] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:41,329] {logging_mixin.py:112} INFO - [2022-03-23 08:46:41,329] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:41,360] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:41,367] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:41,369] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:41,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:41,648] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.328 seconds
[2022-03-23 08:46:45,439] {scheduler_job.py:153} INFO - Started process (PID=8532) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:45,466] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:45,471] {logging_mixin.py:112} INFO - [2022-03-23 08:46:45,470] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:45,573] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:45,588] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:45,591] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:45,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:45,854] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-03-23 08:46:49,324] {scheduler_job.py:153} INFO - Started process (PID=8540) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:49,338] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:49,339] {logging_mixin.py:112} INFO - [2022-03-23 08:46:49,339] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:49,387] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:49,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:49,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:49,412] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:49,621] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.298 seconds
[2022-03-23 08:46:53,352] {scheduler_job.py:153} INFO - Started process (PID=8545) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:53,362] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:53,367] {logging_mixin.py:112} INFO - [2022-03-23 08:46:53,366] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:53,437] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:53,450] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:53,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:53,469] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:53,786] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-03-23 08:46:57,346] {scheduler_job.py:153} INFO - Started process (PID=8550) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:57,369] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:46:57,371] {logging_mixin.py:112} INFO - [2022-03-23 08:46:57,371] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:57,422] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:46:57,434] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:57,436] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:46:57,448] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:46:57,831] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.486 seconds
[2022-03-23 08:47:01,339] {scheduler_job.py:153} INFO - Started process (PID=8555) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:01,347] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:01,349] {logging_mixin.py:112} INFO - [2022-03-23 08:47:01,349] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:01,390] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:01,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:01,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:01,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:01,638] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.299 seconds
[2022-03-23 08:47:05,354] {scheduler_job.py:153} INFO - Started process (PID=8560) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:05,363] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:05,365] {logging_mixin.py:112} INFO - [2022-03-23 08:47:05,364] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:05,413] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:05,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:05,427] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:05,443] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:05,660] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.306 seconds
[2022-03-23 08:47:09,696] {scheduler_job.py:153} INFO - Started process (PID=8569) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:09,714] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:09,722] {logging_mixin.py:112} INFO - [2022-03-23 08:47:09,722] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:09,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:09,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:09,797] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:09,816] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:10,134] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.439 seconds
[2022-03-23 08:47:13,479] {scheduler_job.py:153} INFO - Started process (PID=8574) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:13,489] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:13,493] {logging_mixin.py:112} INFO - [2022-03-23 08:47:13,492] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:13,578] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:13,603] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:13,618] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:13,656] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:13,937] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.459 seconds
[2022-03-23 08:47:17,388] {scheduler_job.py:153} INFO - Started process (PID=8579) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:17,398] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:17,399] {logging_mixin.py:112} INFO - [2022-03-23 08:47:17,399] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:17,455] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:17,482] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:17,489] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:17,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:17,740] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.352 seconds
[2022-03-23 08:47:21,410] {scheduler_job.py:153} INFO - Started process (PID=8584) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:21,431] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:21,433] {logging_mixin.py:112} INFO - [2022-03-23 08:47:21,433] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:21,512] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:21,531] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:21,544] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:21,567] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:21,875] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.465 seconds
[2022-03-23 08:47:25,455] {scheduler_job.py:153} INFO - Started process (PID=8589) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:25,474] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:25,479] {logging_mixin.py:112} INFO - [2022-03-23 08:47:25,479] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:25,627] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:25,646] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:25,649] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:25,674] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:26,083] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.627 seconds
[2022-03-23 08:47:29,415] {scheduler_job.py:153} INFO - Started process (PID=8597) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:29,422] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:29,424] {logging_mixin.py:112} INFO - [2022-03-23 08:47:29,424] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:29,473] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:29,480] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:29,483] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:29,492] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:29,661] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.246 seconds
[2022-03-23 08:47:33,469] {scheduler_job.py:153} INFO - Started process (PID=8602) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:33,477] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:33,478] {logging_mixin.py:112} INFO - [2022-03-23 08:47:33,478] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:33,520] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:33,527] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:33,529] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:33,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:33,775] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.307 seconds
[2022-03-23 08:47:37,410] {scheduler_job.py:153} INFO - Started process (PID=8607) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:37,420] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:37,422] {logging_mixin.py:112} INFO - [2022-03-23 08:47:37,422] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:37,472] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:37,484] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:37,487] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:37,503] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:37,802] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.392 seconds
[2022-03-23 08:47:41,528] {scheduler_job.py:153} INFO - Started process (PID=8612) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:41,549] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:41,551] {logging_mixin.py:112} INFO - [2022-03-23 08:47:41,551] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:41,672] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:41,701] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:41,718] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:41,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:42,405] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.877 seconds
[2022-03-23 08:47:46,420] {scheduler_job.py:153} INFO - Started process (PID=8618) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:46,446] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:46,454] {logging_mixin.py:112} INFO - [2022-03-23 08:47:46,454] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:46,519] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:46,532] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:46,551] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:46,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:48,652] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.232 seconds
[2022-03-23 08:47:49,556] {scheduler_job.py:153} INFO - Started process (PID=8623) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:49,579] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:49,587] {logging_mixin.py:112} INFO - [2022-03-23 08:47:49,587] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:49,723] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:49,744] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:49,755] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:49,785] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:51,203] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.648 seconds
[2022-03-23 08:47:53,615] {scheduler_job.py:153} INFO - Started process (PID=8629) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:53,679] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:53,915] {logging_mixin.py:112} INFO - [2022-03-23 08:47:53,915] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:54,734] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:54,751] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:54,766] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:54,791] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:55,219] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.603 seconds
[2022-03-23 08:47:58,090] {scheduler_job.py:153} INFO - Started process (PID=8636) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:58,122] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:47:58,137] {logging_mixin.py:112} INFO - [2022-03-23 08:47:58,137] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:58,371] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:47:58,393] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:58,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:47:58,418] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:47:58,800] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.711 seconds
[2022-03-23 08:48:01,884] {scheduler_job.py:153} INFO - Started process (PID=8641) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:01,911] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:01,922] {logging_mixin.py:112} INFO - [2022-03-23 08:48:01,921] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:02,232] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:02,278] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:02,300] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:02,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:03,482] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.598 seconds
[2022-03-23 08:48:05,655] {scheduler_job.py:153} INFO - Started process (PID=8646) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:05,673] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:05,683] {logging_mixin.py:112} INFO - [2022-03-23 08:48:05,683] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:05,748] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:05,762] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:05,765] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:05,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:06,122] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.468 seconds
[2022-03-23 08:48:09,678] {scheduler_job.py:153} INFO - Started process (PID=8651) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:09,693] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:09,695] {logging_mixin.py:112} INFO - [2022-03-23 08:48:09,695] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:09,752] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:09,772] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:09,776] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:09,789] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:10,052] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.374 seconds
[2022-03-23 08:48:13,630] {scheduler_job.py:153} INFO - Started process (PID=8656) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:13,638] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:13,640] {logging_mixin.py:112} INFO - [2022-03-23 08:48:13,640] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:13,695] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:13,704] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:13,709] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:13,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:13,994] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.364 seconds
[2022-03-23 08:48:17,620] {scheduler_job.py:153} INFO - Started process (PID=8661) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:17,627] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:17,628] {logging_mixin.py:112} INFO - [2022-03-23 08:48:17,628] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:17,660] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:17,668] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:17,671] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:17,681] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:17,907] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.287 seconds
[2022-03-23 08:48:21,780] {scheduler_job.py:153} INFO - Started process (PID=8670) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:21,803] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:21,807] {logging_mixin.py:112} INFO - [2022-03-23 08:48:21,806] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:21,901] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:21,916] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:21,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:21,965] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:22,248] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.469 seconds
[2022-03-23 08:48:25,716] {scheduler_job.py:153} INFO - Started process (PID=8675) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:25,723] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:25,737] {logging_mixin.py:112} INFO - [2022-03-23 08:48:25,737] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:25,883] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:25,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:25,923] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:26,020] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:26,513] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.801 seconds
[2022-03-23 08:48:29,666] {scheduler_job.py:153} INFO - Started process (PID=8680) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:29,678] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:29,680] {logging_mixin.py:112} INFO - [2022-03-23 08:48:29,680] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:29,766] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:29,779] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:29,782] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:29,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:31,091] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.425 seconds
[2022-03-23 08:48:33,738] {scheduler_job.py:153} INFO - Started process (PID=8685) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:33,755] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:33,756] {logging_mixin.py:112} INFO - [2022-03-23 08:48:33,756] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:33,822] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:33,834] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:33,838] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:33,857] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:34,064] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:48:37,673] {scheduler_job.py:153} INFO - Started process (PID=8690) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:37,682] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:37,684] {logging_mixin.py:112} INFO - [2022-03-23 08:48:37,683] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:37,721] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:37,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:37,732] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:37,740] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:37,950] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.277 seconds
[2022-03-23 08:48:41,678] {scheduler_job.py:153} INFO - Started process (PID=8695) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:41,686] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:41,687] {logging_mixin.py:112} INFO - [2022-03-23 08:48:41,687] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:41,749] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:41,756] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:41,763] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:41,780] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:42,108] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.430 seconds
[2022-03-23 08:48:45,769] {scheduler_job.py:153} INFO - Started process (PID=8703) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:45,778] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:45,780] {logging_mixin.py:112} INFO - [2022-03-23 08:48:45,780] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:45,865] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:45,884] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:45,895] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:45,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:46,245] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.477 seconds
[2022-03-23 08:48:49,703] {scheduler_job.py:153} INFO - Started process (PID=8708) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:49,712] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:49,715] {logging_mixin.py:112} INFO - [2022-03-23 08:48:49,715] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:49,803] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:49,829] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:49,835] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:49,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:50,020] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.318 seconds
[2022-03-23 08:48:53,754] {scheduler_job.py:153} INFO - Started process (PID=8714) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:53,765] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:53,782] {logging_mixin.py:112} INFO - [2022-03-23 08:48:53,781] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:53,865] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:53,874] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:53,883] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:53,918] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:54,417] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.664 seconds
[2022-03-23 08:48:58,186] {scheduler_job.py:153} INFO - Started process (PID=8719) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:58,197] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:48:58,200] {logging_mixin.py:112} INFO - [2022-03-23 08:48:58,200] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:58,417] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:48:58,437] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:58,442] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:48:58,515] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:48:59,303] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.117 seconds
[2022-03-23 08:49:01,721] {scheduler_job.py:153} INFO - Started process (PID=8724) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:01,756] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:01,758] {logging_mixin.py:112} INFO - [2022-03-23 08:49:01,757] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:01,835] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:01,846] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:01,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:01,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:02,143] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.422 seconds
[2022-03-23 08:49:05,743] {scheduler_job.py:153} INFO - Started process (PID=8729) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:05,793] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:05,817] {logging_mixin.py:112} INFO - [2022-03-23 08:49:05,817] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:05,889] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:05,913] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:05,916] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:05,952] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:06,315] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.572 seconds
[2022-03-23 08:49:09,919] {scheduler_job.py:153} INFO - Started process (PID=8734) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:09,966] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:09,996] {logging_mixin.py:112} INFO - [2022-03-23 08:49:09,996] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:10,201] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:10,214] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:10,239] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:10,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:10,698] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.780 seconds
[2022-03-23 08:49:13,777] {scheduler_job.py:153} INFO - Started process (PID=8742) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:13,784] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:13,797] {logging_mixin.py:112} INFO - [2022-03-23 08:49:13,797] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:13,868] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:13,888] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:13,893] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:13,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:14,234] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.457 seconds
[2022-03-23 08:49:17,743] {scheduler_job.py:153} INFO - Started process (PID=8747) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:17,752] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:17,754] {logging_mixin.py:112} INFO - [2022-03-23 08:49:17,754] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:17,812] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:17,825] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:17,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:17,841] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:18,055] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.311 seconds
[2022-03-23 08:49:21,779] {scheduler_job.py:153} INFO - Started process (PID=8752) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:21,786] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:21,789] {logging_mixin.py:112} INFO - [2022-03-23 08:49:21,788] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:21,819] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:21,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:21,828] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:21,838] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:22,061] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.282 seconds
[2022-03-23 08:49:25,768] {scheduler_job.py:153} INFO - Started process (PID=8757) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:25,781] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:25,783] {logging_mixin.py:112} INFO - [2022-03-23 08:49:25,782] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:25,843] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:25,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:25,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:25,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:26,034] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.266 seconds
[2022-03-23 08:49:29,788] {scheduler_job.py:153} INFO - Started process (PID=8763) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:29,804] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:29,813] {logging_mixin.py:112} INFO - [2022-03-23 08:49:29,813] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:30,168] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:30,191] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:30,201] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:30,223] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:30,582] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.795 seconds
[2022-03-23 08:49:34,533] {scheduler_job.py:153} INFO - Started process (PID=8771) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:34,545] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:34,553] {logging_mixin.py:112} INFO - [2022-03-23 08:49:34,553] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:34,731] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:34,746] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:34,750] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:34,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:34,986] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-03-23 08:49:37,998] {scheduler_job.py:153} INFO - Started process (PID=8776) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:38,006] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:38,008] {logging_mixin.py:112} INFO - [2022-03-23 08:49:38,008] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:38,078] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:38,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:38,096] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:38,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:38,421] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.425 seconds
[2022-03-23 08:49:41,875] {scheduler_job.py:153} INFO - Started process (PID=8781) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:41,891] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:41,896] {logging_mixin.py:112} INFO - [2022-03-23 08:49:41,896] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:41,979] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:41,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:42,002] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:42,023] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:42,662] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.787 seconds
[2022-03-23 08:49:47,118] {scheduler_job.py:153} INFO - Started process (PID=8786) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:47,133] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:47,135] {logging_mixin.py:112} INFO - [2022-03-23 08:49:47,135] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:47,262] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:47,272] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:47,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:47,303] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:48,098] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.980 seconds
[2022-03-23 08:49:51,161] {scheduler_job.py:153} INFO - Started process (PID=8791) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:51,179] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:51,181] {logging_mixin.py:112} INFO - [2022-03-23 08:49:51,181] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:51,335] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:51,354] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:51,358] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:51,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:52,228] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.067 seconds
[2022-03-23 08:49:55,386] {scheduler_job.py:153} INFO - Started process (PID=8799) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:55,404] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:55,414] {logging_mixin.py:112} INFO - [2022-03-23 08:49:55,406] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:55,490] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:55,501] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:55,505] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:55,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:55,882] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.496 seconds
[2022-03-23 08:49:59,225] {scheduler_job.py:153} INFO - Started process (PID=8804) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:59,261] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:49:59,263] {logging_mixin.py:112} INFO - [2022-03-23 08:49:59,262] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:59,300] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:49:59,310] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:59,321] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:49:59,342] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:49:59,718] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.493 seconds
[2022-03-23 08:50:03,245] {scheduler_job.py:153} INFO - Started process (PID=8810) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:03,253] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:03,255] {logging_mixin.py:112} INFO - [2022-03-23 08:50:03,255] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:03,314] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:03,322] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:03,326] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:03,338] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:03,571] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.325 seconds
[2022-03-23 08:50:07,235] {scheduler_job.py:153} INFO - Started process (PID=8815) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:07,245] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:07,247] {logging_mixin.py:112} INFO - [2022-03-23 08:50:07,247] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:07,280] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:07,287] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:07,289] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:07,298] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:07,463] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.228 seconds
[2022-03-23 08:50:11,243] {scheduler_job.py:153} INFO - Started process (PID=8820) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:11,255] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:11,257] {logging_mixin.py:112} INFO - [2022-03-23 08:50:11,256] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:11,304] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:11,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:11,317] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:11,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:11,563] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-03-23 08:50:15,258] {scheduler_job.py:153} INFO - Started process (PID=8825) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:15,275] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:15,281] {logging_mixin.py:112} INFO - [2022-03-23 08:50:15,281] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:15,357] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:15,380] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:15,382] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:15,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:16,652] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.394 seconds
[2022-03-23 08:50:19,307] {scheduler_job.py:153} INFO - Started process (PID=8833) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:19,322] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:19,323] {logging_mixin.py:112} INFO - [2022-03-23 08:50:19,323] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:19,401] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:19,420] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:19,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:19,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:20,099] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.794 seconds
[2022-03-23 08:50:23,261] {scheduler_job.py:153} INFO - Started process (PID=8838) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:23,275] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:23,278] {logging_mixin.py:112} INFO - [2022-03-23 08:50:23,278] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:23,322] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:23,334] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:23,337] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:23,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:23,608] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.347 seconds
[2022-03-23 08:50:27,256] {scheduler_job.py:153} INFO - Started process (PID=8843) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:27,272] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:27,274] {logging_mixin.py:112} INFO - [2022-03-23 08:50:27,274] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:27,317] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:27,330] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:27,333] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:27,345] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:27,533] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.277 seconds
[2022-03-23 08:50:31,269] {scheduler_job.py:153} INFO - Started process (PID=8848) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:31,279] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:31,281] {logging_mixin.py:112} INFO - [2022-03-23 08:50:31,281] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:31,324] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:31,337] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:31,340] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:31,351] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:31,582] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-03-23 08:50:35,298] {scheduler_job.py:153} INFO - Started process (PID=8854) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:35,311] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:35,326] {logging_mixin.py:112} INFO - [2022-03-23 08:50:35,326] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:35,413] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:35,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:35,425] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:35,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:35,685] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.389 seconds
[2022-03-23 08:50:39,272] {scheduler_job.py:153} INFO - Started process (PID=8859) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:39,281] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:39,285] {logging_mixin.py:112} INFO - [2022-03-23 08:50:39,284] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:39,528] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:39,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:39,539] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:39,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:39,746] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.474 seconds
[2022-03-23 08:50:43,271] {scheduler_job.py:153} INFO - Started process (PID=8867) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:43,282] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:43,284] {logging_mixin.py:112} INFO - [2022-03-23 08:50:43,283] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:43,330] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:43,339] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:43,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:43,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:43,587] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-03-23 08:50:47,327] {scheduler_job.py:153} INFO - Started process (PID=8872) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:47,342] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:47,347] {logging_mixin.py:112} INFO - [2022-03-23 08:50:47,347] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:47,597] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:47,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:47,608] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:47,633] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:48,220] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.893 seconds
[2022-03-23 08:50:51,289] {scheduler_job.py:153} INFO - Started process (PID=8877) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:51,302] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:51,304] {logging_mixin.py:112} INFO - [2022-03-23 08:50:51,304] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:51,349] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:51,366] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:51,384] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:51,406] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:51,675] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.386 seconds
[2022-03-23 08:50:55,881] {scheduler_job.py:153} INFO - Started process (PID=8882) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:55,903] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:55,929] {logging_mixin.py:112} INFO - [2022-03-23 08:50:55,929] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:56,070] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:56,154] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:56,181] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:56,282] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:56,956] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.076 seconds
[2022-03-23 08:50:59,416] {scheduler_job.py:153} INFO - Started process (PID=8887) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:59,434] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:50:59,438] {logging_mixin.py:112} INFO - [2022-03-23 08:50:59,437] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:50:59,551] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:50:59,571] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:59,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:50:59,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:00,043] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.627 seconds
[2022-03-23 08:51:03,380] {scheduler_job.py:153} INFO - Started process (PID=8892) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:03,428] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:03,437] {logging_mixin.py:112} INFO - [2022-03-23 08:51:03,436] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:03,489] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:03,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:03,505] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:03,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:03,763] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.384 seconds
[2022-03-23 08:51:09,053] {scheduler_job.py:153} INFO - Started process (PID=8901) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:09,084] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:09,097] {logging_mixin.py:112} INFO - [2022-03-23 08:51:09,096] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:09,369] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:09,401] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:09,408] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:09,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:10,551] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.499 seconds
[2022-03-23 08:51:11,453] {scheduler_job.py:153} INFO - Started process (PID=8903) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:11,469] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:11,472] {logging_mixin.py:112} INFO - [2022-03-23 08:51:11,472] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:11,528] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:11,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:11,552] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:11,570] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:11,841] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.389 seconds
[2022-03-23 08:51:15,391] {scheduler_job.py:153} INFO - Started process (PID=8908) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:15,396] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:15,398] {logging_mixin.py:112} INFO - [2022-03-23 08:51:15,398] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:15,495] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:15,519] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:15,522] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:15,541] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:15,738] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.347 seconds
[2022-03-23 08:51:20,073] {scheduler_job.py:153} INFO - Started process (PID=8916) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:20,105] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:20,109] {logging_mixin.py:112} INFO - [2022-03-23 08:51:20,109] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:21,613] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:21,633] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:21,635] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:21,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:21,948] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.876 seconds
[2022-03-23 08:51:23,408] {scheduler_job.py:153} INFO - Started process (PID=8921) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:23,416] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:23,418] {logging_mixin.py:112} INFO - [2022-03-23 08:51:23,418] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:23,449] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:23,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:23,459] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:23,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:23,710] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.302 seconds
[2022-03-23 08:51:27,402] {scheduler_job.py:153} INFO - Started process (PID=8926) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:27,409] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:27,411] {logging_mixin.py:112} INFO - [2022-03-23 08:51:27,411] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:27,443] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:27,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:27,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:27,462] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:27,626] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.224 seconds
[2022-03-23 08:51:31,451] {scheduler_job.py:153} INFO - Started process (PID=8931) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:31,459] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:31,461] {logging_mixin.py:112} INFO - [2022-03-23 08:51:31,460] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:31,492] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:31,500] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:31,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:31,511] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:31,678] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.227 seconds
[2022-03-23 08:51:35,454] {scheduler_job.py:153} INFO - Started process (PID=8936) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:35,469] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:35,473] {logging_mixin.py:112} INFO - [2022-03-23 08:51:35,473] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:35,556] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:35,573] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:35,577] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:35,598] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:35,872] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-03-23 08:51:39,421] {scheduler_job.py:153} INFO - Started process (PID=8941) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:39,430] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:39,432] {logging_mixin.py:112} INFO - [2022-03-23 08:51:39,432] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:39,485] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:39,498] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:39,500] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:39,515] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:39,770] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.350 seconds
[2022-03-23 08:51:43,585] {scheduler_job.py:153} INFO - Started process (PID=8950) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:43,597] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:43,599] {logging_mixin.py:112} INFO - [2022-03-23 08:51:43,599] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:43,667] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:43,685] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:43,687] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:43,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:44,002] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.417 seconds
[2022-03-23 08:51:47,483] {scheduler_job.py:153} INFO - Started process (PID=8955) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:47,501] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:47,503] {logging_mixin.py:112} INFO - [2022-03-23 08:51:47,503] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:47,565] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:47,577] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:47,580] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:47,592] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:47,828] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.345 seconds
[2022-03-23 08:51:51,475] {scheduler_job.py:153} INFO - Started process (PID=8960) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:51,485] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:51,487] {logging_mixin.py:112} INFO - [2022-03-23 08:51:51,486] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:51,568] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:51,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:51,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:51,594] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:51,812] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.338 seconds
[2022-03-23 08:51:55,576] {scheduler_job.py:153} INFO - Started process (PID=8965) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:55,594] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:51:55,598] {logging_mixin.py:112} INFO - [2022-03-23 08:51:55,598] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:55,681] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:51:55,700] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:55,703] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:51:55,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:51:59,292] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.716 seconds
[2022-03-23 08:52:00,528] {scheduler_job.py:153} INFO - Started process (PID=8970) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:00,535] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:00,537] {logging_mixin.py:112} INFO - [2022-03-23 08:52:00,537] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:00,594] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:00,603] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:00,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:00,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:00,966] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.438 seconds
[2022-03-23 08:52:03,439] {scheduler_job.py:153} INFO - Started process (PID=8975) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:03,445] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:03,446] {logging_mixin.py:112} INFO - [2022-03-23 08:52:03,446] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:03,477] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:03,487] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:03,489] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:03,499] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:03,674] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.235 seconds
[2022-03-23 08:52:07,481] {scheduler_job.py:153} INFO - Started process (PID=8980) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:07,488] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:07,490] {logging_mixin.py:112} INFO - [2022-03-23 08:52:07,490] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:07,533] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:07,542] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:07,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:07,605] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:08,128] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.647 seconds
[2022-03-23 08:52:11,459] {scheduler_job.py:153} INFO - Started process (PID=8988) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:11,466] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:11,468] {logging_mixin.py:112} INFO - [2022-03-23 08:52:11,467] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:11,499] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:11,506] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:11,510] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:11,519] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:11,739] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.280 seconds
[2022-03-23 08:52:15,463] {scheduler_job.py:153} INFO - Started process (PID=8993) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:15,470] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:15,472] {logging_mixin.py:112} INFO - [2022-03-23 08:52:15,472] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:15,513] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:15,522] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:15,528] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:15,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:15,713] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.251 seconds
[2022-03-23 08:52:19,572] {scheduler_job.py:153} INFO - Started process (PID=8999) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:19,589] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:19,591] {logging_mixin.py:112} INFO - [2022-03-23 08:52:19,591] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:19,644] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:19,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:19,656] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:19,669] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:19,874] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-03-23 08:52:23,495] {scheduler_job.py:153} INFO - Started process (PID=9004) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:23,503] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:23,504] {logging_mixin.py:112} INFO - [2022-03-23 08:52:23,504] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:23,535] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:23,541] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:23,543] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:23,550] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:23,823] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.329 seconds
[2022-03-23 08:52:27,549] {scheduler_job.py:153} INFO - Started process (PID=9009) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:27,555] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:27,566] {logging_mixin.py:112} INFO - [2022-03-23 08:52:27,565] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:27,617] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:27,632] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:27,635] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:27,665] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:27,894] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.345 seconds
[2022-03-23 08:52:32,188] {scheduler_job.py:153} INFO - Started process (PID=9015) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:32,273] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:32,346] {logging_mixin.py:112} INFO - [2022-03-23 08:52:32,345] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:32,441] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:32,459] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:32,462] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:32,503] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:32,896] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.717 seconds
[2022-03-23 08:52:35,688] {scheduler_job.py:153} INFO - Started process (PID=9022) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:35,702] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:35,704] {logging_mixin.py:112} INFO - [2022-03-23 08:52:35,703] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:35,821] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:35,841] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:35,848] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:35,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:36,247] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.559 seconds
[2022-03-23 08:52:39,505] {scheduler_job.py:153} INFO - Started process (PID=9027) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:39,515] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:39,517] {logging_mixin.py:112} INFO - [2022-03-23 08:52:39,517] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:39,555] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:39,564] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:39,566] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:39,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:39,808] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-03-23 08:52:43,527] {scheduler_job.py:153} INFO - Started process (PID=9032) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:43,543] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:43,546] {logging_mixin.py:112} INFO - [2022-03-23 08:52:43,546] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:43,581] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:43,588] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:43,590] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:43,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:43,771] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.244 seconds
[2022-03-23 08:52:47,503] {scheduler_job.py:153} INFO - Started process (PID=9037) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:47,512] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:47,515] {logging_mixin.py:112} INFO - [2022-03-23 08:52:47,514] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:47,548] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:47,556] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:47,561] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:47,570] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:47,770] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.267 seconds
[2022-03-23 08:52:51,511] {scheduler_job.py:153} INFO - Started process (PID=9043) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:51,520] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:51,521] {logging_mixin.py:112} INFO - [2022-03-23 08:52:51,521] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:51,570] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:51,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:51,585] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:51,595] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:51,791] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.280 seconds
[2022-03-23 08:52:55,536] {scheduler_job.py:153} INFO - Started process (PID=9048) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:55,546] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:55,548] {logging_mixin.py:112} INFO - [2022-03-23 08:52:55,548] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:55,585] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:55,594] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:55,596] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:55,606] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:55,803] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.267 seconds
[2022-03-23 08:52:59,541] {scheduler_job.py:153} INFO - Started process (PID=9056) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:59,550] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:52:59,552] {logging_mixin.py:112} INFO - [2022-03-23 08:52:59,551] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:59,603] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:52:59,613] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:59,615] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:52:59,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:52:59,822] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-03-23 08:53:03,526] {scheduler_job.py:153} INFO - Started process (PID=9061) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:03,532] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:03,534] {logging_mixin.py:112} INFO - [2022-03-23 08:53:03,534] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:03,566] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:03,573] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:03,576] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:03,584] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:03,768] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.242 seconds
[2022-03-23 08:53:07,555] {scheduler_job.py:153} INFO - Started process (PID=9066) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:07,562] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:07,564] {logging_mixin.py:112} INFO - [2022-03-23 08:53:07,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:07,594] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:07,601] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:07,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:07,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:07,761] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.206 seconds
[2022-03-23 08:53:11,553] {scheduler_job.py:153} INFO - Started process (PID=9071) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:11,563] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:11,564] {logging_mixin.py:112} INFO - [2022-03-23 08:53:11,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:11,596] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:11,604] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:11,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:11,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:11,814] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.261 seconds
[2022-03-23 08:53:15,548] {scheduler_job.py:153} INFO - Started process (PID=9076) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:15,556] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:15,560] {logging_mixin.py:112} INFO - [2022-03-23 08:53:15,560] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:15,598] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:15,606] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:15,609] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:15,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:15,789] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.241 seconds
[2022-03-23 08:53:19,584] {scheduler_job.py:153} INFO - Started process (PID=9081) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:19,591] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:19,593] {logging_mixin.py:112} INFO - [2022-03-23 08:53:19,593] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:19,649] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:19,657] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:19,661] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:19,672] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:19,904] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-03-23 08:53:23,589] {scheduler_job.py:153} INFO - Started process (PID=9090) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:23,604] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:23,607] {logging_mixin.py:112} INFO - [2022-03-23 08:53:23,606] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:23,655] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:23,665] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:23,667] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:23,678] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:24,011] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.423 seconds
[2022-03-23 08:53:27,566] {scheduler_job.py:153} INFO - Started process (PID=9095) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:27,574] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:27,577] {logging_mixin.py:112} INFO - [2022-03-23 08:53:27,577] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:27,606] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:27,613] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:27,615] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:27,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:27,816] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.250 seconds
[2022-03-23 08:53:31,593] {scheduler_job.py:153} INFO - Started process (PID=9100) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:31,603] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:31,605] {logging_mixin.py:112} INFO - [2022-03-23 08:53:31,604] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:31,637] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:31,646] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:31,648] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:31,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:31,845] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.252 seconds
[2022-03-23 08:53:35,586] {scheduler_job.py:153} INFO - Started process (PID=9105) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:35,593] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:35,595] {logging_mixin.py:112} INFO - [2022-03-23 08:53:35,594] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:35,644] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:35,652] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:35,653] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:35,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:35,915] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.329 seconds
[2022-03-23 08:53:39,577] {scheduler_job.py:153} INFO - Started process (PID=9110) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:39,584] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:39,586] {logging_mixin.py:112} INFO - [2022-03-23 08:53:39,586] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:39,622] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:39,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:39,631] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:39,640] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:39,889] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-03-23 08:53:43,640] {scheduler_job.py:153} INFO - Started process (PID=9118) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:43,653] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:43,654] {logging_mixin.py:112} INFO - [2022-03-23 08:53:43,654] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:43,716] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:43,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:43,732] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:43,749] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:43,943] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-03-23 08:53:47,599] {scheduler_job.py:153} INFO - Started process (PID=9123) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:47,611] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:47,613] {logging_mixin.py:112} INFO - [2022-03-23 08:53:47,612] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:47,644] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:47,650] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:47,652] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:47,662] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:48,067] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.467 seconds
[2022-03-23 08:53:51,598] {scheduler_job.py:153} INFO - Started process (PID=9128) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:51,603] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:51,605] {logging_mixin.py:112} INFO - [2022-03-23 08:53:51,605] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:51,636] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:51,643] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:51,645] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:51,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:51,828] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.230 seconds
[2022-03-23 08:53:55,620] {scheduler_job.py:153} INFO - Started process (PID=9133) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:55,628] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:55,630] {logging_mixin.py:112} INFO - [2022-03-23 08:53:55,630] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:55,667] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:55,675] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:55,678] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:55,687] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:55,925] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-03-23 08:53:59,614] {scheduler_job.py:153} INFO - Started process (PID=9139) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:59,620] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:53:59,622] {logging_mixin.py:112} INFO - [2022-03-23 08:53:59,621] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:59,655] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:53:59,666] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:59,668] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:53:59,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:53:59,845] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.232 seconds
[2022-03-23 08:54:03,620] {scheduler_job.py:153} INFO - Started process (PID=9147) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:03,628] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:03,629] {logging_mixin.py:112} INFO - [2022-03-23 08:54:03,629] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:03,667] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:03,675] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:03,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:03,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:03,873] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.253 seconds
[2022-03-23 08:54:07,662] {scheduler_job.py:153} INFO - Started process (PID=9152) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:07,669] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:07,670] {logging_mixin.py:112} INFO - [2022-03-23 08:54:07,670] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:07,711] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:07,719] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:07,721] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:07,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:07,913] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.251 seconds
[2022-03-23 08:54:11,622] {scheduler_job.py:153} INFO - Started process (PID=9157) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:11,632] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:11,633] {logging_mixin.py:112} INFO - [2022-03-23 08:54:11,633] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:11,668] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:11,677] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:11,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:11,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:11,927] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-03-23 08:54:15,632] {scheduler_job.py:153} INFO - Started process (PID=9162) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:15,639] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:15,640] {logging_mixin.py:112} INFO - [2022-03-23 08:54:15,640] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:15,678] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:15,686] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:15,688] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:15,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:15,871] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.238 seconds
[2022-03-23 08:54:19,676] {scheduler_job.py:153} INFO - Started process (PID=9167) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:19,683] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:19,684] {logging_mixin.py:112} INFO - [2022-03-23 08:54:19,684] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:19,719] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:19,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:19,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:19,740] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:19,911] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.236 seconds
[2022-03-23 08:54:23,646] {scheduler_job.py:153} INFO - Started process (PID=9172) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:23,656] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:23,658] {logging_mixin.py:112} INFO - [2022-03-23 08:54:23,658] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:23,761] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:23,775] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:23,779] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:23,795] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:23,985] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.340 seconds
[2022-03-23 08:54:27,639] {scheduler_job.py:153} INFO - Started process (PID=9180) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:27,647] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:27,648] {logging_mixin.py:112} INFO - [2022-03-23 08:54:27,648] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:27,695] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:27,703] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:27,705] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:27,715] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:27,954] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-03-23 08:54:32,104] {scheduler_job.py:153} INFO - Started process (PID=9186) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:32,119] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:32,127] {logging_mixin.py:112} INFO - [2022-03-23 08:54:32,127] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:32,180] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:32,204] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:32,206] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:32,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:32,420] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.317 seconds
[2022-03-23 08:54:35,666] {scheduler_job.py:153} INFO - Started process (PID=9191) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:35,675] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:35,677] {logging_mixin.py:112} INFO - [2022-03-23 08:54:35,677] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:35,711] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:35,720] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:35,722] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:35,733] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:36,088] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.423 seconds
[2022-03-23 08:54:39,662] {scheduler_job.py:153} INFO - Started process (PID=9196) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:39,668] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:39,669] {logging_mixin.py:112} INFO - [2022-03-23 08:54:39,669] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:39,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:39,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:39,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:39,718] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:39,930] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.268 seconds
[2022-03-23 08:54:43,695] {scheduler_job.py:153} INFO - Started process (PID=9201) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:43,701] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:43,702] {logging_mixin.py:112} INFO - [2022-03-23 08:54:43,702] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:43,731] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:43,737] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:43,739] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:43,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:44,001] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.306 seconds
[2022-03-23 08:54:47,747] {scheduler_job.py:153} INFO - Started process (PID=9209) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:47,765] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:47,767] {logging_mixin.py:112} INFO - [2022-03-23 08:54:47,766] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:47,873] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:47,883] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:47,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:47,915] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:48,842] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.095 seconds
[2022-03-23 08:54:51,694] {scheduler_job.py:153} INFO - Started process (PID=9214) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:51,703] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:51,704] {logging_mixin.py:112} INFO - [2022-03-23 08:54:51,704] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:51,741] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:51,749] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:51,752] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:51,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:52,046] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.353 seconds
[2022-03-23 08:54:55,717] {scheduler_job.py:153} INFO - Started process (PID=9219) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:55,725] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:55,727] {logging_mixin.py:112} INFO - [2022-03-23 08:54:55,727] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:55,766] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:55,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:55,777] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:55,791] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:55,993] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.276 seconds
[2022-03-23 08:54:59,737] {scheduler_job.py:153} INFO - Started process (PID=9224) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:59,748] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:54:59,750] {logging_mixin.py:112} INFO - [2022-03-23 08:54:59,749] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:54:59,801] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:54:59,817] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:59,828] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:54:59,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:00,406] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.669 seconds
[2022-03-23 08:55:03,693] {scheduler_job.py:153} INFO - Started process (PID=9230) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:03,700] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:03,701] {logging_mixin.py:112} INFO - [2022-03-23 08:55:03,701] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:03,739] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:03,748] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:03,750] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:03,760] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:03,960] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.267 seconds
[2022-03-23 08:55:07,739] {scheduler_job.py:153} INFO - Started process (PID=9235) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:07,746] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:07,748] {logging_mixin.py:112} INFO - [2022-03-23 08:55:07,748] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:07,785] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:07,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:07,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:07,805] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:08,001] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:55:11,720] {scheduler_job.py:153} INFO - Started process (PID=9243) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:11,726] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:11,727] {logging_mixin.py:112} INFO - [2022-03-23 08:55:11,727] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:11,771] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:11,779] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:11,783] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:11,797] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:11,996] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.277 seconds
[2022-03-23 08:55:15,716] {scheduler_job.py:153} INFO - Started process (PID=9248) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:15,721] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:15,723] {logging_mixin.py:112} INFO - [2022-03-23 08:55:15,723] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:15,765] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:15,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:15,778] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:15,788] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:15,969] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.253 seconds
[2022-03-23 08:55:19,756] {scheduler_job.py:153} INFO - Started process (PID=9253) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:19,763] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:19,764] {logging_mixin.py:112} INFO - [2022-03-23 08:55:19,764] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:19,797] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:19,804] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:19,807] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:19,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:20,000] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.244 seconds
[2022-03-23 08:55:23,746] {scheduler_job.py:153} INFO - Started process (PID=9258) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:23,754] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:23,755] {logging_mixin.py:112} INFO - [2022-03-23 08:55:23,755] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:23,788] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:23,797] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:23,801] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:23,811] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:24,037] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.291 seconds
[2022-03-23 08:55:27,728] {scheduler_job.py:153} INFO - Started process (PID=9263) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:27,735] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:27,737] {logging_mixin.py:112} INFO - [2022-03-23 08:55:27,737] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:27,772] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:27,781] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:27,784] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:27,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:27,968] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.240 seconds
[2022-03-23 08:55:31,761] {scheduler_job.py:153} INFO - Started process (PID=9271) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:31,767] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:31,769] {logging_mixin.py:112} INFO - [2022-03-23 08:55:31,769] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:31,822] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:31,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:31,835] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:31,851] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:32,037] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.276 seconds
[2022-03-23 08:55:35,769] {scheduler_job.py:153} INFO - Started process (PID=9277) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:35,787] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:35,789] {logging_mixin.py:112} INFO - [2022-03-23 08:55:35,789] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:35,847] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:35,860] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:35,864] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:35,879] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:36,134] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.365 seconds
[2022-03-23 08:55:39,743] {scheduler_job.py:153} INFO - Started process (PID=9282) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:39,749] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:39,750] {logging_mixin.py:112} INFO - [2022-03-23 08:55:39,750] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:39,789] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:39,802] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:39,808] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:39,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:40,052] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-03-23 08:55:43,840] {scheduler_job.py:153} INFO - Started process (PID=9287) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:43,850] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:43,852] {logging_mixin.py:112} INFO - [2022-03-23 08:55:43,851] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:43,889] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:43,900] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:43,903] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:43,921] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:44,166] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-03-23 08:55:47,755] {scheduler_job.py:153} INFO - Started process (PID=9292) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:47,764] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:47,766] {logging_mixin.py:112} INFO - [2022-03-23 08:55:47,765] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:47,798] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:47,805] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:47,811] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:47,821] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:48,016] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:55:51,768] {scheduler_job.py:153} INFO - Started process (PID=9300) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:51,776] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:51,780] {logging_mixin.py:112} INFO - [2022-03-23 08:55:51,779] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:51,841] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:51,853] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:51,854] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:51,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:52,071] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-03-23 08:55:55,794] {scheduler_job.py:153} INFO - Started process (PID=9305) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:55,801] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:55,802] {logging_mixin.py:112} INFO - [2022-03-23 08:55:55,802] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:55,838] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:55,847] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:55,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:55,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:56,030] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.236 seconds
[2022-03-23 08:55:59,796] {scheduler_job.py:153} INFO - Started process (PID=9310) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:59,805] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:55:59,807] {logging_mixin.py:112} INFO - [2022-03-23 08:55:59,806] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:55:59,839] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:55:59,851] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:59,854] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:55:59,864] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:00,081] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.285 seconds
[2022-03-23 08:56:03,774] {scheduler_job.py:153} INFO - Started process (PID=9315) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:03,781] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:03,782] {logging_mixin.py:112} INFO - [2022-03-23 08:56:03,782] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:03,813] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:03,821] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:03,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:03,832] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:04,031] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.257 seconds
[2022-03-23 08:56:07,817] {scheduler_job.py:153} INFO - Started process (PID=9320) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:07,823] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:07,827] {logging_mixin.py:112} INFO - [2022-03-23 08:56:07,827] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:07,869] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:07,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:07,881] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:07,891] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:08,052] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.235 seconds
[2022-03-23 08:56:11,803] {scheduler_job.py:153} INFO - Started process (PID=9326) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:11,812] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:11,814] {logging_mixin.py:112} INFO - [2022-03-23 08:56:11,814] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:11,880] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:11,893] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:11,895] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:11,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:12,146] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.342 seconds
[2022-03-23 08:56:15,785] {scheduler_job.py:153} INFO - Started process (PID=9334) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:15,792] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:15,794] {logging_mixin.py:112} INFO - [2022-03-23 08:56:15,794] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:15,854] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:15,864] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:15,866] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:15,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:16,045] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.260 seconds
[2022-03-23 08:56:19,832] {scheduler_job.py:153} INFO - Started process (PID=9339) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:19,838] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:19,840] {logging_mixin.py:112} INFO - [2022-03-23 08:56:19,839] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:19,874] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:19,883] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:19,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:19,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:20,069] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.237 seconds
[2022-03-23 08:56:23,792] {scheduler_job.py:153} INFO - Started process (PID=9344) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:23,801] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:23,802] {logging_mixin.py:112} INFO - [2022-03-23 08:56:23,802] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:23,832] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:23,839] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:23,842] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:23,852] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:24,050] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.258 seconds
[2022-03-23 08:56:27,806] {scheduler_job.py:153} INFO - Started process (PID=9349) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:27,813] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:27,815] {logging_mixin.py:112} INFO - [2022-03-23 08:56:27,815] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:27,851] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:27,861] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:27,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:27,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:28,051] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.245 seconds
[2022-03-23 08:56:31,834] {scheduler_job.py:153} INFO - Started process (PID=9354) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:31,842] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:31,844] {logging_mixin.py:112} INFO - [2022-03-23 08:56:31,843] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:31,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:31,890] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:31,893] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:31,903] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:32,337] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.503 seconds
[2022-03-23 08:56:35,832] {scheduler_job.py:153} INFO - Started process (PID=9362) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:35,839] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:35,840] {logging_mixin.py:112} INFO - [2022-03-23 08:56:35,840] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:35,877] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:35,888] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:35,890] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:35,899] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:36,084] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.252 seconds
[2022-03-23 08:56:39,819] {scheduler_job.py:153} INFO - Started process (PID=9367) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:39,826] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:39,828] {logging_mixin.py:112} INFO - [2022-03-23 08:56:39,828] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:39,865] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:39,875] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:39,877] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:39,887] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:40,063] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.244 seconds
[2022-03-23 08:56:43,855] {scheduler_job.py:153} INFO - Started process (PID=9373) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:43,863] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:43,864] {logging_mixin.py:112} INFO - [2022-03-23 08:56:43,864] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:43,901] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:43,911] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:43,913] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:43,922] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:44,096] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.241 seconds
[2022-03-23 08:56:47,843] {scheduler_job.py:153} INFO - Started process (PID=9378) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:47,857] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:47,861] {logging_mixin.py:112} INFO - [2022-03-23 08:56:47,860] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:47,901] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:47,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:47,914] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:47,923] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:48,271] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.428 seconds
[2022-03-23 08:56:51,834] {scheduler_job.py:153} INFO - Started process (PID=9383) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:51,839] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:51,842] {logging_mixin.py:112} INFO - [2022-03-23 08:56:51,842] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:51,877] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:51,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:51,888] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:51,898] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:52,118] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.284 seconds
[2022-03-23 08:56:55,867] {scheduler_job.py:153} INFO - Started process (PID=9391) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:55,873] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:55,878] {logging_mixin.py:112} INFO - [2022-03-23 08:56:55,877] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:55,916] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:55,926] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:55,928] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:55,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:56,171] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-03-23 08:56:59,859] {scheduler_job.py:153} INFO - Started process (PID=9396) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:59,865] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:56:59,867] {logging_mixin.py:112} INFO - [2022-03-23 08:56:59,867] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:56:59,900] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:56:59,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:59,914] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:56:59,927] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:00,152] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.295 seconds
[2022-03-23 08:57:03,840] {scheduler_job.py:153} INFO - Started process (PID=9401) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:03,848] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:03,849] {logging_mixin.py:112} INFO - [2022-03-23 08:57:03,849] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:03,883] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:03,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:03,897] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:03,905] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:04,094] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.254 seconds
[2022-03-23 08:57:07,884] {scheduler_job.py:153} INFO - Started process (PID=9406) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:07,889] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:07,891] {logging_mixin.py:112} INFO - [2022-03-23 08:57:07,891] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:07,923] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:07,931] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:07,933] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:07,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:08,116] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.232 seconds
[2022-03-23 08:57:11,873] {scheduler_job.py:153} INFO - Started process (PID=9411) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:11,880] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:11,882] {logging_mixin.py:112} INFO - [2022-03-23 08:57:11,882] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:11,931] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:11,942] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:11,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:11,953] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:12,195] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.322 seconds
[2022-03-23 08:57:15,867] {scheduler_job.py:153} INFO - Started process (PID=9420) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:15,874] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:15,881] {logging_mixin.py:112} INFO - [2022-03-23 08:57:15,881] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:15,955] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:15,968] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:15,971] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:15,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:16,230] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.364 seconds
[2022-03-23 08:57:19,914] {scheduler_job.py:153} INFO - Started process (PID=9425) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:19,921] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:19,922] {logging_mixin.py:112} INFO - [2022-03-23 08:57:19,922] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:19,954] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:19,964] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:19,966] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:19,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:20,155] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.241 seconds
[2022-03-23 08:57:23,889] {scheduler_job.py:153} INFO - Started process (PID=9430) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:23,899] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:23,901] {logging_mixin.py:112} INFO - [2022-03-23 08:57:23,901] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:23,937] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:23,945] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:23,947] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:23,956] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:24,146] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.256 seconds
[2022-03-23 08:57:27,880] {scheduler_job.py:153} INFO - Started process (PID=9435) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:27,886] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:27,887] {logging_mixin.py:112} INFO - [2022-03-23 08:57:27,887] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:27,923] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:27,933] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:27,935] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:27,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:28,187] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.307 seconds
[2022-03-23 08:57:31,920] {scheduler_job.py:153} INFO - Started process (PID=9440) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:31,929] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:31,931] {logging_mixin.py:112} INFO - [2022-03-23 08:57:31,931] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:31,973] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:31,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:31,985] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:31,996] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:32,182] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:57:35,892] {scheduler_job.py:153} INFO - Started process (PID=9448) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:35,898] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:35,899] {logging_mixin.py:112} INFO - [2022-03-23 08:57:35,899] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:35,930] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:35,939] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:35,942] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:35,950] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:36,155] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.263 seconds
[2022-03-23 08:57:39,895] {scheduler_job.py:153} INFO - Started process (PID=9453) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:39,900] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:39,902] {logging_mixin.py:112} INFO - [2022-03-23 08:57:39,901] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:39,931] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:39,939] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:39,940] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:39,949] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:40,104] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.210 seconds
[2022-03-23 08:57:43,926] {scheduler_job.py:153} INFO - Started process (PID=9458) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:43,932] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:43,933] {logging_mixin.py:112} INFO - [2022-03-23 08:57:43,933] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:43,967] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:43,976] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:43,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:43,987] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:44,189] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:57:47,939] {scheduler_job.py:153} INFO - Started process (PID=9464) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:47,949] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:47,952] {logging_mixin.py:112} INFO - [2022-03-23 08:57:47,952] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:48,013] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:48,024] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:48,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:48,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:48,235] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.296 seconds
[2022-03-23 08:57:51,921] {scheduler_job.py:153} INFO - Started process (PID=9469) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:51,928] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:51,929] {logging_mixin.py:112} INFO - [2022-03-23 08:57:51,929] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:51,960] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:51,968] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:51,975] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:51,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:52,183] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.263 seconds
[2022-03-23 08:57:55,935] {scheduler_job.py:153} INFO - Started process (PID=9477) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:55,940] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:55,941] {logging_mixin.py:112} INFO - [2022-03-23 08:57:55,941] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:55,971] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:55,979] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:55,981] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:57:55,989] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:56,171] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.237 seconds
[2022-03-23 08:57:59,937] {scheduler_job.py:153} INFO - Started process (PID=9482) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:59,949] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:57:59,950] {logging_mixin.py:112} INFO - [2022-03-23 08:57:59,950] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:57:59,989] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:57:59,999] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:00,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:00,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:00,252] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-03-23 08:58:03,929] {scheduler_job.py:153} INFO - Started process (PID=9487) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:03,936] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:03,937] {logging_mixin.py:112} INFO - [2022-03-23 08:58:03,937] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:03,967] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:03,977] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:03,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:03,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:04,162] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.233 seconds
[2022-03-23 08:58:07,972] {scheduler_job.py:153} INFO - Started process (PID=9492) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:07,980] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:07,982] {logging_mixin.py:112} INFO - [2022-03-23 08:58:07,981] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:08,020] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:08,029] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:08,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:08,040] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:08,233] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.261 seconds
[2022-03-23 08:58:11,939] {scheduler_job.py:153} INFO - Started process (PID=9497) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:11,951] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:11,953] {logging_mixin.py:112} INFO - [2022-03-23 08:58:11,953] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:12,119] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:12,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:12,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:12,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:12,468] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.529 seconds
[2022-03-23 08:58:15,946] {scheduler_job.py:153} INFO - Started process (PID=9505) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:15,954] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:15,956] {logging_mixin.py:112} INFO - [2022-03-23 08:58:15,956] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:16,003] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:16,015] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:16,017] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:16,029] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:16,218] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.275 seconds
[2022-03-23 08:58:19,990] {scheduler_job.py:153} INFO - Started process (PID=9511) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:19,998] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:20,000] {logging_mixin.py:112} INFO - [2022-03-23 08:58:20,000] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:20,049] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:20,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:20,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:20,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:20,349] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.360 seconds
[2022-03-23 08:58:23,955] {scheduler_job.py:153} INFO - Started process (PID=9516) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:23,966] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:23,968] {logging_mixin.py:112} INFO - [2022-03-23 08:58:23,967] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:24,013] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:24,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:24,042] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:24,062] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:24,250] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.295 seconds
[2022-03-23 08:58:29,467] {scheduler_job.py:153} INFO - Started process (PID=9526) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:29,515] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:29,539] {logging_mixin.py:112} INFO - [2022-03-23 08:58:29,539] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:29,605] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:29,636] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:29,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:29,743] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:30,517] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.049 seconds
[2022-03-23 08:58:32,057] {scheduler_job.py:153} INFO - Started process (PID=9528) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:32,080] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:32,082] {logging_mixin.py:112} INFO - [2022-03-23 08:58:32,082] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:32,132] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:32,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:32,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:32,156] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:33,114] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.057 seconds
[2022-03-23 08:58:36,944] {scheduler_job.py:153} INFO - Started process (PID=9536) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:36,949] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:36,950] {logging_mixin.py:112} INFO - [2022-03-23 08:58:36,950] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:36,981] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:36,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:36,989] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:36,997] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:37,360] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.416 seconds
[2022-03-23 08:58:40,044] {scheduler_job.py:153} INFO - Started process (PID=9541) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:40,050] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:40,052] {logging_mixin.py:112} INFO - [2022-03-23 08:58:40,052] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:40,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:40,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:40,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:40,104] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:40,254] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.211 seconds
[2022-03-23 08:58:44,102] {scheduler_job.py:153} INFO - Started process (PID=9546) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:44,119] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:44,121] {logging_mixin.py:112} INFO - [2022-03-23 08:58:44,121] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:44,362] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:44,411] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:44,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:44,448] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:45,015] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.913 seconds
[2022-03-23 08:58:48,207] {scheduler_job.py:153} INFO - Started process (PID=9551) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:48,222] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:48,226] {logging_mixin.py:112} INFO - [2022-03-23 08:58:48,226] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:48,340] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:48,361] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:48,364] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:48,383] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:48,981] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.774 seconds
[2022-03-23 08:58:56,244] {scheduler_job.py:153} INFO - Started process (PID=9560) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:56,252] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:56,255] {logging_mixin.py:112} INFO - [2022-03-23 08:58:56,255] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:56,436] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:56,447] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:56,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:56,460] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:56,934] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.691 seconds
[2022-03-23 08:58:58,001] {scheduler_job.py:153} INFO - Started process (PID=9565) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:58,009] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:58:58,011] {logging_mixin.py:112} INFO - [2022-03-23 08:58:58,010] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:58,065] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:58:58,082] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:58,084] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:58:58,095] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:58:58,303] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-03-23 08:59:01,229] {scheduler_job.py:153} INFO - Started process (PID=9567) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:01,238] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:01,240] {logging_mixin.py:112} INFO - [2022-03-23 08:59:01,240] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:01,287] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:01,301] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:01,304] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:01,322] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:01,551] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.322 seconds
[2022-03-23 08:59:05,169] {scheduler_job.py:153} INFO - Started process (PID=9577) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:05,180] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:05,182] {logging_mixin.py:112} INFO - [2022-03-23 08:59:05,182] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:05,229] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:05,244] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:05,247] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:05,259] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:05,509] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.341 seconds
[2022-03-23 08:59:09,231] {scheduler_job.py:153} INFO - Started process (PID=9582) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:09,247] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:09,249] {logging_mixin.py:112} INFO - [2022-03-23 08:59:09,249] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:09,330] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:09,346] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:09,349] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:09,367] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:09,783] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.552 seconds
[2022-03-23 08:59:13,226] {scheduler_job.py:153} INFO - Started process (PID=9587) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:13,236] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:13,238] {logging_mixin.py:112} INFO - [2022-03-23 08:59:13,238] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:13,338] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:13,366] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:13,382] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:13,410] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:13,672] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.447 seconds
[2022-03-23 08:59:17,197] {scheduler_job.py:153} INFO - Started process (PID=9592) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:17,203] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:17,205] {logging_mixin.py:112} INFO - [2022-03-23 08:59:17,205] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:17,268] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:17,282] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:17,284] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:17,295] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:17,523] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:59:21,197] {scheduler_job.py:153} INFO - Started process (PID=9597) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:21,204] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:21,205] {logging_mixin.py:112} INFO - [2022-03-23 08:59:21,205] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:21,240] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:21,248] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:21,250] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:21,258] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:22,570] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.374 seconds
[2022-03-23 08:59:25,231] {scheduler_job.py:153} INFO - Started process (PID=9602) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:25,253] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:25,255] {logging_mixin.py:112} INFO - [2022-03-23 08:59:25,254] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:25,306] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:25,320] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:25,322] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:25,344] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:25,617] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.386 seconds
[2022-03-23 08:59:29,218] {scheduler_job.py:153} INFO - Started process (PID=9607) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:29,225] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:29,227] {logging_mixin.py:112} INFO - [2022-03-23 08:59:29,227] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:29,256] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:29,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:29,266] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:29,280] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:29,571] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.354 seconds
[2022-03-23 08:59:33,223] {scheduler_job.py:153} INFO - Started process (PID=9616) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:33,232] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:33,234] {logging_mixin.py:112} INFO - [2022-03-23 08:59:33,234] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:33,268] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:33,276] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:33,278] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:33,287] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:33,485] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-03-23 08:59:37,230] {scheduler_job.py:153} INFO - Started process (PID=9621) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:37,246] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:37,248] {logging_mixin.py:112} INFO - [2022-03-23 08:59:37,248] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:37,281] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:37,289] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:37,291] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:37,310] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:37,615] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.385 seconds
[2022-03-23 08:59:41,226] {scheduler_job.py:153} INFO - Started process (PID=9626) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:41,236] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:41,237] {logging_mixin.py:112} INFO - [2022-03-23 08:59:41,237] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:41,282] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:41,292] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:41,294] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:41,302] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:41,616] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.391 seconds
[2022-03-23 08:59:45,219] {scheduler_job.py:153} INFO - Started process (PID=9631) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:45,227] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:45,229] {logging_mixin.py:112} INFO - [2022-03-23 08:59:45,229] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:45,264] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:45,272] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:45,273] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:45,284] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:45,457] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.238 seconds
[2022-03-23 08:59:49,255] {scheduler_job.py:153} INFO - Started process (PID=9637) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:49,270] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:49,272] {logging_mixin.py:112} INFO - [2022-03-23 08:59:49,271] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:49,299] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:49,305] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:49,307] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:49,318] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:49,582] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-03-23 08:59:53,245] {scheduler_job.py:153} INFO - Started process (PID=9645) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:53,253] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 08:59:53,255] {logging_mixin.py:112} INFO - [2022-03-23 08:59:53,254] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:53,306] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 08:59:53,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:53,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 08:59:53,327] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 08:59:53,519] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.274 seconds
[2022-03-23 08:59:58,352] {scheduler_job.py:153} INFO - Started process (PID=9650) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:00,239] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:00,241] {logging_mixin.py:112} INFO - [2022-03-23 09:00:00,240] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:00,287] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:01,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:01,086] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:02,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:05,440] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 7.088 seconds
[2022-03-23 09:00:17,131] {scheduler_job.py:153} INFO - Started process (PID=9656) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:17,139] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:17,144] {logging_mixin.py:112} INFO - [2022-03-23 09:00:17,140] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:17,184] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:17,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:17,201] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:17,227] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:19,449] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.318 seconds
[2022-03-23 09:00:22,031] {scheduler_job.py:153} INFO - Started process (PID=9658) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:22,049] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:22,050] {logging_mixin.py:112} INFO - [2022-03-23 09:00:22,050] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:22,086] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:22,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:22,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:22,107] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:24,072] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.042 seconds
[2022-03-23 09:00:24,802] {scheduler_job.py:153} INFO - Started process (PID=9660) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:24,811] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:24,812] {logging_mixin.py:112} INFO - [2022-03-23 09:00:24,812] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:24,865] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:24,882] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:24,884] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:24,898] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:25,262] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.460 seconds
[2022-03-23 09:00:25,843] {scheduler_job.py:153} INFO - Started process (PID=9662) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:25,869] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:25,871] {logging_mixin.py:112} INFO - [2022-03-23 09:00:25,871] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:25,951] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:25,966] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:25,969] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:25,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:27,537] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.695 seconds
[2022-03-23 09:00:30,047] {scheduler_job.py:153} INFO - Started process (PID=9664) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:30,063] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:30,070] {logging_mixin.py:112} INFO - [2022-03-23 09:00:30,070] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:30,160] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:30,179] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:30,184] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:30,202] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:31,746] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.699 seconds
[2022-03-23 09:00:33,083] {scheduler_job.py:153} INFO - Started process (PID=9666) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:33,099] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:33,102] {logging_mixin.py:112} INFO - [2022-03-23 09:00:33,101] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:33,158] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:33,167] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:33,174] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:33,189] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:33,649] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.567 seconds
[2022-03-23 09:00:34,931] {scheduler_job.py:153} INFO - Started process (PID=9668) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:34,947] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:34,950] {logging_mixin.py:112} INFO - [2022-03-23 09:00:34,949] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:35,036] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:35,056] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:35,060] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:35,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:36,006] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.075 seconds
[2022-03-23 09:00:37,641] {scheduler_job.py:153} INFO - Started process (PID=9670) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:37,654] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:37,656] {logging_mixin.py:112} INFO - [2022-03-23 09:00:37,656] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:37,712] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:37,729] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:37,732] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:37,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:38,416] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.775 seconds
[2022-03-23 09:00:39,708] {scheduler_job.py:153} INFO - Started process (PID=9672) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:39,718] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:39,720] {logging_mixin.py:112} INFO - [2022-03-23 09:00:39,720] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:39,851] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:39,868] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:39,871] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:39,892] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:41,134] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.426 seconds
[2022-03-23 09:00:50,872] {scheduler_job.py:153} INFO - Started process (PID=9678) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:51,047] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-03-23 09:00:51,079] {logging_mixin.py:112} INFO - [2022-03-23 09:00:51,074] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:51,459] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-03-23 09:00:51,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:51,613] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-03-23 09:00:51,712] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-03-23 09:00:54,777] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.008 seconds
