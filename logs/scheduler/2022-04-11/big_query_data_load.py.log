[2022-04-11 18:12:09,534] {scheduler_job.py:153} INFO - Started process (PID=20181) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:09,540] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:09,542] {logging_mixin.py:112} INFO - [2022-04-11 18:12:09,542] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:09,584] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:09,639] {logging_mixin.py:112} INFO - [2022-04-11 18:12:09,628] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:09,647] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:09,960] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.426 seconds
[2022-04-11 18:12:13,319] {scheduler_job.py:153} INFO - Started process (PID=20183) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:13,324] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:13,325] {logging_mixin.py:112} INFO - [2022-04-11 18:12:13,325] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:13,358] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:13,402] {logging_mixin.py:112} INFO - [2022-04-11 18:12:13,392] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:13,410] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:13,572] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.253 seconds
[2022-04-11 18:12:17,321] {scheduler_job.py:153} INFO - Started process (PID=20185) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:17,329] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:17,331] {logging_mixin.py:112} INFO - [2022-04-11 18:12:17,331] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:17,379] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:17,421] {logging_mixin.py:112} INFO - [2022-04-11 18:12:17,410] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:17,428] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:17,582] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.262 seconds
[2022-04-11 18:12:21,546] {scheduler_job.py:153} INFO - Started process (PID=20187) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:21,553] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:21,560] {logging_mixin.py:112} INFO - [2022-04-11 18:12:21,560] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:21,716] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:21,864] {logging_mixin.py:112} INFO - [2022-04-11 18:12:21,846] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:21,878] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:22,190] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.644 seconds
[2022-04-11 18:12:26,039] {scheduler_job.py:153} INFO - Started process (PID=20190) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:26,049] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:26,053] {logging_mixin.py:112} INFO - [2022-04-11 18:12:26,053] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:26,120] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:26,651] {logging_mixin.py:112} INFO - [2022-04-11 18:12:26,640] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:26,665] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:27,223] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.184 seconds
[2022-04-11 18:12:29,444] {scheduler_job.py:153} INFO - Started process (PID=20192) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:29,473] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:29,476] {logging_mixin.py:112} INFO - [2022-04-11 18:12:29,475] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:29,546] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:29,660] {logging_mixin.py:112} INFO - [2022-04-11 18:12:29,637] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:29,679] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:29,865] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.421 seconds
[2022-04-11 18:12:34,102] {scheduler_job.py:153} INFO - Started process (PID=20194) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:34,124] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:34,141] {logging_mixin.py:112} INFO - [2022-04-11 18:12:34,140] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:34,228] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:34,981] {logging_mixin.py:112} INFO - [2022-04-11 18:12:34,962] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:34,993] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:35,163] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.061 seconds
[2022-04-11 18:12:37,888] {scheduler_job.py:153} INFO - Started process (PID=20196) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:37,894] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:37,895] {logging_mixin.py:112} INFO - [2022-04-11 18:12:37,895] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:37,927] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:37,973] {logging_mixin.py:112} INFO - [2022-04-11 18:12:37,961] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:37,980] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:38,117] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.230 seconds
[2022-04-11 18:12:41,894] {scheduler_job.py:153} INFO - Started process (PID=20198) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:41,901] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:41,902] {logging_mixin.py:112} INFO - [2022-04-11 18:12:41,902] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:41,937] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:41,981] {logging_mixin.py:112} INFO - [2022-04-11 18:12:41,971] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:41,994] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:42,163] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.270 seconds
[2022-04-11 18:12:45,944] {scheduler_job.py:153} INFO - Started process (PID=20200) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:45,949] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:45,952] {logging_mixin.py:112} INFO - [2022-04-11 18:12:45,951] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:45,996] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:46,058] {logging_mixin.py:112} INFO - [2022-04-11 18:12:46,046] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:46,065] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:46,177] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.233 seconds
[2022-04-11 18:12:49,915] {scheduler_job.py:153} INFO - Started process (PID=20202) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:49,922] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:49,923] {logging_mixin.py:112} INFO - [2022-04-11 18:12:49,923] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:49,956] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:49,995] {logging_mixin.py:112} INFO - [2022-04-11 18:12:49,986] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:50,002] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:50,148] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.233 seconds
[2022-04-11 18:12:53,954] {scheduler_job.py:153} INFO - Started process (PID=20204) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:53,961] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:53,963] {logging_mixin.py:112} INFO - [2022-04-11 18:12:53,962] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:54,016] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:54,088] {logging_mixin.py:112} INFO - [2022-04-11 18:12:54,077] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:54,097] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:54,179] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.229 seconds
[2022-04-11 18:12:57,969] {scheduler_job.py:153} INFO - Started process (PID=20206) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:57,976] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:12:57,978] {logging_mixin.py:112} INFO - [2022-04-11 18:12:57,977] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:58,042] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:12:58,145] {logging_mixin.py:112} INFO - [2022-04-11 18:12:58,130] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:12:58,158] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:12:58,284] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-04-11 18:13:01,964] {scheduler_job.py:153} INFO - Started process (PID=20209) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:01,974] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:01,976] {logging_mixin.py:112} INFO - [2022-04-11 18:13:01,975] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:02,033] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:02,380] {logging_mixin.py:112} INFO - [2022-04-11 18:13:02,354] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:02,396] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:02,565] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.601 seconds
[2022-04-11 18:13:05,973] {scheduler_job.py:153} INFO - Started process (PID=20211) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:05,988] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:06,001] {logging_mixin.py:112} INFO - [2022-04-11 18:13:06,000] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:06,199] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:06,282] {logging_mixin.py:112} INFO - [2022-04-11 18:13:06,266] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:06,295] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:06,401] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.428 seconds
[2022-04-11 18:13:10,385] {scheduler_job.py:153} INFO - Started process (PID=20214) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:10,492] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:10,507] {logging_mixin.py:112} INFO - [2022-04-11 18:13:10,506] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:11,309] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:11,595] {logging_mixin.py:112} INFO - [2022-04-11 18:13:11,481] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:11,630] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:11,811] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.426 seconds
[2022-04-11 18:13:14,392] {scheduler_job.py:153} INFO - Started process (PID=20217) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:14,398] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:14,401] {logging_mixin.py:112} INFO - [2022-04-11 18:13:14,401] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:14,528] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:14,688] {logging_mixin.py:112} INFO - [2022-04-11 18:13:14,663] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:14,709] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:15,061] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.669 seconds
[2022-04-11 18:13:18,587] {scheduler_job.py:153} INFO - Started process (PID=20219) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:18,600] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:18,603] {logging_mixin.py:112} INFO - [2022-04-11 18:13:18,602] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:18,819] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:18,910] {logging_mixin.py:112} INFO - [2022-04-11 18:13:18,889] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:18,927] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:19,136] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.549 seconds
[2022-04-11 18:13:23,938] {scheduler_job.py:153} INFO - Started process (PID=20221) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:23,953] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:23,960] {logging_mixin.py:112} INFO - [2022-04-11 18:13:23,959] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:24,032] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:24,099] {logging_mixin.py:112} INFO - [2022-04-11 18:13:24,085] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:24,111] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:24,270] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.333 seconds
[2022-04-11 18:13:26,927] {scheduler_job.py:153} INFO - Started process (PID=20223) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:26,934] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:26,935] {logging_mixin.py:112} INFO - [2022-04-11 18:13:26,935] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:26,994] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:27,072] {logging_mixin.py:112} INFO - [2022-04-11 18:13:27,047] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:27,084] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:27,196] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.270 seconds
[2022-04-11 18:13:30,928] {scheduler_job.py:153} INFO - Started process (PID=20225) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:30,936] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:30,947] {logging_mixin.py:112} INFO - [2022-04-11 18:13:30,947] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:30,990] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:31,037] {logging_mixin.py:112} INFO - [2022-04-11 18:13:31,026] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:31,046] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:31,166] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.238 seconds
[2022-04-11 18:13:36,451] {scheduler_job.py:153} INFO - Started process (PID=20228) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:36,464] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:36,466] {logging_mixin.py:112} INFO - [2022-04-11 18:13:36,466] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:36,497] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:37,243] {logging_mixin.py:112} INFO - [2022-04-11 18:13:37,231] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:37,254] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:37,362] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.911 seconds
[2022-04-11 18:13:40,033] {scheduler_job.py:153} INFO - Started process (PID=20230) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:40,038] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:40,040] {logging_mixin.py:112} INFO - [2022-04-11 18:13:40,040] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:40,119] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:40,160] {logging_mixin.py:112} INFO - [2022-04-11 18:13:40,149] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:40,170] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:40,515] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.482 seconds
[2022-04-11 18:13:43,132] {scheduler_job.py:153} INFO - Started process (PID=20232) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:43,140] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:43,142] {logging_mixin.py:112} INFO - [2022-04-11 18:13:43,141] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:43,284] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:43,574] {logging_mixin.py:112} INFO - [2022-04-11 18:13:43,560] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:43,636] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:44,178] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.047 seconds
[2022-04-11 18:13:47,132] {scheduler_job.py:153} INFO - Started process (PID=20234) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:47,147] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:47,149] {logging_mixin.py:112} INFO - [2022-04-11 18:13:47,148] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:47,199] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:47,365] {logging_mixin.py:112} INFO - [2022-04-11 18:13:47,300] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:47,391] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:47,575] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.443 seconds
[2022-04-11 18:13:51,106] {scheduler_job.py:153} INFO - Started process (PID=20236) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:51,112] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:51,113] {logging_mixin.py:112} INFO - [2022-04-11 18:13:51,113] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:51,150] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:51,200] {logging_mixin.py:112} INFO - [2022-04-11 18:13:51,182] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:51,209] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:51,288] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.182 seconds
[2022-04-11 18:13:55,108] {scheduler_job.py:153} INFO - Started process (PID=20238) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:55,113] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:55,115] {logging_mixin.py:112} INFO - [2022-04-11 18:13:55,114] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:55,172] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:55,247] {logging_mixin.py:112} INFO - [2022-04-11 18:13:55,236] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:55,258] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:55,361] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.253 seconds
[2022-04-11 18:13:59,109] {scheduler_job.py:153} INFO - Started process (PID=20240) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:59,120] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:13:59,122] {logging_mixin.py:112} INFO - [2022-04-11 18:13:59,122] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:59,172] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:13:59,298] {logging_mixin.py:112} INFO - [2022-04-11 18:13:59,288] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:13:59,306] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:13:59,394] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.286 seconds
[2022-04-11 18:14:03,572] {scheduler_job.py:153} INFO - Started process (PID=20243) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:03,582] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:03,597] {logging_mixin.py:112} INFO - [2022-04-11 18:14:03,597] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:03,805] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:03,952] {logging_mixin.py:112} INFO - [2022-04-11 18:14:03,912] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:04,043] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:05,106] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.535 seconds
[2022-04-11 18:14:12,640] {scheduler_job.py:153} INFO - Started process (PID=20252) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:17,516] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:18,251] {logging_mixin.py:112} INFO - [2022-04-11 18:14:17,961] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:20,119] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:21,701] {logging_mixin.py:112} INFO - [2022-04-11 18:14:21,687] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:21,711] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:24,109] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 11.485 seconds
[2022-04-11 18:14:31,406] {scheduler_job.py:153} INFO - Started process (PID=20254) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:31,411] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:31,412] {logging_mixin.py:112} INFO - [2022-04-11 18:14:31,412] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:31,465] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:31,815] {logging_mixin.py:112} INFO - [2022-04-11 18:14:31,806] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:31,823] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:32,037] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.632 seconds
[2022-04-11 18:14:33,418] {scheduler_job.py:153} INFO - Started process (PID=20256) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:33,427] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:33,429] {logging_mixin.py:112} INFO - [2022-04-11 18:14:33,429] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:33,484] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:33,711] {logging_mixin.py:112} INFO - [2022-04-11 18:14:33,703] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:33,719] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:33,900] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.482 seconds
[2022-04-11 18:14:34,309] {scheduler_job.py:153} INFO - Started process (PID=20258) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:34,315] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:34,317] {logging_mixin.py:112} INFO - [2022-04-11 18:14:34,316] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:34,365] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:34,413] {logging_mixin.py:112} INFO - [2022-04-11 18:14:34,404] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:34,422] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:34,517] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.208 seconds
[2022-04-11 18:14:34,963] {scheduler_job.py:153} INFO - Started process (PID=20260) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:34,972] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:34,974] {logging_mixin.py:112} INFO - [2022-04-11 18:14:34,974] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:35,013] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:35,078] {logging_mixin.py:112} INFO - [2022-04-11 18:14:35,063] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:35,089] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:35,194] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.231 seconds
[2022-04-11 18:14:35,679] {scheduler_job.py:153} INFO - Started process (PID=20262) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:35,687] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:35,688] {logging_mixin.py:112} INFO - [2022-04-11 18:14:35,688] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:35,726] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:35,785] {logging_mixin.py:112} INFO - [2022-04-11 18:14:35,765] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:35,792] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:35,946] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.268 seconds
[2022-04-11 18:14:36,541] {scheduler_job.py:153} INFO - Started process (PID=20264) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:36,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:36,549] {logging_mixin.py:112} INFO - [2022-04-11 18:14:36,549] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:36,612] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:36,762] {logging_mixin.py:112} INFO - [2022-04-11 18:14:36,745] {dagbag.py:239} ERROR - Failed to import: /c/users/dan/airflow/dags/big_query_data_load.py
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 236, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/usr/lib/python3.8/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 702, in _load
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/c/users/dan/airflow/dags/big_query_data_load.py", line 40, in <module>
    PROJECT_ID = Variable.get('project')
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/variable.py", line 118, in get
    raise KeyError('Variable {} does not exist'.format(key))
KeyError: 'Variable project does not exist'
[2022-04-11 18:14:36,772] {scheduler_job.py:1576} WARNING - No viable dags retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:37,164] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.623 seconds
[2022-04-11 18:14:39,387] {scheduler_job.py:153} INFO - Started process (PID=20266) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:39,394] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:39,395] {logging_mixin.py:112} INFO - [2022-04-11 18:14:39,395] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:39,453] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:39,637] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:39,639] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:39,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:39,879] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.492 seconds
[2022-04-11 18:14:43,579] {scheduler_job.py:153} INFO - Started process (PID=20268) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:43,593] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:43,595] {logging_mixin.py:112} INFO - [2022-04-11 18:14:43,595] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:43,650] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:43,783] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:43,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:43,863] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:44,264] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.685 seconds
[2022-04-11 18:14:47,829] {scheduler_job.py:153} INFO - Started process (PID=20270) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:47,836] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:47,837] {logging_mixin.py:112} INFO - [2022-04-11 18:14:47,837] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:47,867] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:47,959] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:47,961] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:47,969] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:48,290] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.461 seconds
[2022-04-11 18:14:51,842] {scheduler_job.py:153} INFO - Started process (PID=20272) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:51,848] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:51,850] {logging_mixin.py:112} INFO - [2022-04-11 18:14:51,850] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:51,897] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:52,292] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:52,294] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:52,305] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:52,657] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.815 seconds
[2022-04-11 18:14:55,960] {scheduler_job.py:153} INFO - Started process (PID=20276) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:55,969] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:55,981] {logging_mixin.py:112} INFO - [2022-04-11 18:14:55,981] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:56,027] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:56,874] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:56,876] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:56,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:57,166] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.206 seconds
[2022-04-11 18:14:59,861] {scheduler_job.py:153} INFO - Started process (PID=20278) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:59,867] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:14:59,872] {logging_mixin.py:112} INFO - [2022-04-11 18:14:59,869] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:14:59,913] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:14:59,992] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:14:59,994] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:00,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:00,157] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.296 seconds
[2022-04-11 18:15:04,523] {scheduler_job.py:153} INFO - Started process (PID=20281) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:04,531] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:04,540] {logging_mixin.py:112} INFO - [2022-04-11 18:15:04,540] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:04,648] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:04,966] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:04,968] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:04,979] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:05,132] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.609 seconds
[2022-04-11 18:15:07,926] {scheduler_job.py:153} INFO - Started process (PID=20285) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:07,936] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:07,938] {logging_mixin.py:112} INFO - [2022-04-11 18:15:07,937] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:07,993] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:08,165] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:08,168] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:08,183] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:08,408] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.482 seconds
[2022-04-11 18:15:11,943] {scheduler_job.py:153} INFO - Started process (PID=20287) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:11,958] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:11,960] {logging_mixin.py:112} INFO - [2022-04-11 18:15:11,960] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:12,004] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:12,158] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:12,160] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:12,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:12,410] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.467 seconds
[2022-04-11 18:15:17,244] {scheduler_job.py:153} INFO - Started process (PID=20289) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:17,263] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:17,266] {logging_mixin.py:112} INFO - [2022-04-11 18:15:17,265] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:18,086] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:18,265] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:18,273] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:18,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:19,113] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.869 seconds
[2022-04-11 18:15:26,026] {scheduler_job.py:153} INFO - Started process (PID=20291) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:26,035] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:26,037] {logging_mixin.py:112} INFO - [2022-04-11 18:15:26,037] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:26,106] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:26,279] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:26,282] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:26,313] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:28,003] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.978 seconds
[2022-04-11 18:15:28,699] {scheduler_job.py:153} INFO - Started process (PID=20293) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:28,710] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:28,712] {logging_mixin.py:112} INFO - [2022-04-11 18:15:28,711] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:28,792] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:28,984] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:28,990] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:29,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:29,317] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.619 seconds
[2022-04-11 18:15:31,273] {scheduler_job.py:153} INFO - Started process (PID=20295) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:31,291] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:31,293] {logging_mixin.py:112} INFO - [2022-04-11 18:15:31,293] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:31,417] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:31,714] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:31,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:31,805] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:39,913] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 8.640 seconds
[2022-04-11 18:15:40,895] {scheduler_job.py:153} INFO - Started process (PID=20298) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:40,913] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:40,918] {logging_mixin.py:112} INFO - [2022-04-11 18:15:40,918] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:41,275] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:41,763] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:41,766] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:41,788] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:42,350] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.455 seconds
[2022-04-11 18:15:46,148] {scheduler_job.py:153} INFO - Started process (PID=20300) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:46,243] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:46,245] {logging_mixin.py:112} INFO - [2022-04-11 18:15:46,244] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:46,327] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:46,604] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:46,606] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:46,627] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:47,105] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.958 seconds
[2022-04-11 18:15:48,615] {scheduler_job.py:153} INFO - Started process (PID=20302) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:48,627] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:48,628] {logging_mixin.py:112} INFO - [2022-04-11 18:15:48,628] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:48,679] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:48,867] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:48,870] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:48,883] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:49,930] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.315 seconds
[2022-04-11 18:15:50,468] {scheduler_job.py:153} INFO - Started process (PID=20304) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:50,477] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:50,479] {logging_mixin.py:112} INFO - [2022-04-11 18:15:50,478] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:50,533] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:50,660] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:50,662] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:50,674] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:50,896] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.429 seconds
[2022-04-11 18:15:53,066] {scheduler_job.py:153} INFO - Started process (PID=20306) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:53,074] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:53,075] {logging_mixin.py:112} INFO - [2022-04-11 18:15:53,075] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:53,366] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:53,547] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:53,553] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:53,563] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:53,794] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.727 seconds
[2022-04-11 18:15:57,091] {scheduler_job.py:153} INFO - Started process (PID=20308) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:57,098] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:15:57,101] {logging_mixin.py:112} INFO - [2022-04-11 18:15:57,100] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:57,176] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:15:57,327] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:57,342] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:15:57,352] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:15:57,538] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.447 seconds
[2022-04-11 18:16:01,105] {scheduler_job.py:153} INFO - Started process (PID=20310) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:01,115] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:01,118] {logging_mixin.py:112} INFO - [2022-04-11 18:16:01,117] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:01,161] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:01,255] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:01,257] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:01,266] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:01,424] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.319 seconds
[2022-04-11 18:16:05,074] {scheduler_job.py:153} INFO - Started process (PID=20312) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:05,079] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:05,080] {logging_mixin.py:112} INFO - [2022-04-11 18:16:05,080] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:05,111] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:05,214] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:05,216] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:05,225] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:05,375] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.301 seconds
[2022-04-11 18:16:09,140] {scheduler_job.py:153} INFO - Started process (PID=20314) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:09,159] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:09,162] {logging_mixin.py:112} INFO - [2022-04-11 18:16:09,162] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:09,242] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:09,417] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:09,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:09,438] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:09,736] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.596 seconds
[2022-04-11 18:16:13,162] {scheduler_job.py:153} INFO - Started process (PID=20316) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:13,175] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:13,177] {logging_mixin.py:112} INFO - [2022-04-11 18:16:13,176] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:13,230] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:13,377] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:13,379] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:13,397] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:13,604] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.441 seconds
[2022-04-11 18:16:17,375] {scheduler_job.py:153} INFO - Started process (PID=20319) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:17,430] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:17,479] {logging_mixin.py:112} INFO - [2022-04-11 18:16:17,479] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:17,663] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:18,081] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:18,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:18,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:18,589] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.215 seconds
[2022-04-11 18:16:21,161] {scheduler_job.py:153} INFO - Started process (PID=20321) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:21,187] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:21,209] {logging_mixin.py:112} INFO - [2022-04-11 18:16:21,209] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:21,333] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:21,566] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:21,575] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:21,597] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:22,080] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.919 seconds
[2022-04-11 18:16:25,170] {scheduler_job.py:153} INFO - Started process (PID=20323) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:25,185] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:25,191] {logging_mixin.py:112} INFO - [2022-04-11 18:16:25,190] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:25,346] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:25,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:25,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:25,511] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:25,732] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.562 seconds
[2022-04-11 18:16:29,122] {scheduler_job.py:153} INFO - Started process (PID=20325) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:29,217] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:29,224] {logging_mixin.py:112} INFO - [2022-04-11 18:16:29,224] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:29,280] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:29,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:29,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:29,566] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:29,928] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.806 seconds
[2022-04-11 18:16:33,204] {scheduler_job.py:153} INFO - Started process (PID=20327) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:33,215] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:33,217] {logging_mixin.py:112} INFO - [2022-04-11 18:16:33,217] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:33,277] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:33,448] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:33,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:33,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:33,846] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.643 seconds
[2022-04-11 18:16:37,176] {scheduler_job.py:153} INFO - Started process (PID=20329) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:37,182] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:37,185] {logging_mixin.py:112} INFO - [2022-04-11 18:16:37,185] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:37,246] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:37,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:37,452] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:37,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:37,807] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.631 seconds
[2022-04-11 18:16:41,149] {scheduler_job.py:153} INFO - Started process (PID=20331) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:41,156] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:41,158] {logging_mixin.py:112} INFO - [2022-04-11 18:16:41,157] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:41,194] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:41,295] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:41,297] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:41,307] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:41,461] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-04-11 18:16:45,170] {scheduler_job.py:153} INFO - Started process (PID=20333) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:45,187] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:45,196] {logging_mixin.py:112} INFO - [2022-04-11 18:16:45,196] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:45,271] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:45,389] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:45,391] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:45,399] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:46,136] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.965 seconds
[2022-04-11 18:16:49,192] {scheduler_job.py:153} INFO - Started process (PID=20335) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:49,198] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:49,204] {logging_mixin.py:112} INFO - [2022-04-11 18:16:49,200] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:49,247] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:49,362] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:49,364] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:49,380] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:49,562] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.370 seconds
[2022-04-11 18:16:53,167] {scheduler_job.py:153} INFO - Started process (PID=20338) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:53,194] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:53,195] {logging_mixin.py:112} INFO - [2022-04-11 18:16:53,195] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:53,242] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:53,360] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:53,362] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:53,373] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:53,574] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.407 seconds
[2022-04-11 18:16:57,182] {scheduler_job.py:153} INFO - Started process (PID=20340) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:57,218] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:16:57,226] {logging_mixin.py:112} INFO - [2022-04-11 18:16:57,224] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:57,338] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:16:57,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:57,967] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:16:57,995] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:16:59,106] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.925 seconds
[2022-04-11 18:17:01,267] {scheduler_job.py:153} INFO - Started process (PID=20342) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:01,283] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:01,292] {logging_mixin.py:112} INFO - [2022-04-11 18:17:01,292] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:01,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:01,964] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:01,967] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:02,001] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:02,728] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.462 seconds
[2022-04-11 18:17:05,219] {scheduler_job.py:153} INFO - Started process (PID=20344) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:05,235] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:05,239] {logging_mixin.py:112} INFO - [2022-04-11 18:17:05,239] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:05,374] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:05,586] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:05,593] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:05,608] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:06,363] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.143 seconds
[2022-04-11 18:17:09,198] {scheduler_job.py:153} INFO - Started process (PID=20346) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:09,211] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:09,212] {logging_mixin.py:112} INFO - [2022-04-11 18:17:09,212] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:09,272] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:09,601] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:09,610] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:09,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:09,914] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.715 seconds
[2022-04-11 18:17:13,172] {scheduler_job.py:153} INFO - Started process (PID=20348) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:13,179] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:13,181] {logging_mixin.py:112} INFO - [2022-04-11 18:17:13,180] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:13,264] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:13,399] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:13,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:13,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:13,767] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.595 seconds
[2022-04-11 18:17:17,191] {scheduler_job.py:153} INFO - Started process (PID=20350) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:17,199] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:17,201] {logging_mixin.py:112} INFO - [2022-04-11 18:17:17,201] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:17,261] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:17,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:17,401] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:17,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:17,744] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.553 seconds
[2022-04-11 18:17:21,213] {scheduler_job.py:153} INFO - Started process (PID=20352) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:21,227] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:21,229] {logging_mixin.py:112} INFO - [2022-04-11 18:17:21,229] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:21,301] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:21,432] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:21,435] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:21,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:21,705] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.492 seconds
[2022-04-11 18:17:25,269] {scheduler_job.py:153} INFO - Started process (PID=20355) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:25,296] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:25,307] {logging_mixin.py:112} INFO - [2022-04-11 18:17:25,307] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:25,461] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:25,772] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:25,775] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:25,799] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:26,609] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.340 seconds
[2022-04-11 18:17:29,386] {scheduler_job.py:153} INFO - Started process (PID=20357) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:29,412] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:29,414] {logging_mixin.py:112} INFO - [2022-04-11 18:17:29,413] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:29,493] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:29,663] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:29,666] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:29,678] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:29,943] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.558 seconds
[2022-04-11 18:17:33,333] {scheduler_job.py:153} INFO - Started process (PID=20359) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:33,354] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:33,356] {logging_mixin.py:112} INFO - [2022-04-11 18:17:33,356] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:33,400] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:33,670] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:33,673] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:33,694] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:33,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.646 seconds
[2022-04-11 18:17:37,961] {scheduler_job.py:153} INFO - Started process (PID=20363) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:37,973] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:37,974] {logging_mixin.py:112} INFO - [2022-04-11 18:17:37,974] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:38,005] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:38,090] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:38,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:38,099] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:38,242] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-04-11 18:17:41,219] {scheduler_job.py:153} INFO - Started process (PID=20365) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:41,235] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:41,241] {logging_mixin.py:112} INFO - [2022-04-11 18:17:41,241] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:41,304] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:41,416] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:41,418] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:41,428] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:41,584] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.366 seconds
[2022-04-11 18:17:45,211] {scheduler_job.py:153} INFO - Started process (PID=20367) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:45,223] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:45,225] {logging_mixin.py:112} INFO - [2022-04-11 18:17:45,224] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:45,271] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:45,371] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:45,373] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:45,381] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:45,662] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.451 seconds
[2022-04-11 18:17:49,256] {scheduler_job.py:153} INFO - Started process (PID=20369) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:49,271] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:49,275] {logging_mixin.py:112} INFO - [2022-04-11 18:17:49,274] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:49,342] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:49,464] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:49,466] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:49,477] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:49,744] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.488 seconds
[2022-04-11 18:17:53,229] {scheduler_job.py:153} INFO - Started process (PID=20371) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:53,249] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:53,254] {logging_mixin.py:112} INFO - [2022-04-11 18:17:53,253] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:53,306] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:53,438] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:53,441] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:53,456] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:53,667] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.439 seconds
[2022-04-11 18:17:57,250] {scheduler_job.py:153} INFO - Started process (PID=20373) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:57,279] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:17:57,280] {logging_mixin.py:112} INFO - [2022-04-11 18:17:57,280] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:57,343] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:17:57,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:57,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:17:57,514] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:17:57,712] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.462 seconds
[2022-04-11 18:18:01,268] {scheduler_job.py:153} INFO - Started process (PID=20376) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:01,300] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:01,306] {logging_mixin.py:112} INFO - [2022-04-11 18:18:01,306] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:01,390] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:01,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:01,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:01,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:01,975] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.707 seconds
[2022-04-11 18:18:05,409] {scheduler_job.py:153} INFO - Started process (PID=20378) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:05,456] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:05,466] {logging_mixin.py:112} INFO - [2022-04-11 18:18:05,466] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:05,599] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:05,762] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:05,766] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:05,791] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:06,207] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.799 seconds
[2022-04-11 18:18:09,432] {scheduler_job.py:153} INFO - Started process (PID=20380) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:09,479] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:09,509] {logging_mixin.py:112} INFO - [2022-04-11 18:18:09,509] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:09,666] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:09,992] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:09,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:10,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:10,182] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.750 seconds
[2022-04-11 18:18:13,356] {scheduler_job.py:153} INFO - Started process (PID=20384) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:13,382] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:13,414] {logging_mixin.py:112} INFO - [2022-04-11 18:18:13,413] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:13,609] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:13,814] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:13,817] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:13,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:14,090] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.734 seconds
[2022-04-11 18:18:17,530] {scheduler_job.py:153} INFO - Started process (PID=20386) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:17,538] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:17,540] {logging_mixin.py:112} INFO - [2022-04-11 18:18:17,540] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:17,573] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:17,681] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:17,683] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:17,692] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:17,873] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.343 seconds
[2022-04-11 18:18:21,266] {scheduler_job.py:153} INFO - Started process (PID=20388) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:21,272] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:21,273] {logging_mixin.py:112} INFO - [2022-04-11 18:18:21,273] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:21,314] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:21,447] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:21,450] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:21,469] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:21,733] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.468 seconds
[2022-04-11 18:18:25,273] {scheduler_job.py:153} INFO - Started process (PID=20392) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:25,283] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:25,286] {logging_mixin.py:112} INFO - [2022-04-11 18:18:25,286] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:25,354] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:25,509] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:25,513] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:25,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:25,727] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-04-11 18:18:29,260] {scheduler_job.py:153} INFO - Started process (PID=20394) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:29,265] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:29,266] {logging_mixin.py:112} INFO - [2022-04-11 18:18:29,266] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:29,319] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:29,456] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:29,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:29,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:29,811] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.551 seconds
[2022-04-11 18:18:33,296] {scheduler_job.py:153} INFO - Started process (PID=20397) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:33,314] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:33,317] {logging_mixin.py:112} INFO - [2022-04-11 18:18:33,316] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:33,383] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:33,506] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:33,509] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:33,524] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:33,699] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.403 seconds
[2022-04-11 18:18:37,308] {scheduler_job.py:153} INFO - Started process (PID=20400) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:37,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:37,320] {logging_mixin.py:112} INFO - [2022-04-11 18:18:37,319] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:37,370] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:37,520] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:37,521] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:37,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:37,694] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.386 seconds
[2022-04-11 18:18:41,327] {scheduler_job.py:153} INFO - Started process (PID=20402) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:41,333] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:41,336] {logging_mixin.py:112} INFO - [2022-04-11 18:18:41,336] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:41,381] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:41,484] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:41,486] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:41,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:41,833] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.506 seconds
[2022-04-11 18:18:45,324] {scheduler_job.py:153} INFO - Started process (PID=20404) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:45,338] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:45,341] {logging_mixin.py:112} INFO - [2022-04-11 18:18:45,340] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:45,411] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:45,557] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:45,560] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:45,572] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:45,801] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.478 seconds
[2022-04-11 18:18:49,299] {scheduler_job.py:153} INFO - Started process (PID=20406) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:49,310] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:49,311] {logging_mixin.py:112} INFO - [2022-04-11 18:18:49,311] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:49,366] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:49,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:49,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:49,514] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:49,731] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.432 seconds
[2022-04-11 18:18:53,325] {scheduler_job.py:153} INFO - Started process (PID=20408) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:53,364] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:53,377] {logging_mixin.py:112} INFO - [2022-04-11 18:18:53,377] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:53,751] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:54,938] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:54,945] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:54,983] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:55,594] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.270 seconds
[2022-04-11 18:18:59,480] {scheduler_job.py:153} INFO - Started process (PID=20410) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:59,499] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:18:59,507] {logging_mixin.py:112} INFO - [2022-04-11 18:18:59,506] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:18:59,612] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:18:59,851] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:59,855] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:18:59,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:00,124] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.643 seconds
[2022-04-11 18:19:02,845] {scheduler_job.py:153} INFO - Started process (PID=20412) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:02,857] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:02,860] {logging_mixin.py:112} INFO - [2022-04-11 18:19:02,860] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:02,924] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:03,058] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:03,061] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:03,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:03,311] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.466 seconds
[2022-04-11 18:19:06,924] {scheduler_job.py:153} INFO - Started process (PID=20414) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:06,940] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:06,943] {logging_mixin.py:112} INFO - [2022-04-11 18:19:06,943] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:07,324] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:07,547] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:07,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:07,583] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:08,187] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.272 seconds
[2022-04-11 18:19:10,869] {scheduler_job.py:153} INFO - Started process (PID=20417) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:10,889] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:10,904] {logging_mixin.py:112} INFO - [2022-04-11 18:19:10,904] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:11,021] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:11,247] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:11,250] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:11,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:11,429] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.560 seconds
[2022-04-11 18:19:14,870] {scheduler_job.py:153} INFO - Started process (PID=20419) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:14,884] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:14,888] {logging_mixin.py:112} INFO - [2022-04-11 18:19:14,887] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:14,971] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:15,153] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:15,159] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:15,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:15,404] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.534 seconds
[2022-04-11 18:19:18,859] {scheduler_job.py:153} INFO - Started process (PID=20423) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:18,865] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:18,867] {logging_mixin.py:112} INFO - [2022-04-11 18:19:18,866] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:18,958] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:19,095] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:19,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:19,111] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:19,294] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.436 seconds
[2022-04-11 18:19:22,928] {scheduler_job.py:153} INFO - Started process (PID=20425) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:22,942] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:22,944] {logging_mixin.py:112} INFO - [2022-04-11 18:19:22,944] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:22,982] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:23,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:23,119] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:23,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:23,321] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.393 seconds
[2022-04-11 18:19:26,856] {scheduler_job.py:153} INFO - Started process (PID=20427) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:26,861] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:26,862] {logging_mixin.py:112} INFO - [2022-04-11 18:19:26,862] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:26,891] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:27,040] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:27,042] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:27,051] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:27,222] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.366 seconds
[2022-04-11 18:19:30,882] {scheduler_job.py:153} INFO - Started process (PID=20429) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:30,901] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:30,927] {logging_mixin.py:112} INFO - [2022-04-11 18:19:30,926] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:30,977] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:31,137] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:31,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:31,149] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:31,353] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.471 seconds
[2022-04-11 18:19:34,898] {scheduler_job.py:153} INFO - Started process (PID=20431) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:34,906] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:34,908] {logging_mixin.py:112} INFO - [2022-04-11 18:19:34,908] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:34,943] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:35,078] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:35,079] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:35,088] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:35,233] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-04-11 18:19:38,883] {scheduler_job.py:153} INFO - Started process (PID=20433) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:38,890] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:38,892] {logging_mixin.py:112} INFO - [2022-04-11 18:19:38,892] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:38,939] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:39,041] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:39,043] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:39,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:39,296] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.413 seconds
[2022-04-11 18:19:42,915] {scheduler_job.py:153} INFO - Started process (PID=20436) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:42,922] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:42,924] {logging_mixin.py:112} INFO - [2022-04-11 18:19:42,924] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:42,970] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:43,171] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:43,174] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:43,198] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:43,631] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.716 seconds
[2022-04-11 18:19:46,948] {scheduler_job.py:153} INFO - Started process (PID=20438) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:46,956] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:46,959] {logging_mixin.py:112} INFO - [2022-04-11 18:19:46,958] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:47,062] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:47,498] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:47,501] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:47,512] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:48,053] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.106 seconds
[2022-04-11 18:19:50,894] {scheduler_job.py:153} INFO - Started process (PID=20440) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:50,904] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:50,907] {logging_mixin.py:112} INFO - [2022-04-11 18:19:50,906] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:50,983] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:51,100] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:51,105] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:51,115] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:51,312] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.417 seconds
[2022-04-11 18:19:54,910] {scheduler_job.py:153} INFO - Started process (PID=20442) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:54,916] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:54,918] {logging_mixin.py:112} INFO - [2022-04-11 18:19:54,918] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:54,953] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:55,029] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:55,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:55,040] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:55,197] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.287 seconds
[2022-04-11 18:19:58,918] {scheduler_job.py:153} INFO - Started process (PID=20444) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:58,926] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:19:58,927] {logging_mixin.py:112} INFO - [2022-04-11 18:19:58,927] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:58,960] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:19:59,120] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:59,124] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:19:59,142] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:19:59,383] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.465 seconds
[2022-04-11 18:20:02,922] {scheduler_job.py:153} INFO - Started process (PID=20446) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:02,927] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:02,929] {logging_mixin.py:112} INFO - [2022-04-11 18:20:02,929] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:02,961] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:03,039] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:03,041] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:03,049] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:03,283] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.362 seconds
[2022-04-11 18:20:06,919] {scheduler_job.py:153} INFO - Started process (PID=20448) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:06,926] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:06,928] {logging_mixin.py:112} INFO - [2022-04-11 18:20:06,928] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:06,960] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:07,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:07,049] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:07,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:07,221] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-04-11 18:20:10,939] {scheduler_job.py:153} INFO - Started process (PID=20450) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:10,949] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:10,951] {logging_mixin.py:112} INFO - [2022-04-11 18:20:10,950] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:10,984] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:11,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:11,134] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:11,142] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:11,308] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.369 seconds
[2022-04-11 18:20:14,960] {scheduler_job.py:153} INFO - Started process (PID=20452) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:14,965] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:14,966] {logging_mixin.py:112} INFO - [2022-04-11 18:20:14,966] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:14,993] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:15,073] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:15,075] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:15,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:15,250] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.290 seconds
[2022-04-11 18:20:18,931] {scheduler_job.py:153} INFO - Started process (PID=20455) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:18,939] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:18,941] {logging_mixin.py:112} INFO - [2022-04-11 18:20:18,940] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:18,999] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:19,126] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:19,128] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:19,137] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:20,178] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.248 seconds
[2022-04-11 18:20:22,957] {scheduler_job.py:153} INFO - Started process (PID=20457) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:22,970] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:22,972] {logging_mixin.py:112} INFO - [2022-04-11 18:20:22,971] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:23,022] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:23,175] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:23,177] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:23,192] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:23,445] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.489 seconds
[2022-04-11 18:20:26,980] {scheduler_job.py:153} INFO - Started process (PID=20459) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:26,993] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:26,995] {logging_mixin.py:112} INFO - [2022-04-11 18:20:26,995] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:27,036] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:27,144] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:27,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:27,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:27,333] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.354 seconds
[2022-04-11 18:20:30,934] {scheduler_job.py:153} INFO - Started process (PID=20461) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:30,939] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:30,941] {logging_mixin.py:112} INFO - [2022-04-11 18:20:30,940] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:30,969] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:31,040] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:31,041] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:31,049] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:31,259] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-04-11 18:20:34,996] {scheduler_job.py:153} INFO - Started process (PID=20463) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:35,010] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:35,012] {logging_mixin.py:112} INFO - [2022-04-11 18:20:35,011] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:35,056] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:35,161] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:35,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:35,179] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:35,428] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.432 seconds
[2022-04-11 18:20:38,948] {scheduler_job.py:153} INFO - Started process (PID=20465) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:38,954] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:38,956] {logging_mixin.py:112} INFO - [2022-04-11 18:20:38,956] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:38,997] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:39,163] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:39,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:39,178] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:39,346] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.398 seconds
[2022-04-11 18:20:42,977] {scheduler_job.py:153} INFO - Started process (PID=20467) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:42,988] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:42,990] {logging_mixin.py:112} INFO - [2022-04-11 18:20:42,990] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:43,048] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:43,184] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:43,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:43,198] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:43,363] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.386 seconds
[2022-04-11 18:20:46,982] {scheduler_job.py:153} INFO - Started process (PID=20469) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:46,994] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:46,996] {logging_mixin.py:112} INFO - [2022-04-11 18:20:46,995] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:47,042] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:47,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:47,190] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:47,206] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:47,391] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.409 seconds
[2022-04-11 18:20:51,115] {scheduler_job.py:153} INFO - Started process (PID=20472) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:51,129] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:51,141] {logging_mixin.py:112} INFO - [2022-04-11 18:20:51,141] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:51,400] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:51,584] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:51,588] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:51,599] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:51,883] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.768 seconds
[2022-04-11 18:20:55,056] {scheduler_job.py:153} INFO - Started process (PID=20474) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:55,074] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:55,086] {logging_mixin.py:112} INFO - [2022-04-11 18:20:55,076] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:55,209] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:55,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:55,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:55,465] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:55,733] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.677 seconds
[2022-04-11 18:20:59,156] {scheduler_job.py:153} INFO - Started process (PID=20476) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:59,172] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:20:59,182] {logging_mixin.py:112} INFO - [2022-04-11 18:20:59,181] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:20:59,294] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:20:59,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:59,504] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:20:59,513] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:00,233] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.077 seconds
[2022-04-11 18:21:02,999] {scheduler_job.py:153} INFO - Started process (PID=20478) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:03,007] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:03,009] {logging_mixin.py:112} INFO - [2022-04-11 18:21:03,008] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:03,052] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:03,150] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:03,153] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:03,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:03,414] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-04-11 18:21:07,005] {scheduler_job.py:153} INFO - Started process (PID=20480) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:07,011] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:07,013] {logging_mixin.py:112} INFO - [2022-04-11 18:21:07,012] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:07,064] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:07,160] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:07,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:07,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:07,324] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.319 seconds
[2022-04-11 18:21:11,015] {scheduler_job.py:153} INFO - Started process (PID=20482) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:11,025] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:11,027] {logging_mixin.py:112} INFO - [2022-04-11 18:21:11,026] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:11,073] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:11,197] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:11,200] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:11,210] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:11,392] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.377 seconds
[2022-04-11 18:21:15,013] {scheduler_job.py:153} INFO - Started process (PID=20484) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:15,024] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:15,025] {logging_mixin.py:112} INFO - [2022-04-11 18:21:15,025] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:15,065] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:15,201] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:15,212] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:15,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:15,593] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.580 seconds
[2022-04-11 18:21:19,036] {scheduler_job.py:153} INFO - Started process (PID=20486) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:19,044] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:19,046] {logging_mixin.py:112} INFO - [2022-04-11 18:21:19,046] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:19,093] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:19,225] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:19,228] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:19,241] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:19,393] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.358 seconds
[2022-04-11 18:21:23,039] {scheduler_job.py:153} INFO - Started process (PID=20488) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:23,060] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:23,070] {logging_mixin.py:112} INFO - [2022-04-11 18:21:23,069] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:23,124] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:23,253] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:23,255] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:23,263] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:23,449] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.411 seconds
[2022-04-11 18:21:27,139] {scheduler_job.py:153} INFO - Started process (PID=20491) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:27,167] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:27,173] {logging_mixin.py:112} INFO - [2022-04-11 18:21:27,173] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:27,227] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:28,074] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:28,077] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:28,093] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:28,533] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.394 seconds
[2022-04-11 18:21:31,045] {scheduler_job.py:153} INFO - Started process (PID=20493) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:31,054] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:31,057] {logging_mixin.py:112} INFO - [2022-04-11 18:21:31,057] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:31,098] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:31,195] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:31,197] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:31,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:31,398] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.354 seconds
[2022-04-11 18:21:35,051] {scheduler_job.py:153} INFO - Started process (PID=20495) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:35,059] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:35,061] {logging_mixin.py:112} INFO - [2022-04-11 18:21:35,061] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:35,093] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:35,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:35,195] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:35,204] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:35,349] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.298 seconds
[2022-04-11 18:21:39,056] {scheduler_job.py:153} INFO - Started process (PID=20497) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:39,065] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:39,067] {logging_mixin.py:112} INFO - [2022-04-11 18:21:39,067] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:39,128] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:39,261] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:39,265] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:39,281] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:39,595] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.539 seconds
[2022-04-11 18:21:43,169] {scheduler_job.py:153} INFO - Started process (PID=20499) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:43,184] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:43,191] {logging_mixin.py:112} INFO - [2022-04-11 18:21:43,191] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:44,093] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:44,245] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:44,247] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:44,268] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:44,451] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.282 seconds
[2022-04-11 18:21:47,104] {scheduler_job.py:153} INFO - Started process (PID=20501) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:47,123] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:47,126] {logging_mixin.py:112} INFO - [2022-04-11 18:21:47,126] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:47,208] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:47,460] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:47,464] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:47,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:47,747] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.643 seconds
[2022-04-11 18:21:51,073] {scheduler_job.py:153} INFO - Started process (PID=20503) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:51,081] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:51,082] {logging_mixin.py:112} INFO - [2022-04-11 18:21:51,082] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:51,146] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:51,282] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:51,284] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:51,298] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:51,533] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.459 seconds
[2022-04-11 18:21:55,079] {scheduler_job.py:153} INFO - Started process (PID=20505) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:55,091] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:21:55,093] {logging_mixin.py:112} INFO - [2022-04-11 18:21:55,093] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:55,141] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:21:55,277] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:55,279] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:21:55,293] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:21:55,499] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.420 seconds
[2022-04-11 18:22:05,008] {scheduler_job.py:153} INFO - Started process (PID=20508) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:05,074] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:05,171] {logging_mixin.py:112} INFO - [2022-04-11 18:22:05,171] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:05,559] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:06,148] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:06,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:06,184] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:07,330] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.323 seconds
[2022-04-11 18:22:07,951] {scheduler_job.py:153} INFO - Started process (PID=20510) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:07,963] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:07,964] {logging_mixin.py:112} INFO - [2022-04-11 18:22:07,964] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:08,012] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:08,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:08,145] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:08,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:08,417] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.466 seconds
[2022-04-11 18:22:10,697] {scheduler_job.py:153} INFO - Started process (PID=20512) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:10,710] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:10,711] {logging_mixin.py:112} INFO - [2022-04-11 18:22:10,711] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:10,824] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:11,333] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:11,338] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:11,350] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:11,600] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.903 seconds
[2022-04-11 18:22:14,834] {scheduler_job.py:153} INFO - Started process (PID=20514) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:14,851] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:14,877] {logging_mixin.py:112} INFO - [2022-04-11 18:22:14,877] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:15,013] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:15,238] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:15,251] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:15,281] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:15,630] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.796 seconds
[2022-04-11 18:22:18,707] {scheduler_job.py:153} INFO - Started process (PID=20516) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:18,713] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:18,715] {logging_mixin.py:112} INFO - [2022-04-11 18:22:18,715] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:18,753] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:18,858] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:18,860] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:18,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:19,050] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.343 seconds
[2022-04-11 18:22:22,701] {scheduler_job.py:153} INFO - Started process (PID=20518) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:22,709] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:22,710] {logging_mixin.py:112} INFO - [2022-04-11 18:22:22,710] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:22,807] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:22,995] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:22,999] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:23,020] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:23,223] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.522 seconds
[2022-04-11 18:22:26,747] {scheduler_job.py:153} INFO - Started process (PID=20520) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:26,753] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:26,758] {logging_mixin.py:112} INFO - [2022-04-11 18:22:26,755] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:26,827] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:26,943] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:26,946] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:26,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:27,167] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.420 seconds
[2022-04-11 18:22:30,736] {scheduler_job.py:153} INFO - Started process (PID=20522) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:30,742] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:30,744] {logging_mixin.py:112} INFO - [2022-04-11 18:22:30,744] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:30,776] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:30,947] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:30,949] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:30,964] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:31,148] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.411 seconds
[2022-04-11 18:22:34,722] {scheduler_job.py:153} INFO - Started process (PID=20524) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:34,728] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:34,730] {logging_mixin.py:112} INFO - [2022-04-11 18:22:34,730] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:34,792] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:34,928] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:34,930] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:34,939] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:35,114] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.392 seconds
[2022-04-11 18:22:39,130] {scheduler_job.py:153} INFO - Started process (PID=20527) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:39,137] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:39,147] {logging_mixin.py:112} INFO - [2022-04-11 18:22:39,147] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:39,239] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:39,374] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:39,376] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:39,396] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:40,199] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.069 seconds
[2022-04-11 18:22:42,731] {scheduler_job.py:153} INFO - Started process (PID=20529) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:42,742] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:42,744] {logging_mixin.py:112} INFO - [2022-04-11 18:22:42,744] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:42,799] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:42,919] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:42,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:42,931] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:43,128] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.397 seconds
[2022-04-11 18:22:46,841] {scheduler_job.py:153} INFO - Started process (PID=20531) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:46,849] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:46,865] {logging_mixin.py:112} INFO - [2022-04-11 18:22:46,864] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:46,951] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:47,100] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:47,103] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:47,122] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:47,322] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.483 seconds
[2022-04-11 18:22:50,779] {scheduler_job.py:153} INFO - Started process (PID=20533) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:50,787] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:50,789] {logging_mixin.py:112} INFO - [2022-04-11 18:22:50,789] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:50,854] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:51,021] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:51,023] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:51,035] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:51,204] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.425 seconds
[2022-04-11 18:22:54,738] {scheduler_job.py:153} INFO - Started process (PID=20535) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:54,743] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:54,745] {logging_mixin.py:112} INFO - [2022-04-11 18:22:54,745] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:54,777] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:54,892] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:54,895] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:54,906] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:55,057] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.319 seconds
[2022-04-11 18:22:58,756] {scheduler_job.py:153} INFO - Started process (PID=20537) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:58,764] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:22:58,765] {logging_mixin.py:112} INFO - [2022-04-11 18:22:58,765] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:58,799] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:22:58,892] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:58,895] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:22:58,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:22:59,117] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.361 seconds
[2022-04-11 18:23:02,905] {scheduler_job.py:153} INFO - Started process (PID=20539) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:02,911] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:02,913] {logging_mixin.py:112} INFO - [2022-04-11 18:23:02,913] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:02,983] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:03,082] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:03,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:03,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:03,274] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.369 seconds
[2022-04-11 18:23:06,823] {scheduler_job.py:153} INFO - Started process (PID=20541) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:06,838] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:06,845] {logging_mixin.py:112} INFO - [2022-04-11 18:23:06,844] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:07,014] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:07,178] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:07,181] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:07,201] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:07,377] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.554 seconds
[2022-04-11 18:23:11,291] {scheduler_job.py:153} INFO - Started process (PID=20543) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:11,308] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:11,310] {logging_mixin.py:112} INFO - [2022-04-11 18:23:11,310] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:11,383] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:11,538] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:11,541] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:11,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:11,740] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.449 seconds
[2022-04-11 18:23:15,187] {scheduler_job.py:153} INFO - Started process (PID=20546) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:15,195] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:15,197] {logging_mixin.py:112} INFO - [2022-04-11 18:23:15,196] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:15,284] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:15,422] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:15,424] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:15,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:15,625] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.438 seconds
[2022-04-11 18:23:18,782] {scheduler_job.py:153} INFO - Started process (PID=20548) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:18,792] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:18,794] {logging_mixin.py:112} INFO - [2022-04-11 18:23:18,794] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:18,859] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:19,180] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:19,182] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:19,218] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:19,583] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.801 seconds
[2022-04-11 18:23:22,828] {scheduler_job.py:153} INFO - Started process (PID=20550) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:22,856] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:22,861] {logging_mixin.py:112} INFO - [2022-04-11 18:23:22,860] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:23,006] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:23,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:23,287] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:23,314] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:23,709] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.881 seconds
[2022-04-11 18:23:27,196] {scheduler_job.py:153} INFO - Started process (PID=20552) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:27,214] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:27,216] {logging_mixin.py:112} INFO - [2022-04-11 18:23:27,216] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:28,128] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:28,344] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:28,346] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:28,366] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:28,677] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.481 seconds
[2022-04-11 18:23:31,291] {scheduler_job.py:153} INFO - Started process (PID=20554) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:31,299] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:31,302] {logging_mixin.py:112} INFO - [2022-04-11 18:23:31,302] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:31,352] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:31,478] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:31,480] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:31,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:31,734] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.443 seconds
[2022-04-11 18:23:35,307] {scheduler_job.py:153} INFO - Started process (PID=20556) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:35,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:35,320] {logging_mixin.py:112} INFO - [2022-04-11 18:23:35,320] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:35,380] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:35,568] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:35,571] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:35,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:35,828] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.521 seconds
[2022-04-11 18:23:39,302] {scheduler_job.py:153} INFO - Started process (PID=20558) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:39,331] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:39,333] {logging_mixin.py:112} INFO - [2022-04-11 18:23:39,333] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:39,383] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:39,745] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:39,747] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:39,761] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:39,927] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.625 seconds
[2022-04-11 18:23:43,294] {scheduler_job.py:153} INFO - Started process (PID=20560) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:43,300] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:43,303] {logging_mixin.py:112} INFO - [2022-04-11 18:23:43,302] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:43,341] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:43,435] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:43,437] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:43,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:43,614] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-04-11 18:23:47,333] {scheduler_job.py:153} INFO - Started process (PID=20563) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:47,343] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:47,345] {logging_mixin.py:112} INFO - [2022-04-11 18:23:47,345] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:47,387] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:47,508] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:47,510] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:47,521] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:47,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.349 seconds
[2022-04-11 18:23:51,324] {scheduler_job.py:153} INFO - Started process (PID=20565) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:51,343] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:51,355] {logging_mixin.py:112} INFO - [2022-04-11 18:23:51,355] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:51,405] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:52,417] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:52,421] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:52,441] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:52,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.405 seconds
[2022-04-11 18:23:55,456] {scheduler_job.py:153} INFO - Started process (PID=20567) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:55,467] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:55,481] {logging_mixin.py:112} INFO - [2022-04-11 18:23:55,480] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:55,698] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:23:55,914] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:55,919] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:23:55,937] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:56,169] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.713 seconds
[2022-04-11 18:23:59,473] {scheduler_job.py:153} INFO - Started process (PID=20569) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:59,481] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:23:59,483] {logging_mixin.py:112} INFO - [2022-04-11 18:23:59,483] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:23:59,543] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:00,235] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:00,238] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:00,269] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:00,603] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.131 seconds
[2022-04-11 18:24:03,454] {scheduler_job.py:153} INFO - Started process (PID=20571) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:03,469] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:03,471] {logging_mixin.py:112} INFO - [2022-04-11 18:24:03,471] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:03,545] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:03,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:03,733] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:03,745] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:03,952] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.499 seconds
[2022-04-11 18:24:07,434] {scheduler_job.py:153} INFO - Started process (PID=20573) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:07,446] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:07,448] {logging_mixin.py:112} INFO - [2022-04-11 18:24:07,448] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:07,508] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:07,625] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:07,627] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:07,644] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:07,863] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.429 seconds
[2022-04-11 18:24:11,663] {scheduler_job.py:153} INFO - Started process (PID=20575) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:11,673] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:11,683] {logging_mixin.py:112} INFO - [2022-04-11 18:24:11,682] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:11,917] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:12,116] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:12,118] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:12,138] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:12,347] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.684 seconds
[2022-04-11 18:24:15,565] {scheduler_job.py:153} INFO - Started process (PID=20577) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:15,584] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:15,596] {logging_mixin.py:112} INFO - [2022-04-11 18:24:15,596] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:15,879] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:16,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:16,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:16,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:16,437] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.872 seconds
[2022-04-11 18:24:19,457] {scheduler_job.py:153} INFO - Started process (PID=20580) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:19,472] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:19,475] {logging_mixin.py:112} INFO - [2022-04-11 18:24:19,474] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:19,783] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:19,994] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:19,996] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:20,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:20,271] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.814 seconds
[2022-04-11 18:24:23,484] {scheduler_job.py:153} INFO - Started process (PID=20582) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:23,493] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:23,496] {logging_mixin.py:112} INFO - [2022-04-11 18:24:23,495] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:23,583] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:23,668] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:23,670] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:23,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:23,866] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.382 seconds
[2022-04-11 18:24:27,471] {scheduler_job.py:153} INFO - Started process (PID=20584) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:27,484] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:27,488] {logging_mixin.py:112} INFO - [2022-04-11 18:24:27,487] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:27,542] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:27,677] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:27,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:27,691] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:27,868] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.397 seconds
[2022-04-11 18:24:31,458] {scheduler_job.py:153} INFO - Started process (PID=20586) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:31,465] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:31,466] {logging_mixin.py:112} INFO - [2022-04-11 18:24:31,466] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:31,512] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:31,625] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:31,626] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:31,636] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:31,830] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.372 seconds
[2022-04-11 18:24:35,498] {scheduler_job.py:153} INFO - Started process (PID=20588) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:35,506] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:35,507] {logging_mixin.py:112} INFO - [2022-04-11 18:24:35,507] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:35,542] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:35,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:35,644] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:35,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:35,800] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.302 seconds
[2022-04-11 18:24:39,508] {scheduler_job.py:153} INFO - Started process (PID=20590) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:39,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:39,524] {logging_mixin.py:112} INFO - [2022-04-11 18:24:39,524] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:39,578] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:39,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:39,828] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:39,844] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:40,131] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.624 seconds
[2022-04-11 18:24:43,550] {scheduler_job.py:153} INFO - Started process (PID=20592) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:43,566] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:43,576] {logging_mixin.py:112} INFO - [2022-04-11 18:24:43,576] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:43,626] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:43,898] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:43,900] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:43,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:44,217] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.667 seconds
[2022-04-11 18:24:47,551] {scheduler_job.py:153} INFO - Started process (PID=20594) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:47,569] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:47,576] {logging_mixin.py:112} INFO - [2022-04-11 18:24:47,575] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:47,624] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:47,709] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:47,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:47,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:47,967] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.416 seconds
[2022-04-11 18:24:51,507] {scheduler_job.py:153} INFO - Started process (PID=20596) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:51,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:51,520] {logging_mixin.py:112} INFO - [2022-04-11 18:24:51,520] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:51,565] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:51,676] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:51,678] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:51,690] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:51,840] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.333 seconds
[2022-04-11 18:24:55,676] {scheduler_job.py:153} INFO - Started process (PID=20599) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:55,703] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:55,717] {logging_mixin.py:112} INFO - [2022-04-11 18:24:55,717] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:55,956] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:56,325] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:56,331] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:56,362] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:57,419] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.743 seconds
[2022-04-11 18:24:59,543] {scheduler_job.py:153} INFO - Started process (PID=20601) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:59,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:24:59,549] {logging_mixin.py:112} INFO - [2022-04-11 18:24:59,549] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:59,579] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:24:59,670] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:59,673] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:24:59,685] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:24:59,904] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.361 seconds
[2022-04-11 18:25:03,502] {scheduler_job.py:153} INFO - Started process (PID=20603) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:03,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:03,520] {logging_mixin.py:112} INFO - [2022-04-11 18:25:03,520] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:03,577] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:03,694] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:03,696] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:03,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:03,924] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.422 seconds
[2022-04-11 18:25:07,497] {scheduler_job.py:153} INFO - Started process (PID=20605) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:07,503] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:07,505] {logging_mixin.py:112} INFO - [2022-04-11 18:25:07,504] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:07,559] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:07,697] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:07,700] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:07,715] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:07,863] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.367 seconds
[2022-04-11 18:25:11,563] {scheduler_job.py:153} INFO - Started process (PID=20607) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:11,571] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:11,573] {logging_mixin.py:112} INFO - [2022-04-11 18:25:11,573] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:11,643] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:11,786] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:11,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:11,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:12,022] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.459 seconds
[2022-04-11 18:25:15,558] {scheduler_job.py:153} INFO - Started process (PID=20609) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:15,574] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:15,576] {logging_mixin.py:112} INFO - [2022-04-11 18:25:15,576] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:15,645] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:15,830] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:15,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:15,846] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:16,166] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.609 seconds
[2022-04-11 18:25:19,520] {scheduler_job.py:153} INFO - Started process (PID=20611) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:19,529] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:19,531] {logging_mixin.py:112} INFO - [2022-04-11 18:25:19,530] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:19,581] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:19,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:19,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:19,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:19,982] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.462 seconds
[2022-04-11 18:25:23,563] {scheduler_job.py:153} INFO - Started process (PID=20613) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:23,573] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:23,575] {logging_mixin.py:112} INFO - [2022-04-11 18:25:23,575] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:23,624] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:23,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:23,834] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:23,876] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:24,129] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.566 seconds
[2022-04-11 18:25:33,289] {scheduler_job.py:153} INFO - Started process (PID=20616) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:33,314] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:33,320] {logging_mixin.py:112} INFO - [2022-04-11 18:25:33,319] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:33,439] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:33,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:33,632] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:33,656] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:34,114] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.826 seconds
[2022-04-11 18:25:36,220] {scheduler_job.py:153} INFO - Started process (PID=20618) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:36,248] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:36,251] {logging_mixin.py:112} INFO - [2022-04-11 18:25:36,250] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:36,489] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:37,824] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:37,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:37,837] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:38,026] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.806 seconds
[2022-04-11 18:25:40,172] {scheduler_job.py:153} INFO - Started process (PID=20620) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:40,198] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:40,200] {logging_mixin.py:112} INFO - [2022-04-11 18:25:40,199] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:40,274] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:40,460] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:40,462] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:40,493] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:41,035] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.863 seconds
[2022-04-11 18:25:44,221] {scheduler_job.py:153} INFO - Started process (PID=20622) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:44,232] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:44,236] {logging_mixin.py:112} INFO - [2022-04-11 18:25:44,235] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:44,327] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:44,534] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:44,540] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:44,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:44,962] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.741 seconds
[2022-04-11 18:25:48,799] {scheduler_job.py:153} INFO - Started process (PID=20624) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:48,811] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:48,813] {logging_mixin.py:112} INFO - [2022-04-11 18:25:48,813] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:49,064] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:49,259] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:49,279] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:49,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:49,948] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.149 seconds
[2022-04-11 18:25:52,269] {scheduler_job.py:153} INFO - Started process (PID=20626) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:52,283] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:52,290] {logging_mixin.py:112} INFO - [2022-04-11 18:25:52,290] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:52,383] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:52,486] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:52,488] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:52,497] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:52,696] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.428 seconds
[2022-04-11 18:25:56,204] {scheduler_job.py:153} INFO - Started process (PID=20628) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:56,213] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:25:56,216] {logging_mixin.py:112} INFO - [2022-04-11 18:25:56,215] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:56,295] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:25:56,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:56,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:25:56,604] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:25:56,832] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.628 seconds
[2022-04-11 18:26:00,187] {scheduler_job.py:153} INFO - Started process (PID=20630) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:00,193] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:00,195] {logging_mixin.py:112} INFO - [2022-04-11 18:26:00,195] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:00,232] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:00,324] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:00,326] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:00,339] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:00,503] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-04-11 18:26:04,182] {scheduler_job.py:153} INFO - Started process (PID=20632) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:04,193] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:04,195] {logging_mixin.py:112} INFO - [2022-04-11 18:26:04,195] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:04,243] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:04,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:04,606] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:04,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:04,932] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.751 seconds
[2022-04-11 18:26:08,246] {scheduler_job.py:153} INFO - Started process (PID=20635) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:08,260] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:08,263] {logging_mixin.py:112} INFO - [2022-04-11 18:26:08,263] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:08,362] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:08,828] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:08,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:08,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:09,163] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.917 seconds
[2022-04-11 18:26:12,230] {scheduler_job.py:153} INFO - Started process (PID=20637) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:12,242] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:12,248] {logging_mixin.py:112} INFO - [2022-04-11 18:26:12,248] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:12,311] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:12,465] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:12,467] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:12,481] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:12,683] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-04-11 18:26:16,241] {scheduler_job.py:153} INFO - Started process (PID=20639) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:16,255] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:16,258] {logging_mixin.py:112} INFO - [2022-04-11 18:26:16,258] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:16,317] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:16,406] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:16,408] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:16,421] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:16,610] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.370 seconds
[2022-04-11 18:26:20,244] {scheduler_job.py:153} INFO - Started process (PID=20641) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:20,253] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:20,257] {logging_mixin.py:112} INFO - [2022-04-11 18:26:20,256] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:20,345] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:20,547] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:20,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:20,565] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:20,793] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.550 seconds
[2022-04-11 18:26:24,230] {scheduler_job.py:153} INFO - Started process (PID=20643) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:24,236] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:24,244] {logging_mixin.py:112} INFO - [2022-04-11 18:26:24,243] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:24,328] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:24,487] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:24,494] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:24,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:24,742] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.512 seconds
[2022-04-11 18:26:28,231] {scheduler_job.py:153} INFO - Started process (PID=20645) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:28,241] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:28,243] {logging_mixin.py:112} INFO - [2022-04-11 18:26:28,243] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:28,298] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:28,469] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:28,477] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:28,492] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:28,845] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.614 seconds
[2022-04-11 18:26:32,284] {scheduler_job.py:153} INFO - Started process (PID=20647) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:32,299] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:32,301] {logging_mixin.py:112} INFO - [2022-04-11 18:26:32,301] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:32,400] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:32,975] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:32,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:32,992] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:33,248] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.964 seconds
[2022-04-11 18:26:36,340] {scheduler_job.py:153} INFO - Started process (PID=20649) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:36,350] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:36,359] {logging_mixin.py:112} INFO - [2022-04-11 18:26:36,358] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:36,425] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:36,662] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:36,665] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:36,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:36,926] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.589 seconds
[2022-04-11 18:26:43,166] {scheduler_job.py:153} INFO - Started process (PID=20652) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:43,184] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:43,194] {logging_mixin.py:112} INFO - [2022-04-11 18:26:43,193] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:43,430] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:43,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:43,778] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:43,800] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:44,516] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.349 seconds
[2022-04-11 18:26:46,041] {scheduler_job.py:153} INFO - Started process (PID=20654) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:46,059] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:46,087] {logging_mixin.py:112} INFO - [2022-04-11 18:26:46,086] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:46,677] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:46,917] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:46,925] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:46,938] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:47,174] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.133 seconds
[2022-04-11 18:26:49,790] {scheduler_job.py:153} INFO - Started process (PID=20656) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:49,799] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:49,802] {logging_mixin.py:112} INFO - [2022-04-11 18:26:49,801] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:49,867] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:49,999] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:50,001] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:50,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:50,207] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.417 seconds
[2022-04-11 18:26:53,805] {scheduler_job.py:153} INFO - Started process (PID=20658) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:53,822] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:53,832] {logging_mixin.py:112} INFO - [2022-04-11 18:26:53,832] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:53,900] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:54,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:54,050] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:54,065] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:54,283] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.479 seconds
[2022-04-11 18:26:57,891] {scheduler_job.py:153} INFO - Started process (PID=20660) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:57,900] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:26:57,907] {logging_mixin.py:112} INFO - [2022-04-11 18:26:57,907] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:58,001] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:26:58,159] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:58,161] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:26:58,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:26:58,646] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.757 seconds
[2022-04-11 18:27:01,832] {scheduler_job.py:153} INFO - Started process (PID=20662) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:01,845] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:01,847] {logging_mixin.py:112} INFO - [2022-04-11 18:27:01,846] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:01,900] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:02,043] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:02,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:02,057] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:02,274] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.442 seconds
[2022-04-11 18:27:05,829] {scheduler_job.py:153} INFO - Started process (PID=20664) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:05,842] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:05,844] {logging_mixin.py:112} INFO - [2022-04-11 18:27:05,844] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:05,899] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:06,050] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:06,057] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:06,067] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:06,264] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.435 seconds
[2022-04-11 18:27:10,740] {scheduler_job.py:153} INFO - Started process (PID=20666) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:10,756] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:10,759] {logging_mixin.py:112} INFO - [2022-04-11 18:27:10,759] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:10,883] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:11,044] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:11,047] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:11,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:11,268] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.528 seconds
[2022-04-11 18:27:14,209] {scheduler_job.py:153} INFO - Started process (PID=20668) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:14,215] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:14,217] {logging_mixin.py:112} INFO - [2022-04-11 18:27:14,217] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:14,274] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:14,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:14,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:14,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:14,713] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.504 seconds
[2022-04-11 18:27:18,037] {scheduler_job.py:153} INFO - Started process (PID=20670) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:18,050] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:18,052] {logging_mixin.py:112} INFO - [2022-04-11 18:27:18,052] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:18,115] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:18,270] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:18,275] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:18,288] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:18,560] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.524 seconds
[2022-04-11 18:27:22,217] {scheduler_job.py:153} INFO - Started process (PID=20673) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:22,238] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:22,256] {logging_mixin.py:112} INFO - [2022-04-11 18:27:22,255] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:22,540] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:22,829] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:22,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:22,879] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:23,095] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.878 seconds
[2022-04-11 18:27:26,107] {scheduler_job.py:153} INFO - Started process (PID=20675) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:26,123] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:26,125] {logging_mixin.py:112} INFO - [2022-04-11 18:27:26,125] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:26,193] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:26,526] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:26,528] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:26,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:27,151] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.044 seconds
[2022-04-11 18:27:30,087] {scheduler_job.py:153} INFO - Started process (PID=20677) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:30,103] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:30,105] {logging_mixin.py:112} INFO - [2022-04-11 18:27:30,105] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:30,206] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:30,387] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:30,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:30,420] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:30,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.643 seconds
[2022-04-11 18:27:35,139] {scheduler_job.py:153} INFO - Started process (PID=20679) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:35,147] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:35,149] {logging_mixin.py:112} INFO - [2022-04-11 18:27:35,149] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:35,269] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:35,444] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:35,446] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:35,466] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:36,921] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.783 seconds
[2022-04-11 18:27:38,080] {scheduler_job.py:153} INFO - Started process (PID=20681) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:38,090] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:38,092] {logging_mixin.py:112} INFO - [2022-04-11 18:27:38,092] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:38,144] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:38,370] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:38,374] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:38,388] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:38,684] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.604 seconds
[2022-04-11 18:27:42,076] {scheduler_job.py:153} INFO - Started process (PID=20683) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:42,087] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:42,089] {logging_mixin.py:112} INFO - [2022-04-11 18:27:42,089] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:42,141] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:42,262] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:42,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:42,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:42,490] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.415 seconds
[2022-04-11 18:27:46,131] {scheduler_job.py:153} INFO - Started process (PID=20685) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:46,146] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:46,148] {logging_mixin.py:112} INFO - [2022-04-11 18:27:46,148] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:46,236] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:46,416] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:46,421] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:46,444] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:46,664] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.533 seconds
[2022-04-11 18:27:50,080] {scheduler_job.py:153} INFO - Started process (PID=20687) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:50,088] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:50,093] {logging_mixin.py:112} INFO - [2022-04-11 18:27:50,093] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:50,129] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:50,217] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:50,220] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:50,230] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:50,395] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-04-11 18:27:54,257] {scheduler_job.py:153} INFO - Started process (PID=20690) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:54,360] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:27:54,364] {logging_mixin.py:112} INFO - [2022-04-11 18:27:54,363] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:54,431] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:27:54,678] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:54,681] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:27:54,703] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:27:54,913] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.658 seconds
[2022-04-11 18:28:00,396] {scheduler_job.py:153} INFO - Started process (PID=20700) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:00,415] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:00,420] {logging_mixin.py:112} INFO - [2022-04-11 18:28:00,419] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:00,479] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:00,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:00,685] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:00,700] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:01,021] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.625 seconds
[2022-04-11 18:28:03,510] {scheduler_job.py:153} INFO - Started process (PID=20706) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:03,517] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:03,519] {logging_mixin.py:112} INFO - [2022-04-11 18:28:03,518] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:03,558] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:03,651] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:03,653] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:03,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:03,999] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.489 seconds
[2022-04-11 18:28:07,674] {scheduler_job.py:153} INFO - Started process (PID=20708) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:07,903] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:07,915] {logging_mixin.py:112} INFO - [2022-04-11 18:28:07,915] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:08,283] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:08,508] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:08,510] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:08,527] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:08,806] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.132 seconds
[2022-04-11 18:28:11,704] {scheduler_job.py:153} INFO - Started process (PID=20710) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:11,713] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:11,714] {logging_mixin.py:112} INFO - [2022-04-11 18:28:11,714] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:11,764] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:11,907] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:11,910] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:11,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:12,776] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.072 seconds
[2022-04-11 18:28:15,640] {scheduler_job.py:153} INFO - Started process (PID=20712) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:15,666] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:15,684] {logging_mixin.py:112} INFO - [2022-04-11 18:28:15,684] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:15,830] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:16,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:16,137] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:16,161] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:16,443] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.803 seconds
[2022-04-11 18:28:19,538] {scheduler_job.py:153} INFO - Started process (PID=20714) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:19,554] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:19,583] {logging_mixin.py:112} INFO - [2022-04-11 18:28:19,583] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:19,678] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:19,877] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:19,880] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:19,893] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:20,114] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.576 seconds
[2022-04-11 18:28:23,606] {scheduler_job.py:153} INFO - Started process (PID=20716) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:23,615] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:23,617] {logging_mixin.py:112} INFO - [2022-04-11 18:28:23,617] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:23,668] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:23,789] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:23,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:23,802] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:23,996] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.390 seconds
[2022-04-11 18:28:27,548] {scheduler_job.py:153} INFO - Started process (PID=20718) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:27,558] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:27,561] {logging_mixin.py:112} INFO - [2022-04-11 18:28:27,560] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:27,615] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:27,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:27,868] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:27,895] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:28,181] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.633 seconds
[2022-04-11 18:28:31,592] {scheduler_job.py:153} INFO - Started process (PID=20721) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:31,602] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:31,610] {logging_mixin.py:112} INFO - [2022-04-11 18:28:31,610] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:31,715] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:32,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:32,042] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:32,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:32,307] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.715 seconds
[2022-04-11 18:28:35,797] {scheduler_job.py:153} INFO - Started process (PID=20723) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:35,814] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:35,832] {logging_mixin.py:112} INFO - [2022-04-11 18:28:35,832] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:36,458] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:36,648] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:36,650] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:36,680] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:37,062] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.265 seconds
[2022-04-11 18:28:39,619] {scheduler_job.py:153} INFO - Started process (PID=20727) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:39,632] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:39,633] {logging_mixin.py:112} INFO - [2022-04-11 18:28:39,633] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:39,727] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:39,862] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:39,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:39,879] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:40,073] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-04-11 18:28:43,646] {scheduler_job.py:153} INFO - Started process (PID=20729) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:43,652] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:43,656] {logging_mixin.py:112} INFO - [2022-04-11 18:28:43,656] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:43,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:43,874] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:43,880] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:43,912] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:44,249] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.604 seconds
[2022-04-11 18:28:47,738] {scheduler_job.py:153} INFO - Started process (PID=20732) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:47,765] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:47,799] {logging_mixin.py:112} INFO - [2022-04-11 18:28:47,798] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:47,926] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:48,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:48,146] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:48,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:49,167] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.429 seconds
[2022-04-11 18:28:51,637] {scheduler_job.py:153} INFO - Started process (PID=20735) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:51,674] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:51,697] {logging_mixin.py:112} INFO - [2022-04-11 18:28:51,696] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:52,184] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:52,535] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:52,549] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:52,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:53,615] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.978 seconds
[2022-04-11 18:28:55,608] {scheduler_job.py:153} INFO - Started process (PID=20737) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:55,614] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:55,616] {logging_mixin.py:112} INFO - [2022-04-11 18:28:55,615] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:55,657] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:28:55,802] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:55,806] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:28:55,817] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:56,027] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-04-11 18:28:59,782] {scheduler_job.py:153} INFO - Started process (PID=20739) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:59,790] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:28:59,792] {logging_mixin.py:112} INFO - [2022-04-11 18:28:59,791] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:28:59,839] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:00,007] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:00,024] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:00,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:00,691] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.909 seconds
[2022-04-11 18:29:03,708] {scheduler_job.py:153} INFO - Started process (PID=20742) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:03,765] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:03,779] {logging_mixin.py:112} INFO - [2022-04-11 18:29:03,779] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:04,042] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:04,422] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:04,430] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:04,468] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:06,945] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.237 seconds
[2022-04-11 18:29:08,578] {scheduler_job.py:153} INFO - Started process (PID=20744) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:08,592] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:08,595] {logging_mixin.py:112} INFO - [2022-04-11 18:29:08,594] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:08,652] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:08,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:08,917] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:08,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:09,448] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.869 seconds
[2022-04-11 18:29:12,257] {scheduler_job.py:153} INFO - Started process (PID=20746) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:12,291] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:12,307] {logging_mixin.py:112} INFO - [2022-04-11 18:29:12,307] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:12,431] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:12,891] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:12,904] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:12,959] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:13,632] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.376 seconds
[2022-04-11 18:29:16,152] {scheduler_job.py:153} INFO - Started process (PID=20748) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:16,264] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:16,269] {logging_mixin.py:112} INFO - [2022-04-11 18:29:16,268] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:16,799] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:16,973] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:16,976] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:16,989] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:17,280] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.128 seconds
[2022-04-11 18:29:20,204] {scheduler_job.py:153} INFO - Started process (PID=20750) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:20,214] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:20,220] {logging_mixin.py:112} INFO - [2022-04-11 18:29:20,216] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:20,299] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:20,560] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:20,562] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:20,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:23,895] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.691 seconds
[2022-04-11 18:29:26,817] {scheduler_job.py:153} INFO - Started process (PID=20752) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:26,837] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:26,856] {logging_mixin.py:112} INFO - [2022-04-11 18:29:26,855] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:27,258] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:27,651] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:27,655] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:27,671] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:28,298] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.481 seconds
[2022-04-11 18:29:29,342] {scheduler_job.py:153} INFO - Started process (PID=20754) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:29,353] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:29,364] {logging_mixin.py:112} INFO - [2022-04-11 18:29:29,359] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:29,414] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:29,563] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:29,572] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:29,589] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:30,057] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.715 seconds
[2022-04-11 18:29:33,465] {scheduler_job.py:153} INFO - Started process (PID=20756) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:33,481] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:33,573] {logging_mixin.py:112} INFO - [2022-04-11 18:29:33,572] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:33,948] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:34,993] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:34,995] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:35,029] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:36,047] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.583 seconds
[2022-04-11 18:29:37,351] {scheduler_job.py:153} INFO - Started process (PID=20758) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:37,360] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:37,362] {logging_mixin.py:112} INFO - [2022-04-11 18:29:37,362] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:37,416] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:37,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:37,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:37,600] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:37,931] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.581 seconds
[2022-04-11 18:29:41,462] {scheduler_job.py:153} INFO - Started process (PID=20761) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:41,472] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:41,477] {logging_mixin.py:112} INFO - [2022-04-11 18:29:41,476] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:41,528] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:41,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:41,799] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:41,832] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:42,195] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.732 seconds
[2022-04-11 18:29:45,100] {scheduler_job.py:153} INFO - Started process (PID=20763) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:45,123] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:45,138] {logging_mixin.py:112} INFO - [2022-04-11 18:29:45,138] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:45,320] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:45,731] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:45,734] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:45,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:46,007] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.908 seconds
[2022-04-11 18:29:49,663] {scheduler_job.py:153} INFO - Started process (PID=20765) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:49,718] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:49,768] {logging_mixin.py:112} INFO - [2022-04-11 18:29:49,768] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:50,073] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:51,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:51,133] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:51,148] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:51,446] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.783 seconds
[2022-04-11 18:29:54,116] {scheduler_job.py:153} INFO - Started process (PID=20767) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:54,133] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:54,165] {logging_mixin.py:112} INFO - [2022-04-11 18:29:54,165] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:54,264] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:54,518] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:54,526] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:54,547] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:55,242] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.126 seconds
[2022-04-11 18:29:58,023] {scheduler_job.py:153} INFO - Started process (PID=20769) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:58,035] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:29:58,041] {logging_mixin.py:112} INFO - [2022-04-11 18:29:58,041] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:58,140] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:29:58,754] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:58,763] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:29:58,786] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:29:59,647] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.630 seconds
[2022-04-11 18:30:01,972] {scheduler_job.py:153} INFO - Started process (PID=20771) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:01,984] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:01,988] {logging_mixin.py:112} INFO - [2022-04-11 18:30:01,988] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:02,050] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:02,223] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:02,227] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:02,240] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:02,447] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.480 seconds
[2022-04-11 18:30:05,987] {scheduler_job.py:153} INFO - Started process (PID=20773) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:05,999] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:06,001] {logging_mixin.py:112} INFO - [2022-04-11 18:30:06,001] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:06,058] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:06,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:06,196] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:06,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:06,465] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.478 seconds
[2022-04-11 18:30:10,012] {scheduler_job.py:153} INFO - Started process (PID=20775) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:10,021] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:10,023] {logging_mixin.py:112} INFO - [2022-04-11 18:30:10,022] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:10,111] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:10,259] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:10,261] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:10,272] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:10,438] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.427 seconds
[2022-04-11 18:30:14,212] {scheduler_job.py:153} INFO - Started process (PID=20777) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:14,258] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:14,262] {logging_mixin.py:112} INFO - [2022-04-11 18:30:14,261] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:14,396] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:15,021] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:15,040] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:15,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:16,365] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.153 seconds
[2022-04-11 18:30:26,526] {scheduler_job.py:153} INFO - Started process (PID=20780) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:26,805] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:26,826] {logging_mixin.py:112} INFO - [2022-04-11 18:30:26,825] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:29,078] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:34,222] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:34,707] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:36,378] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:46,777] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 20.252 seconds
[2022-04-11 18:30:52,007] {scheduler_job.py:153} INFO - Started process (PID=20782) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:52,014] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:52,016] {logging_mixin.py:112} INFO - [2022-04-11 18:30:52,015] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:52,059] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:52,244] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:52,247] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:52,257] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:53,558] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.551 seconds
[2022-04-11 18:30:56,466] {scheduler_job.py:153} INFO - Started process (PID=20784) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:56,474] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:56,476] {logging_mixin.py:112} INFO - [2022-04-11 18:30:56,476] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:56,524] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:56,650] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:56,652] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:56,669] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:57,144] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.678 seconds
[2022-04-11 18:30:57,877] {scheduler_job.py:153} INFO - Started process (PID=20786) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:57,885] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:57,886] {logging_mixin.py:112} INFO - [2022-04-11 18:30:57,886] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:57,949] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:58,306] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:58,307] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:58,324] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:58,633] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.756 seconds
[2022-04-11 18:30:59,481] {scheduler_job.py:153} INFO - Started process (PID=20788) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:59,490] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:30:59,492] {logging_mixin.py:112} INFO - [2022-04-11 18:30:59,492] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:30:59,553] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:30:59,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:59,744] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:30:59,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:00,038] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.557 seconds
[2022-04-11 18:31:00,814] {scheduler_job.py:153} INFO - Started process (PID=20790) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:00,822] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:00,824] {logging_mixin.py:112} INFO - [2022-04-11 18:31:00,824] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:00,858] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:00,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:00,945] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:00,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:01,133] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.319 seconds
[2022-04-11 18:31:01,776] {scheduler_job.py:153} INFO - Started process (PID=20792) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:01,784] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:01,806] {logging_mixin.py:112} INFO - [2022-04-11 18:31:01,806] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:02,014] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:02,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:02,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:02,470] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:02,911] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.136 seconds
[2022-04-11 18:31:03,994] {scheduler_job.py:153} INFO - Started process (PID=20794) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:04,008] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:04,010] {logging_mixin.py:112} INFO - [2022-04-11 18:31:04,009] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:04,087] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:04,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:04,286] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:04,299] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:04,636] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.642 seconds
[2022-04-11 18:31:05,186] {scheduler_job.py:153} INFO - Started process (PID=20796) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:05,196] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:05,197] {logging_mixin.py:112} INFO - [2022-04-11 18:31:05,197] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:05,261] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:05,447] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:05,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:05,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:05,876] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.691 seconds
[2022-04-11 18:31:06,506] {scheduler_job.py:153} INFO - Started process (PID=20798) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:06,514] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:06,516] {logging_mixin.py:112} INFO - [2022-04-11 18:31:06,515] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:06,552] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:06,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:06,644] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:06,653] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:06,813] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.307 seconds
[2022-04-11 18:31:07,222] {scheduler_job.py:153} INFO - Started process (PID=20800) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:07,228] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:07,229] {logging_mixin.py:112} INFO - [2022-04-11 18:31:07,229] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:07,296] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:07,378] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:07,388] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:07,400] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:07,555] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.334 seconds
[2022-04-11 18:31:07,970] {scheduler_job.py:153} INFO - Started process (PID=20802) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:07,977] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:07,978] {logging_mixin.py:112} INFO - [2022-04-11 18:31:07,978] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:08,012] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:08,090] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:08,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:08,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:08,341] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.371 seconds
[2022-04-11 18:31:10,355] {scheduler_job.py:153} INFO - Started process (PID=20804) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:10,366] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:10,368] {logging_mixin.py:112} INFO - [2022-04-11 18:31:10,367] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:10,402] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:10,900] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:10,906] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:10,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:11,544] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.189 seconds
[2022-04-11 18:31:14,322] {scheduler_job.py:153} INFO - Started process (PID=20806) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:14,329] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:14,330] {logging_mixin.py:112} INFO - [2022-04-11 18:31:14,330] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:14,362] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:14,526] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:14,532] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:14,545] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:14,801] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.479 seconds
[2022-04-11 18:31:19,229] {scheduler_job.py:153} INFO - Started process (PID=20808) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:19,235] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:19,236] {logging_mixin.py:112} INFO - [2022-04-11 18:31:19,236] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:19,268] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:19,515] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:19,520] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:19,634] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:20,014] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.785 seconds
[2022-04-11 18:31:25,701] {scheduler_job.py:153} INFO - Started process (PID=20811) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:25,752] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:25,770] {logging_mixin.py:112} INFO - [2022-04-11 18:31:25,770] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:26,416] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:27,845] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:28,140] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:28,495] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:29,604] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.902 seconds
[2022-04-11 18:31:38,577] {scheduler_job.py:153} INFO - Started process (PID=20813) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:38,675] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:38,681] {logging_mixin.py:112} INFO - [2022-04-11 18:31:38,680] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:38,827] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:39,980] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:39,992] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:40,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:40,547] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.970 seconds
[2022-04-11 18:31:41,883] {scheduler_job.py:153} INFO - Started process (PID=20815) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:41,892] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:41,894] {logging_mixin.py:112} INFO - [2022-04-11 18:31:41,894] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:42,001] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:42,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:42,190] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:42,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:42,971] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.087 seconds
[2022-04-11 18:31:43,632] {scheduler_job.py:153} INFO - Started process (PID=20817) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:43,647] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:43,650] {logging_mixin.py:112} INFO - [2022-04-11 18:31:43,649] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:43,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:43,974] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:43,976] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:43,990] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:44,335] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.703 seconds
[2022-04-11 18:31:45,569] {scheduler_job.py:153} INFO - Started process (PID=20819) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:45,599] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:45,613] {logging_mixin.py:112} INFO - [2022-04-11 18:31:45,613] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:45,707] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:45,846] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:45,848] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:45,863] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:46,251] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.682 seconds
[2022-04-11 18:31:47,240] {scheduler_job.py:153} INFO - Started process (PID=20821) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:47,251] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:47,254] {logging_mixin.py:112} INFO - [2022-04-11 18:31:47,254] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:47,350] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:47,493] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:47,496] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:47,511] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:47,783] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.544 seconds
[2022-04-11 18:31:48,957] {scheduler_job.py:153} INFO - Started process (PID=20823) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:48,970] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:48,972] {logging_mixin.py:112} INFO - [2022-04-11 18:31:48,972] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:49,205] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:49,469] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:49,473] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:49,489] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:50,002] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.046 seconds
[2022-04-11 18:31:52,957] {scheduler_job.py:153} INFO - Started process (PID=20825) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:52,964] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:52,968] {logging_mixin.py:112} INFO - [2022-04-11 18:31:52,967] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:53,039] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:53,542] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:53,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:53,559] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:53,828] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.874 seconds
[2022-04-11 18:31:56,974] {scheduler_job.py:153} INFO - Started process (PID=20827) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:56,986] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:31:56,994] {logging_mixin.py:112} INFO - [2022-04-11 18:31:56,993] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:57,060] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:31:57,239] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:57,241] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:31:57,262] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:31:57,514] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.540 seconds
[2022-04-11 18:32:01,007] {scheduler_job.py:153} INFO - Started process (PID=20829) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:01,017] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:01,026] {logging_mixin.py:112} INFO - [2022-04-11 18:32:01,025] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:01,114] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:01,495] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:01,498] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:01,520] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:02,538] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.527 seconds
[2022-04-11 18:32:06,755] {scheduler_job.py:153} INFO - Started process (PID=20831) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:06,763] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:06,765] {logging_mixin.py:112} INFO - [2022-04-11 18:32:06,765] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:06,824] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:06,934] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:06,940] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:06,954] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:07,194] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.440 seconds
[2022-04-11 18:32:10,887] {scheduler_job.py:153} INFO - Started process (PID=20834) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:10,934] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:10,950] {logging_mixin.py:112} INFO - [2022-04-11 18:32:10,950] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:11,225] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:12,055] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:12,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:12,096] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:12,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.610 seconds
[2022-04-11 18:32:15,385] {scheduler_job.py:153} INFO - Started process (PID=20836) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:15,399] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:15,401] {logging_mixin.py:112} INFO - [2022-04-11 18:32:15,400] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:15,563] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:16,059] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:16,077] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:16,100] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:16,526] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.141 seconds
[2022-04-11 18:32:19,069] {scheduler_job.py:153} INFO - Started process (PID=20838) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:19,086] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:19,093] {logging_mixin.py:112} INFO - [2022-04-11 18:32:19,093] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:19,159] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:19,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:19,408] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:19,423] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:19,618] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.550 seconds
[2022-04-11 18:32:23,124] {scheduler_job.py:153} INFO - Started process (PID=20840) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:23,154] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:23,167] {logging_mixin.py:112} INFO - [2022-04-11 18:32:23,166] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:23,533] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:23,819] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:23,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:23,834] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:24,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.557 seconds
[2022-04-11 18:32:27,174] {scheduler_job.py:153} INFO - Started process (PID=20842) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:27,186] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:27,189] {logging_mixin.py:112} INFO - [2022-04-11 18:32:27,189] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:27,258] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:27,445] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:27,447] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:27,473] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:27,830] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.657 seconds
[2022-04-11 18:32:31,107] {scheduler_job.py:153} INFO - Started process (PID=20844) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:31,123] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:31,126] {logging_mixin.py:112} INFO - [2022-04-11 18:32:31,125] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:31,164] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:31,259] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:31,261] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:31,272] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:31,474] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.368 seconds
[2022-04-11 18:32:35,085] {scheduler_job.py:153} INFO - Started process (PID=20846) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:35,093] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:35,094] {logging_mixin.py:112} INFO - [2022-04-11 18:32:35,094] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:35,127] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:35,233] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:35,235] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:35,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:35,410] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.325 seconds
[2022-04-11 18:32:39,098] {scheduler_job.py:153} INFO - Started process (PID=20848) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:39,107] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:39,109] {logging_mixin.py:112} INFO - [2022-04-11 18:32:39,109] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:39,199] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:39,302] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:39,304] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:39,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:39,502] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.404 seconds
[2022-04-11 18:32:43,070] {scheduler_job.py:153} INFO - Started process (PID=20850) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:43,075] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:43,076] {logging_mixin.py:112} INFO - [2022-04-11 18:32:43,076] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:43,107] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:43,181] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:43,183] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:43,191] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:43,330] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.261 seconds
[2022-04-11 18:32:47,144] {scheduler_job.py:153} INFO - Started process (PID=20853) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:47,173] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:47,180] {logging_mixin.py:112} INFO - [2022-04-11 18:32:47,180] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:47,292] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:47,552] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:47,557] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:47,572] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:47,780] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.637 seconds
[2022-04-11 18:32:51,108] {scheduler_job.py:153} INFO - Started process (PID=20855) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:51,114] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:51,116] {logging_mixin.py:112} INFO - [2022-04-11 18:32:51,116] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:51,168] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:51,343] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:51,346] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:51,358] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:51,726] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.618 seconds
[2022-04-11 18:32:55,137] {scheduler_job.py:153} INFO - Started process (PID=20857) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:55,150] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:55,152] {logging_mixin.py:112} INFO - [2022-04-11 18:32:55,151] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:55,251] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:55,478] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:55,482] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:55,499] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:55,948] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.811 seconds
[2022-04-11 18:32:59,126] {scheduler_job.py:153} INFO - Started process (PID=20859) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:59,136] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:32:59,139] {logging_mixin.py:112} INFO - [2022-04-11 18:32:59,139] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:59,185] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:32:59,349] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:59,351] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:32:59,365] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:32:59,549] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.423 seconds
[2022-04-11 18:33:03,232] {scheduler_job.py:153} INFO - Started process (PID=20861) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:03,240] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:03,247] {logging_mixin.py:112} INFO - [2022-04-11 18:33:03,247] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:03,300] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:03,400] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:03,405] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:03,417] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:03,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.449 seconds
[2022-04-11 18:33:07,100] {scheduler_job.py:153} INFO - Started process (PID=20863) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:07,107] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:07,113] {logging_mixin.py:112} INFO - [2022-04-11 18:33:07,108] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:07,153] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:07,262] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:07,265] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:07,275] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:07,441] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.341 seconds
[2022-04-11 18:33:11,235] {scheduler_job.py:153} INFO - Started process (PID=20865) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:11,256] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:11,275] {logging_mixin.py:112} INFO - [2022-04-11 18:33:11,275] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:11,425] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:11,579] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:11,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:11,610] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:12,017] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.783 seconds
[2022-04-11 18:33:15,166] {scheduler_job.py:153} INFO - Started process (PID=20867) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:15,172] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:15,174] {logging_mixin.py:112} INFO - [2022-04-11 18:33:15,174] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:15,214] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:15,310] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:15,312] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:15,322] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:15,470] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-04-11 18:33:19,629] {scheduler_job.py:153} INFO - Started process (PID=20870) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:19,636] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:19,639] {logging_mixin.py:112} INFO - [2022-04-11 18:33:19,639] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:19,752] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:19,898] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:19,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:19,927] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:20,145] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.517 seconds
[2022-04-11 18:33:23,173] {scheduler_job.py:153} INFO - Started process (PID=20872) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:23,182] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:23,184] {logging_mixin.py:112} INFO - [2022-04-11 18:33:23,184] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:23,222] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:24,012] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:24,015] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:24,043] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:25,059] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.886 seconds
[2022-04-11 18:33:27,173] {scheduler_job.py:153} INFO - Started process (PID=20874) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:27,182] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:27,185] {logging_mixin.py:112} INFO - [2022-04-11 18:33:27,185] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:27,243] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:27,343] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:27,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:27,355] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:27,514] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.342 seconds
[2022-04-11 18:33:31,308] {scheduler_job.py:153} INFO - Started process (PID=20876) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:31,314] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:31,316] {logging_mixin.py:112} INFO - [2022-04-11 18:33:31,316] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:31,358] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:31,486] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:31,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:31,515] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:31,715] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.408 seconds
[2022-04-11 18:33:35,155] {scheduler_job.py:153} INFO - Started process (PID=20878) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:35,190] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:35,192] {logging_mixin.py:112} INFO - [2022-04-11 18:33:35,192] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:35,262] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:35,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:35,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:35,578] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:35,927] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.773 seconds
[2022-04-11 18:33:39,290] {scheduler_job.py:153} INFO - Started process (PID=20880) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:39,298] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:39,312] {logging_mixin.py:112} INFO - [2022-04-11 18:33:39,312] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:39,459] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:39,639] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:39,641] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:39,676] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:39,930] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.640 seconds
[2022-04-11 18:33:43,209] {scheduler_job.py:153} INFO - Started process (PID=20882) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:43,224] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:43,225] {logging_mixin.py:112} INFO - [2022-04-11 18:33:43,225] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:43,320] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:43,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:43,607] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:43,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:44,047] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.838 seconds
[2022-04-11 18:33:47,596] {scheduler_job.py:153} INFO - Started process (PID=20884) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:47,619] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:47,624] {logging_mixin.py:112} INFO - [2022-04-11 18:33:47,622] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:47,689] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:47,942] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:47,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:47,957] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:48,241] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.645 seconds
[2022-04-11 18:33:51,213] {scheduler_job.py:153} INFO - Started process (PID=20886) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:51,224] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:33:51,226] {logging_mixin.py:112} INFO - [2022-04-11 18:33:51,225] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:51,278] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:33:51,378] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:51,380] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:33:51,393] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:33:51,594] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.382 seconds
[2022-04-11 18:34:00,565] {scheduler_job.py:153} INFO - Started process (PID=20889) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:00,581] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:00,598] {logging_mixin.py:112} INFO - [2022-04-11 18:34:00,597] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:00,931] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:02,909] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:03,040] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:03,946] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:06,612] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 6.047 seconds
[2022-04-11 18:34:09,227] {scheduler_job.py:153} INFO - Started process (PID=20891) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:09,239] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:09,242] {logging_mixin.py:112} INFO - [2022-04-11 18:34:09,241] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:09,326] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:09,551] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:09,558] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:09,575] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:10,339] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.112 seconds
[2022-04-11 18:34:13,493] {scheduler_job.py:153} INFO - Started process (PID=20894) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:13,500] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:13,502] {logging_mixin.py:112} INFO - [2022-04-11 18:34:13,502] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:13,588] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:13,704] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:13,707] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:13,717] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:13,941] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.448 seconds
[2022-04-11 18:34:15,088] {scheduler_job.py:153} INFO - Started process (PID=20896) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:15,115] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:15,118] {logging_mixin.py:112} INFO - [2022-04-11 18:34:15,118] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:15,227] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:15,562] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:15,567] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:15,596] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:15,955] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.867 seconds
[2022-04-11 18:34:16,549] {scheduler_job.py:153} INFO - Started process (PID=20898) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:16,561] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:16,563] {logging_mixin.py:112} INFO - [2022-04-11 18:34:16,563] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:16,607] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:16,715] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:16,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:16,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:16,978] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.429 seconds
[2022-04-11 18:34:17,498] {scheduler_job.py:153} INFO - Started process (PID=20900) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:17,505] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:17,507] {logging_mixin.py:112} INFO - [2022-04-11 18:34:17,507] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:17,550] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:17,649] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:17,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:17,665] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:17,998] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.501 seconds
[2022-04-11 18:34:20,459] {scheduler_job.py:153} INFO - Started process (PID=20903) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:20,470] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:20,472] {logging_mixin.py:112} INFO - [2022-04-11 18:34:20,472] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:20,537] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:20,631] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:20,633] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:20,643] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:20,904] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.445 seconds
[2022-04-11 18:34:24,456] {scheduler_job.py:153} INFO - Started process (PID=20905) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:24,466] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:24,467] {logging_mixin.py:112} INFO - [2022-04-11 18:34:24,467] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:24,496] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:24,799] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:24,803] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:24,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:25,237] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.780 seconds
[2022-04-11 18:34:28,670] {scheduler_job.py:153} INFO - Started process (PID=20907) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:28,688] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:28,692] {logging_mixin.py:112} INFO - [2022-04-11 18:34:28,691] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:28,747] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:28,939] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:28,984] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:29,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:29,460] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.790 seconds
[2022-04-11 18:34:32,470] {scheduler_job.py:153} INFO - Started process (PID=20909) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:32,481] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:32,482] {logging_mixin.py:112} INFO - [2022-04-11 18:34:32,482] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:32,535] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:32,666] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:32,673] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:32,683] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:32,997] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.528 seconds
[2022-04-11 18:34:36,867] {scheduler_job.py:153} INFO - Started process (PID=20911) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:36,895] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:36,900] {logging_mixin.py:112} INFO - [2022-04-11 18:34:36,900] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:37,443] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:39,112] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:39,125] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:39,198] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:40,396] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.529 seconds
[2022-04-11 18:34:41,950] {scheduler_job.py:153} INFO - Started process (PID=20914) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:41,968] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:41,980] {logging_mixin.py:112} INFO - [2022-04-11 18:34:41,979] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:42,074] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:42,314] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:42,328] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:42,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:42,745] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.795 seconds
[2022-04-11 18:34:46,517] {scheduler_job.py:153} INFO - Started process (PID=20916) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:46,529] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:46,531] {logging_mixin.py:112} INFO - [2022-04-11 18:34:46,530] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:46,573] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:46,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:46,713] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:46,727] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:46,953] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.436 seconds
[2022-04-11 18:34:50,591] {scheduler_job.py:153} INFO - Started process (PID=20918) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:50,623] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:50,640] {logging_mixin.py:112} INFO - [2022-04-11 18:34:50,639] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:51,272] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:51,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:51,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:51,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:52,145] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.554 seconds
[2022-04-11 18:34:54,531] {scheduler_job.py:153} INFO - Started process (PID=20920) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:54,541] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:54,549] {logging_mixin.py:112} INFO - [2022-04-11 18:34:54,549] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:54,667] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:54,810] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:54,812] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:54,827] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:55,051] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.520 seconds
[2022-04-11 18:34:58,536] {scheduler_job.py:153} INFO - Started process (PID=20922) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:58,557] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:34:58,561] {logging_mixin.py:112} INFO - [2022-04-11 18:34:58,561] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:58,768] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:34:59,098] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:59,101] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:34:59,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:34:59,474] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.937 seconds
[2022-04-11 18:35:02,587] {scheduler_job.py:153} INFO - Started process (PID=20924) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:02,596] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:02,599] {logging_mixin.py:112} INFO - [2022-04-11 18:35:02,599] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:02,684] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:03,268] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:03,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:03,357] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:03,779] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.192 seconds
[2022-04-11 18:35:07,312] {scheduler_job.py:153} INFO - Started process (PID=20926) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:07,391] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:07,405] {logging_mixin.py:112} INFO - [2022-04-11 18:35:07,404] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:07,581] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:07,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:07,861] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:07,882] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:09,063] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.751 seconds
[2022-04-11 18:35:10,624] {scheduler_job.py:153} INFO - Started process (PID=20928) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:10,642] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:10,653] {logging_mixin.py:112} INFO - [2022-04-11 18:35:10,653] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:10,892] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:11,736] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:11,740] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:11,756] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:12,004] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.380 seconds
[2022-04-11 18:35:14,552] {scheduler_job.py:153} INFO - Started process (PID=20930) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:14,567] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:14,572] {logging_mixin.py:112} INFO - [2022-04-11 18:35:14,571] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:14,611] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:14,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:14,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:14,741] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:14,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.427 seconds
[2022-04-11 18:35:18,621] {scheduler_job.py:153} INFO - Started process (PID=20933) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:18,631] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:18,633] {logging_mixin.py:112} INFO - [2022-04-11 18:35:18,633] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:18,707] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:19,087] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:19,089] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:19,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:19,499] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.878 seconds
[2022-04-11 18:35:22,567] {scheduler_job.py:153} INFO - Started process (PID=20935) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:22,575] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:22,577] {logging_mixin.py:112} INFO - [2022-04-11 18:35:22,577] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:22,609] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:22,700] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:22,703] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:22,713] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:23,009] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.442 seconds
[2022-04-11 18:35:26,575] {scheduler_job.py:153} INFO - Started process (PID=20937) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:26,596] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:26,599] {logging_mixin.py:112} INFO - [2022-04-11 18:35:26,598] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:26,633] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:26,954] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:26,957] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:26,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:27,327] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.753 seconds
[2022-04-11 18:35:30,584] {scheduler_job.py:153} INFO - Started process (PID=20939) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:30,593] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:30,596] {logging_mixin.py:112} INFO - [2022-04-11 18:35:30,595] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:30,633] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:30,773] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:30,775] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:30,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:31,750] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.167 seconds
[2022-04-11 18:35:34,670] {scheduler_job.py:153} INFO - Started process (PID=20941) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:34,699] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:34,702] {logging_mixin.py:112} INFO - [2022-04-11 18:35:34,702] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:34,810] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:35,054] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:35,065] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:35,105] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:35,437] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.767 seconds
[2022-04-11 18:35:38,615] {scheduler_job.py:153} INFO - Started process (PID=20943) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:38,627] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:38,629] {logging_mixin.py:112} INFO - [2022-04-11 18:35:38,629] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:38,670] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:38,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:38,771] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:38,779] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:38,931] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-04-11 18:35:42,578] {scheduler_job.py:153} INFO - Started process (PID=20945) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:42,583] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:42,586] {logging_mixin.py:112} INFO - [2022-04-11 18:35:42,586] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:42,620] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:42,706] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:42,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:42,716] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:42,872] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.295 seconds
[2022-04-11 18:35:46,612] {scheduler_job.py:153} INFO - Started process (PID=20947) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:46,619] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:46,621] {logging_mixin.py:112} INFO - [2022-04-11 18:35:46,621] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:46,653] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:46,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:46,789] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:46,819] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:47,037] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.425 seconds
[2022-04-11 18:35:50,687] {scheduler_job.py:153} INFO - Started process (PID=20950) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:50,694] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:50,696] {logging_mixin.py:112} INFO - [2022-04-11 18:35:50,695] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:50,813] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:50,932] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:50,936] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:50,946] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:51,150] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.463 seconds
[2022-04-11 18:35:54,631] {scheduler_job.py:153} INFO - Started process (PID=20952) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:54,643] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:54,655] {logging_mixin.py:112} INFO - [2022-04-11 18:35:54,655] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:54,807] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:55,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:55,209] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:55,235] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:56,338] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.705 seconds
[2022-04-11 18:35:58,652] {scheduler_job.py:153} INFO - Started process (PID=20954) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:58,659] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:35:58,661] {logging_mixin.py:112} INFO - [2022-04-11 18:35:58,661] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:58,695] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:35:58,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:58,769] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:35:58,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:35:58,920] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.268 seconds
[2022-04-11 18:36:03,254] {scheduler_job.py:153} INFO - Started process (PID=20957) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:03,274] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:03,278] {logging_mixin.py:112} INFO - [2022-04-11 18:36:03,278] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:03,359] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:03,532] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:03,534] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:03,543] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:03,709] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.455 seconds
[2022-04-11 18:36:06,686] {scheduler_job.py:153} INFO - Started process (PID=20959) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:06,693] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:06,695] {logging_mixin.py:112} INFO - [2022-04-11 18:36:06,695] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:06,783] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:06,973] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:06,976] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:06,997] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:07,215] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.529 seconds
[2022-04-11 18:36:10,662] {scheduler_job.py:153} INFO - Started process (PID=20961) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:10,673] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:10,675] {logging_mixin.py:112} INFO - [2022-04-11 18:36:10,674] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:10,722] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:10,859] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:10,862] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:10,875] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:11,111] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.449 seconds
[2022-04-11 18:36:14,703] {scheduler_job.py:153} INFO - Started process (PID=20964) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:14,710] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:14,711] {logging_mixin.py:112} INFO - [2022-04-11 18:36:14,711] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:14,745] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:14,838] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:14,840] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:14,849] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:14,980] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.276 seconds
[2022-04-11 18:36:18,686] {scheduler_job.py:153} INFO - Started process (PID=20966) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:18,691] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:18,693] {logging_mixin.py:112} INFO - [2022-04-11 18:36:18,692] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:18,723] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:18,833] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:18,835] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:18,843] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:19,000] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 18:36:22,883] {scheduler_job.py:153} INFO - Started process (PID=20969) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:22,897] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:22,899] {logging_mixin.py:112} INFO - [2022-04-11 18:36:22,899] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:22,981] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:23,207] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:23,215] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:23,233] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:23,490] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.608 seconds
[2022-04-11 18:36:26,866] {scheduler_job.py:153} INFO - Started process (PID=20971) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:26,888] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:26,894] {logging_mixin.py:112} INFO - [2022-04-11 18:36:26,893] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:26,949] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:27,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:27,096] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:27,110] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:27,312] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.445 seconds
[2022-04-11 18:36:30,868] {scheduler_job.py:153} INFO - Started process (PID=20973) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:30,897] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:30,899] {logging_mixin.py:112} INFO - [2022-04-11 18:36:30,898] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:30,968] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:31,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:31,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:31,238] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:32,093] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.225 seconds
[2022-04-11 18:36:35,265] {scheduler_job.py:153} INFO - Started process (PID=20975) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:35,279] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:35,281] {logging_mixin.py:112} INFO - [2022-04-11 18:36:35,281] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:35,329] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:35,473] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:35,476] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:35,491] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:35,684] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-04-11 18:36:39,283] {scheduler_job.py:153} INFO - Started process (PID=20977) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:39,314] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:39,317] {logging_mixin.py:112} INFO - [2022-04-11 18:36:39,317] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:39,480] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:39,819] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:39,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:39,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:40,229] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.946 seconds
[2022-04-11 18:36:43,780] {scheduler_job.py:153} INFO - Started process (PID=20979) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:43,818] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:43,851] {logging_mixin.py:112} INFO - [2022-04-11 18:36:43,851] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:44,009] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:44,641] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:44,644] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:44,731] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:45,697] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.917 seconds
[2022-04-11 18:36:47,413] {scheduler_job.py:153} INFO - Started process (PID=20981) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:47,447] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:47,531] {logging_mixin.py:112} INFO - [2022-04-11 18:36:47,531] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:47,809] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:48,886] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:48,898] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:48,928] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:49,580] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.167 seconds
[2022-04-11 18:36:52,028] {scheduler_job.py:153} INFO - Started process (PID=20983) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:52,038] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:52,040] {logging_mixin.py:112} INFO - [2022-04-11 18:36:52,040] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:52,359] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:52,618] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:52,621] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:52,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:52,957] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.929 seconds
[2022-04-11 18:36:55,702] {scheduler_job.py:153} INFO - Started process (PID=20985) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:55,731] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:55,733] {logging_mixin.py:112} INFO - [2022-04-11 18:36:55,733] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:56,061] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:36:57,065] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:57,089] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:36:57,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:57,907] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.205 seconds
[2022-04-11 18:36:59,875] {scheduler_job.py:153} INFO - Started process (PID=20988) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:36:59,905] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:36:59,908] {logging_mixin.py:112} INFO - [2022-04-11 18:36:59,908] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:00,122] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:00,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:00,771] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:00,793] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:01,579] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.704 seconds
[2022-04-11 18:37:04,032] {scheduler_job.py:153} INFO - Started process (PID=20990) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:04,048] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:04,063] {logging_mixin.py:112} INFO - [2022-04-11 18:37:04,063] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:04,165] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:04,322] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:04,332] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:04,355] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:04,660] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.629 seconds
[2022-04-11 18:37:07,456] {scheduler_job.py:153} INFO - Started process (PID=20992) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:07,466] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:07,468] {logging_mixin.py:112} INFO - [2022-04-11 18:37:07,467] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:07,581] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:07,673] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:07,675] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:07,684] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:07,842] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.386 seconds
[2022-04-11 18:37:11,604] {scheduler_job.py:153} INFO - Started process (PID=20994) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:11,619] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:11,627] {logging_mixin.py:112} INFO - [2022-04-11 18:37:11,626] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:11,678] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:11,773] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:11,776] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:11,786] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:12,045] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.442 seconds
[2022-04-11 18:37:15,617] {scheduler_job.py:153} INFO - Started process (PID=20996) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:15,632] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:15,635] {logging_mixin.py:112} INFO - [2022-04-11 18:37:15,634] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:15,710] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:15,890] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:15,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:15,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:16,122] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.505 seconds
[2022-04-11 18:37:21,411] {scheduler_job.py:153} INFO - Started process (PID=20999) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:21,420] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:21,430] {logging_mixin.py:112} INFO - [2022-04-11 18:37:21,429] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:21,529] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:21,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:21,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:21,743] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:21,968] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.557 seconds
[2022-04-11 18:37:27,781] {scheduler_job.py:153} INFO - Started process (PID=21002) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:27,817] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:27,830] {logging_mixin.py:112} INFO - [2022-04-11 18:37:27,830] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:28,461] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:29,330] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:29,333] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:29,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:30,019] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.238 seconds
[2022-04-11 18:37:34,221] {scheduler_job.py:153} INFO - Started process (PID=21006) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:34,288] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:34,305] {logging_mixin.py:112} INFO - [2022-04-11 18:37:34,305] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:34,783] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:35,107] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:35,110] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:35,140] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:35,500] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.279 seconds
[2022-04-11 18:37:40,209] {scheduler_job.py:153} INFO - Started process (PID=21009) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:40,254] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:40,273] {logging_mixin.py:112} INFO - [2022-04-11 18:37:40,273] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:40,413] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:40,808] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:40,810] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:40,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:41,057] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.850 seconds
[2022-04-11 18:37:46,400] {scheduler_job.py:153} INFO - Started process (PID=21012) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:46,437] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:46,452] {logging_mixin.py:112} INFO - [2022-04-11 18:37:46,452] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:47,585] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:50,302] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:50,313] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:50,347] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:50,585] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.186 seconds
[2022-04-11 18:37:53,587] {scheduler_job.py:153} INFO - Started process (PID=21015) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:53,605] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:53,613] {logging_mixin.py:112} INFO - [2022-04-11 18:37:53,613] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:53,703] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:53,916] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:53,918] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:53,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:54,184] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.598 seconds
[2022-04-11 18:37:59,597] {scheduler_job.py:153} INFO - Started process (PID=21018) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:59,609] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:37:59,612] {logging_mixin.py:112} INFO - [2022-04-11 18:37:59,611] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:37:59,662] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:37:59,814] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:59,816] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:37:59,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:00,025] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.428 seconds
[2022-04-11 18:38:05,655] {scheduler_job.py:153} INFO - Started process (PID=21021) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:05,672] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:05,691] {logging_mixin.py:112} INFO - [2022-04-11 18:38:05,691] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:05,883] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:06,968] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:06,979] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:06,993] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:07,227] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.573 seconds
[2022-04-11 18:38:11,637] {scheduler_job.py:153} INFO - Started process (PID=21025) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:11,645] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:11,647] {logging_mixin.py:112} INFO - [2022-04-11 18:38:11,647] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:11,816] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:11,956] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:11,958] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:11,971] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:12,763] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.127 seconds
[2022-04-11 18:38:17,618] {scheduler_job.py:153} INFO - Started process (PID=21028) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:17,631] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:17,633] {logging_mixin.py:112} INFO - [2022-04-11 18:38:17,632] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:17,728] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:17,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:17,992] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:18,020] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:18,304] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.686 seconds
[2022-04-11 18:38:23,630] {scheduler_job.py:153} INFO - Started process (PID=21031) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:23,636] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:23,640] {logging_mixin.py:112} INFO - [2022-04-11 18:38:23,640] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:23,681] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:23,793] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:23,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:23,805] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:24,000] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.370 seconds
[2022-04-11 18:38:29,637] {scheduler_job.py:153} INFO - Started process (PID=21034) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:29,643] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:29,644] {logging_mixin.py:112} INFO - [2022-04-11 18:38:29,644] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:29,677] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:29,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:29,793] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:29,803] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:29,948] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.311 seconds
[2022-04-11 18:38:35,734] {scheduler_job.py:153} INFO - Started process (PID=21037) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:35,755] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:35,758] {logging_mixin.py:112} INFO - [2022-04-11 18:38:35,757] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:35,826] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:36,047] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:36,049] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:36,058] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:36,231] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.497 seconds
[2022-04-11 18:38:41,677] {scheduler_job.py:153} INFO - Started process (PID=21040) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:41,688] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:41,690] {logging_mixin.py:112} INFO - [2022-04-11 18:38:41,690] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:41,831] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:41,930] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:41,932] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:41,942] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:42,090] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.413 seconds
[2022-04-11 18:38:47,675] {scheduler_job.py:153} INFO - Started process (PID=21044) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:47,685] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:47,687] {logging_mixin.py:112} INFO - [2022-04-11 18:38:47,686] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:47,722] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:47,861] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:47,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:47,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:48,040] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.366 seconds
[2022-04-11 18:38:53,736] {scheduler_job.py:153} INFO - Started process (PID=21047) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:53,745] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:53,757] {logging_mixin.py:112} INFO - [2022-04-11 18:38:53,757] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:53,892] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:54,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:54,071] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:54,084] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:54,328] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.596 seconds
[2022-04-11 18:38:59,737] {scheduler_job.py:153} INFO - Started process (PID=21050) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:59,768] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:38:59,778] {logging_mixin.py:112} INFO - [2022-04-11 18:38:59,778] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:38:59,862] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:38:59,995] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:38:59,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:00,006] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:00,227] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.490 seconds
[2022-04-11 18:39:05,740] {scheduler_job.py:153} INFO - Started process (PID=21053) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:05,750] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:05,753] {logging_mixin.py:112} INFO - [2022-04-11 18:39:05,753] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:05,804] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:06,037] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:06,039] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:06,048] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:06,378] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.638 seconds
[2022-04-11 18:39:11,704] {scheduler_job.py:153} INFO - Started process (PID=21056) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:11,714] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:11,715] {logging_mixin.py:112} INFO - [2022-04-11 18:39:11,715] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:11,750] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:11,853] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:11,855] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:11,865] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:12,050] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.346 seconds
[2022-04-11 18:39:17,972] {scheduler_job.py:153} INFO - Started process (PID=21060) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:17,990] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:18,004] {logging_mixin.py:112} INFO - [2022-04-11 18:39:18,003] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:18,500] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:18,970] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:18,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:19,024] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:19,451] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.479 seconds
[2022-04-11 18:39:23,777] {scheduler_job.py:153} INFO - Started process (PID=21063) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:23,805] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:23,809] {logging_mixin.py:112} INFO - [2022-04-11 18:39:23,808] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:23,850] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:24,207] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:24,209] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:24,219] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:24,463] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.685 seconds
[2022-04-11 18:39:30,017] {scheduler_job.py:153} INFO - Started process (PID=21066) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:30,035] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:30,041] {logging_mixin.py:112} INFO - [2022-04-11 18:39:30,041] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:30,296] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:30,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:30,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:30,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:30,969] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.952 seconds
[2022-04-11 18:39:35,721] {scheduler_job.py:153} INFO - Started process (PID=21069) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:35,730] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:35,732] {logging_mixin.py:112} INFO - [2022-04-11 18:39:35,732] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:35,770] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:35,981] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:35,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:35,993] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:36,952] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.231 seconds
[2022-04-11 18:39:41,762] {scheduler_job.py:153} INFO - Started process (PID=21072) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:41,772] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:41,776] {logging_mixin.py:112} INFO - [2022-04-11 18:39:41,775] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:41,875] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:42,050] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:42,053] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:42,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:42,380] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.628 seconds
[2022-04-11 18:39:47,766] {scheduler_job.py:153} INFO - Started process (PID=21075) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:47,784] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:47,791] {logging_mixin.py:112} INFO - [2022-04-11 18:39:47,791] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:47,861] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:48,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:48,071] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:48,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:48,347] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.581 seconds
[2022-04-11 18:39:53,798] {scheduler_job.py:153} INFO - Started process (PID=21079) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:53,812] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:53,827] {logging_mixin.py:112} INFO - [2022-04-11 18:39:53,826] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:53,897] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:54,088] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:54,096] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:54,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:54,502] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.704 seconds
[2022-04-11 18:39:59,772] {scheduler_job.py:153} INFO - Started process (PID=21082) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:59,784] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:39:59,790] {logging_mixin.py:112} INFO - [2022-04-11 18:39:59,789] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:39:59,844] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:39:59,996] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:39:59,998] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:00,010] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:00,207] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.436 seconds
[2022-04-11 18:40:05,785] {scheduler_job.py:153} INFO - Started process (PID=21085) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:05,798] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:05,799] {logging_mixin.py:112} INFO - [2022-04-11 18:40:05,799] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:05,862] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:06,029] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:06,032] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:06,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:06,332] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.547 seconds
[2022-04-11 18:40:11,794] {scheduler_job.py:153} INFO - Started process (PID=21088) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:11,802] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:11,805] {logging_mixin.py:112} INFO - [2022-04-11 18:40:11,804] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:11,857] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:12,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:12,008] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:12,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:12,199] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.407 seconds
[2022-04-11 18:40:17,803] {scheduler_job.py:153} INFO - Started process (PID=21091) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:17,817] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:17,822] {logging_mixin.py:112} INFO - [2022-04-11 18:40:17,821] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:17,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:18,019] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:18,032] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:18,049] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:18,249] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.446 seconds
[2022-04-11 18:40:23,800] {scheduler_job.py:153} INFO - Started process (PID=21094) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:23,816] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:23,820] {logging_mixin.py:112} INFO - [2022-04-11 18:40:23,820] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:23,892] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:24,030] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:24,032] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:24,047] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:24,249] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.449 seconds
[2022-04-11 18:40:32,437] {scheduler_job.py:153} INFO - Started process (PID=21098) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:32,468] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:32,484] {logging_mixin.py:112} INFO - [2022-04-11 18:40:32,484] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:32,616] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:32,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:32,940] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:33,014] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:35,439] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.003 seconds
[2022-04-11 18:40:36,888] {scheduler_job.py:153} INFO - Started process (PID=21101) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:36,904] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:36,909] {logging_mixin.py:112} INFO - [2022-04-11 18:40:36,908] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:36,964] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:37,147] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:37,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:37,163] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:37,416] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.528 seconds
[2022-04-11 18:40:43,208] {scheduler_job.py:153} INFO - Started process (PID=21104) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:43,222] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:43,229] {logging_mixin.py:112} INFO - [2022-04-11 18:40:43,229] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:43,308] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:43,536] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:43,541] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:43,570] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:43,845] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.638 seconds
[2022-04-11 18:40:49,666] {scheduler_job.py:153} INFO - Started process (PID=21107) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:49,683] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:49,685] {logging_mixin.py:112} INFO - [2022-04-11 18:40:49,685] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:49,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:49,985] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:49,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:50,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:52,419] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.753 seconds
[2022-04-11 18:40:56,479] {scheduler_job.py:153} INFO - Started process (PID=21110) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:56,488] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:40:56,490] {logging_mixin.py:112} INFO - [2022-04-11 18:40:56,489] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:56,544] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:40:56,762] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:56,764] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:40:56,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:40:57,208] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.729 seconds
[2022-04-11 18:41:00,891] {scheduler_job.py:153} INFO - Started process (PID=21113) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:00,903] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:00,905] {logging_mixin.py:112} INFO - [2022-04-11 18:41:00,905] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:00,956] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:01,465] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:01,468] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:01,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:01,977] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.086 seconds
[2022-04-11 18:41:06,996] {scheduler_job.py:153} INFO - Started process (PID=21117) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:07,006] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:07,008] {logging_mixin.py:112} INFO - [2022-04-11 18:41:07,007] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:07,058] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:07,236] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:07,238] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:07,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:07,495] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.499 seconds
[2022-04-11 18:41:12,947] {scheduler_job.py:153} INFO - Started process (PID=21120) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:12,964] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:12,966] {logging_mixin.py:112} INFO - [2022-04-11 18:41:12,966] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:13,051] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:13,253] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:13,256] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:13,277] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:13,615] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.668 seconds
[2022-04-11 18:41:19,590] {scheduler_job.py:153} INFO - Started process (PID=21123) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:19,604] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:19,610] {logging_mixin.py:112} INFO - [2022-04-11 18:41:19,610] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:19,678] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:19,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:19,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:19,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:20,099] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.509 seconds
[2022-04-11 18:41:25,513] {scheduler_job.py:153} INFO - Started process (PID=21126) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:25,537] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:25,549] {logging_mixin.py:112} INFO - [2022-04-11 18:41:25,548] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:25,752] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:26,074] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:26,078] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:26,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:26,667] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.154 seconds
[2022-04-11 18:41:31,200] {scheduler_job.py:153} INFO - Started process (PID=21129) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:31,225] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:31,228] {logging_mixin.py:112} INFO - [2022-04-11 18:41:31,227] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:31,363] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:31,633] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:31,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:31,651] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:31,878] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.679 seconds
[2022-04-11 18:41:37,003] {scheduler_job.py:153} INFO - Started process (PID=21132) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:37,031] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:37,034] {logging_mixin.py:112} INFO - [2022-04-11 18:41:37,034] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:37,108] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:37,410] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:37,413] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:37,436] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:37,751] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.748 seconds
[2022-04-11 18:41:43,494] {scheduler_job.py:153} INFO - Started process (PID=21136) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:43,517] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:43,524] {logging_mixin.py:112} INFO - [2022-04-11 18:41:43,523] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:43,800] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:45,452] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:45,460] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:45,563] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:48,094] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.600 seconds
[2022-04-11 18:41:50,470] {scheduler_job.py:153} INFO - Started process (PID=21139) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:50,482] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:50,484] {logging_mixin.py:112} INFO - [2022-04-11 18:41:50,483] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:50,593] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:50,738] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:50,754] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:50,785] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:51,019] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.549 seconds
[2022-04-11 18:41:55,651] {scheduler_job.py:153} INFO - Started process (PID=21142) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:55,670] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:41:55,683] {logging_mixin.py:112} INFO - [2022-04-11 18:41:55,683] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:55,999] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:41:56,257] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:56,261] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:41:56,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:41:56,931] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.280 seconds
[2022-04-11 18:42:01,318] {scheduler_job.py:153} INFO - Started process (PID=21145) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:01,336] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:01,341] {logging_mixin.py:112} INFO - [2022-04-11 18:42:01,341] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:01,562] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:01,935] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:01,942] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:01,965] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:02,242] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.923 seconds
[2022-04-11 18:42:07,248] {scheduler_job.py:153} INFO - Started process (PID=21148) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:07,266] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:07,274] {logging_mixin.py:112} INFO - [2022-04-11 18:42:07,273] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:07,411] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:07,646] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:07,650] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:07,665] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:08,131] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.883 seconds
[2022-04-11 18:42:13,286] {scheduler_job.py:153} INFO - Started process (PID=21151) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:13,294] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:13,296] {logging_mixin.py:112} INFO - [2022-04-11 18:42:13,296] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:13,350] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:13,549] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:13,552] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:13,567] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:13,763] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.477 seconds
[2022-04-11 18:42:19,358] {scheduler_job.py:153} INFO - Started process (PID=21155) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:19,369] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:19,371] {logging_mixin.py:112} INFO - [2022-04-11 18:42:19,371] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:19,434] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:19,586] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:19,588] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:19,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:19,821] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.460 seconds
[2022-04-11 18:42:25,329] {scheduler_job.py:153} INFO - Started process (PID=21158) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:25,349] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:25,360] {logging_mixin.py:112} INFO - [2022-04-11 18:42:25,360] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:25,437] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:25,542] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:25,544] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:25,552] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:25,801] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.472 seconds
[2022-04-11 18:42:31,738] {scheduler_job.py:153} INFO - Started process (PID=21161) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:31,767] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:31,770] {logging_mixin.py:112} INFO - [2022-04-11 18:42:31,770] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:31,832] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:32,108] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:32,110] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:32,126] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:33,215] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.477 seconds
[2022-04-11 18:42:37,332] {scheduler_job.py:153} INFO - Started process (PID=21164) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:37,350] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:37,352] {logging_mixin.py:112} INFO - [2022-04-11 18:42:37,352] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:37,419] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:37,972] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:37,984] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:38,019] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:38,829] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.498 seconds
[2022-04-11 18:42:44,250] {scheduler_job.py:153} INFO - Started process (PID=21167) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:44,267] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:44,275] {logging_mixin.py:112} INFO - [2022-04-11 18:42:44,275] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:44,462] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:44,686] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:44,691] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:44,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:44,950] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.700 seconds
[2022-04-11 18:42:49,486] {scheduler_job.py:153} INFO - Started process (PID=21170) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:49,538] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:49,564] {logging_mixin.py:112} INFO - [2022-04-11 18:42:49,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:50,384] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:50,593] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:50,595] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:50,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:51,347] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.861 seconds
[2022-04-11 18:42:56,347] {scheduler_job.py:153} INFO - Started process (PID=21174) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:56,514] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:42:56,543] {logging_mixin.py:112} INFO - [2022-04-11 18:42:56,543] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:56,815] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:42:57,188] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:57,190] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:42:57,205] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:42:57,412] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.065 seconds
[2022-04-11 18:43:01,986] {scheduler_job.py:153} INFO - Started process (PID=21177) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:02,001] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:02,005] {logging_mixin.py:112} INFO - [2022-04-11 18:43:02,005] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:02,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:02,344] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:02,350] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:02,375] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:02,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.695 seconds
[2022-04-11 18:43:08,011] {scheduler_job.py:153} INFO - Started process (PID=21180) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:08,022] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:08,024] {logging_mixin.py:112} INFO - [2022-04-11 18:43:08,024] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:08,145] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:08,474] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:08,482] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:08,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:09,092] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.081 seconds
[2022-04-11 18:43:13,998] {scheduler_job.py:153} INFO - Started process (PID=21183) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:14,006] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:14,007] {logging_mixin.py:112} INFO - [2022-04-11 18:43:14,007] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:14,113] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:14,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:14,266] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:14,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:14,508] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.510 seconds
[2022-04-11 18:43:20,064] {scheduler_job.py:153} INFO - Started process (PID=21186) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:20,080] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:20,082] {logging_mixin.py:112} INFO - [2022-04-11 18:43:20,082] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:20,306] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:20,575] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:20,587] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:20,646] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:20,873] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.809 seconds
[2022-04-11 18:43:26,041] {scheduler_job.py:153} INFO - Started process (PID=21189) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:26,051] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:26,057] {logging_mixin.py:112} INFO - [2022-04-11 18:43:26,057] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:26,477] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:26,811] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:26,815] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:26,829] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:27,081] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.040 seconds
[2022-04-11 18:43:34,216] {scheduler_job.py:153} INFO - Started process (PID=21193) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:34,256] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:34,268] {logging_mixin.py:112} INFO - [2022-04-11 18:43:34,267] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:34,777] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:35,370] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:35,377] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:35,416] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:35,850] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.634 seconds
[2022-04-11 18:43:38,149] {scheduler_job.py:153} INFO - Started process (PID=21196) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:38,168] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:38,182] {logging_mixin.py:112} INFO - [2022-04-11 18:43:38,181] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:38,661] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:39,223] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:39,231] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:39,268] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:39,884] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.736 seconds
[2022-04-11 18:43:44,207] {scheduler_job.py:153} INFO - Started process (PID=21199) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:44,225] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:44,227] {logging_mixin.py:112} INFO - [2022-04-11 18:43:44,227] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:44,323] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:44,964] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:44,966] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:44,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:45,599] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.392 seconds
[2022-04-11 18:43:50,227] {scheduler_job.py:153} INFO - Started process (PID=21202) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:50,241] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:50,244] {logging_mixin.py:112} INFO - [2022-04-11 18:43:50,244] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:50,400] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:50,978] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:50,992] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:51,043] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:51,861] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.634 seconds
[2022-04-11 18:43:56,226] {scheduler_job.py:153} INFO - Started process (PID=21205) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:56,254] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:43:56,257] {logging_mixin.py:112} INFO - [2022-04-11 18:43:56,257] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:56,381] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:43:56,883] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:56,897] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:43:56,924] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:43:57,865] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.639 seconds
[2022-04-11 18:44:02,466] {scheduler_job.py:153} INFO - Started process (PID=21208) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:02,492] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:02,497] {logging_mixin.py:112} INFO - [2022-04-11 18:44:02,496] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:02,950] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:03,461] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:03,463] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:03,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:03,907] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.451 seconds
[2022-04-11 18:44:08,867] {scheduler_job.py:153} INFO - Started process (PID=21212) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:08,887] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:08,897] {logging_mixin.py:112} INFO - [2022-04-11 18:44:08,892] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:08,974] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:09,266] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:09,269] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:09,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:09,731] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.864 seconds
[2022-04-11 18:44:14,464] {scheduler_job.py:153} INFO - Started process (PID=21215) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:14,486] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:14,502] {logging_mixin.py:112} INFO - [2022-04-11 18:44:14,501] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:14,692] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:14,963] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:14,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:14,983] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:15,291] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.827 seconds
[2022-04-11 18:44:20,449] {scheduler_job.py:153} INFO - Started process (PID=21218) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:20,461] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:20,477] {logging_mixin.py:112} INFO - [2022-04-11 18:44:20,476] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:20,609] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:20,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:20,881] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:20,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:21,637] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.188 seconds
[2022-04-11 18:44:26,400] {scheduler_job.py:153} INFO - Started process (PID=21221) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:26,414] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:26,416] {logging_mixin.py:112} INFO - [2022-04-11 18:44:26,416] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:26,455] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:26,582] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:26,585] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:26,593] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:26,761] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.361 seconds
[2022-04-11 18:44:32,451] {scheduler_job.py:153} INFO - Started process (PID=21224) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:32,461] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:32,463] {logging_mixin.py:112} INFO - [2022-04-11 18:44:32,463] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:32,572] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:32,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:32,856] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:32,865] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:33,122] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.671 seconds
[2022-04-11 18:44:38,409] {scheduler_job.py:153} INFO - Started process (PID=21227) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:38,416] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:38,417] {logging_mixin.py:112} INFO - [2022-04-11 18:44:38,417] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:38,457] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:38,634] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:38,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:38,659] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:38,885] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.476 seconds
[2022-04-11 18:44:44,623] {scheduler_job.py:153} INFO - Started process (PID=21231) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:44,642] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:44,674] {logging_mixin.py:112} INFO - [2022-04-11 18:44:44,673] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:44,771] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:45,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:45,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:45,077] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:45,423] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.800 seconds
[2022-04-11 18:44:50,455] {scheduler_job.py:153} INFO - Started process (PID=21234) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:50,471] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:50,477] {logging_mixin.py:112} INFO - [2022-04-11 18:44:50,477] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:50,548] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:50,724] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:50,726] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:50,742] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:50,933] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.478 seconds
[2022-04-11 18:44:56,460] {scheduler_job.py:153} INFO - Started process (PID=21237) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:56,471] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:44:56,474] {logging_mixin.py:112} INFO - [2022-04-11 18:44:56,474] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:56,554] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:44:56,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:56,713] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:44:56,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:44:56,914] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-04-11 18:45:02,467] {scheduler_job.py:153} INFO - Started process (PID=21240) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:02,480] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:02,483] {logging_mixin.py:112} INFO - [2022-04-11 18:45:02,482] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:02,592] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:02,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:02,719] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:02,734] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:02,950] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.484 seconds
[2022-04-11 18:45:08,487] {scheduler_job.py:153} INFO - Started process (PID=21243) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:08,520] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:08,525] {logging_mixin.py:112} INFO - [2022-04-11 18:45:08,524] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:08,579] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:08,714] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:08,716] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:08,730] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:08,981] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.505 seconds
[2022-04-11 18:45:14,782] {scheduler_job.py:153} INFO - Started process (PID=21246) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:14,816] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:14,870] {logging_mixin.py:112} INFO - [2022-04-11 18:45:14,870] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:15,152] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:15,308] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:15,310] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:15,321] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:16,287] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.506 seconds
[2022-04-11 18:45:20,472] {scheduler_job.py:153} INFO - Started process (PID=21250) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:20,477] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:20,479] {logging_mixin.py:112} INFO - [2022-04-11 18:45:20,479] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:20,516] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:20,633] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:20,635] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:20,644] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:20,862] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.390 seconds
[2022-04-11 18:45:26,483] {scheduler_job.py:153} INFO - Started process (PID=21253) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:26,496] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:26,498] {logging_mixin.py:112} INFO - [2022-04-11 18:45:26,497] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:26,534] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:26,704] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:26,706] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:26,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:26,943] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.460 seconds
[2022-04-11 18:45:32,503] {scheduler_job.py:153} INFO - Started process (PID=21256) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:32,521] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:32,533] {logging_mixin.py:112} INFO - [2022-04-11 18:45:32,533] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:32,591] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:32,749] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:32,753] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:32,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:32,978] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.475 seconds
[2022-04-11 18:45:38,533] {scheduler_job.py:153} INFO - Started process (PID=21259) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:38,559] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:38,565] {logging_mixin.py:112} INFO - [2022-04-11 18:45:38,565] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:38,675] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:38,913] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:38,921] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:38,942] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:39,645] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.113 seconds
[2022-04-11 18:45:44,578] {scheduler_job.py:153} INFO - Started process (PID=21262) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:44,596] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:44,616] {logging_mixin.py:112} INFO - [2022-04-11 18:45:44,616] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:44,996] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:45,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:45,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:45,473] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:45,911] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.333 seconds
[2022-04-11 18:45:50,515] {scheduler_job.py:153} INFO - Started process (PID=21266) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:50,532] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:50,535] {logging_mixin.py:112} INFO - [2022-04-11 18:45:50,534] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:50,591] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:50,841] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:50,843] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:50,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:51,064] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.549 seconds
[2022-04-11 18:45:56,516] {scheduler_job.py:153} INFO - Started process (PID=21269) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:56,524] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:45:56,526] {logging_mixin.py:112} INFO - [2022-04-11 18:45:56,526] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:56,566] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:45:56,696] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:56,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:45:56,707] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:45:56,906] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.390 seconds
[2022-04-11 18:46:02,538] {scheduler_job.py:153} INFO - Started process (PID=21272) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:02,545] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:02,546] {logging_mixin.py:112} INFO - [2022-04-11 18:46:02,546] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:02,592] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:02,692] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:02,694] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:02,705] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:02,876] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.338 seconds
[2022-04-11 18:46:08,558] {scheduler_job.py:153} INFO - Started process (PID=21275) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:08,569] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:08,571] {logging_mixin.py:112} INFO - [2022-04-11 18:46:08,571] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:08,601] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:08,696] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:08,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:08,706] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:08,860] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.302 seconds
[2022-04-11 18:46:14,539] {scheduler_job.py:153} INFO - Started process (PID=21278) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:14,543] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:14,545] {logging_mixin.py:112} INFO - [2022-04-11 18:46:14,545] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:14,591] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:14,705] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:14,707] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:14,715] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:14,897] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.358 seconds
[2022-04-11 18:46:20,555] {scheduler_job.py:153} INFO - Started process (PID=21281) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:20,562] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:20,563] {logging_mixin.py:112} INFO - [2022-04-11 18:46:20,563] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:20,592] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:20,686] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:20,687] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:20,697] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:20,869] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 18:46:26,548] {scheduler_job.py:153} INFO - Started process (PID=21285) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:26,557] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:26,559] {logging_mixin.py:112} INFO - [2022-04-11 18:46:26,559] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:26,599] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:26,709] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:26,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:26,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:26,961] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.413 seconds
[2022-04-11 18:46:32,570] {scheduler_job.py:153} INFO - Started process (PID=21288) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:32,577] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:32,578] {logging_mixin.py:112} INFO - [2022-04-11 18:46:32,578] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:32,611] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:32,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:32,769] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:32,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:32,923] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.353 seconds
[2022-04-11 18:46:38,575] {scheduler_job.py:153} INFO - Started process (PID=21291) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:38,582] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:38,583] {logging_mixin.py:112} INFO - [2022-04-11 18:46:38,583] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:38,613] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:38,705] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:38,707] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:38,714] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:38,872] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.297 seconds
[2022-04-11 18:46:44,601] {scheduler_job.py:153} INFO - Started process (PID=21294) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:44,612] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:44,614] {logging_mixin.py:112} INFO - [2022-04-11 18:46:44,614] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:44,643] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:44,771] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:44,773] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:44,781] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:44,960] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.359 seconds
[2022-04-11 18:46:50,599] {scheduler_job.py:153} INFO - Started process (PID=21297) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:50,605] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:50,607] {logging_mixin.py:112} INFO - [2022-04-11 18:46:50,606] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:50,647] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:50,898] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:50,899] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:50,910] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:51,073] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.474 seconds
[2022-04-11 18:46:56,618] {scheduler_job.py:153} INFO - Started process (PID=21301) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:56,624] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:46:56,626] {logging_mixin.py:112} INFO - [2022-04-11 18:46:56,625] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:56,676] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:46:56,843] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:56,845] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:46:56,856] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:46:57,064] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.447 seconds
[2022-04-11 18:47:02,605] {scheduler_job.py:153} INFO - Started process (PID=21304) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:02,612] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:02,614] {logging_mixin.py:112} INFO - [2022-04-11 18:47:02,614] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:02,645] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:02,777] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:02,779] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:02,789] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:02,946] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.341 seconds
[2022-04-11 18:47:08,635] {scheduler_job.py:153} INFO - Started process (PID=21307) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:08,644] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:08,645] {logging_mixin.py:112} INFO - [2022-04-11 18:47:08,645] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:08,679] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:08,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:08,776] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:08,783] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:08,929] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.294 seconds
[2022-04-11 18:47:14,631] {scheduler_job.py:153} INFO - Started process (PID=21310) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:14,637] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:14,639] {logging_mixin.py:112} INFO - [2022-04-11 18:47:14,638] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:14,667] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:14,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:14,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:14,805] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:14,958] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-04-11 18:47:20,654] {scheduler_job.py:153} INFO - Started process (PID=21313) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:20,664] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:20,665] {logging_mixin.py:112} INFO - [2022-04-11 18:47:20,665] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:20,694] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:20,787] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:20,789] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:20,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:20,963] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.309 seconds
[2022-04-11 18:47:26,652] {scheduler_job.py:153} INFO - Started process (PID=21316) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:26,658] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:26,660] {logging_mixin.py:112} INFO - [2022-04-11 18:47:26,659] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:26,691] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:26,789] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:26,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:26,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:27,012] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.360 seconds
[2022-04-11 18:47:32,656] {scheduler_job.py:153} INFO - Started process (PID=21320) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:32,664] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:32,665] {logging_mixin.py:112} INFO - [2022-04-11 18:47:32,665] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:32,692] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:32,807] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:32,809] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:32,816] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:33,035] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.380 seconds
[2022-04-11 18:47:38,666] {scheduler_job.py:153} INFO - Started process (PID=21323) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:38,674] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:38,676] {logging_mixin.py:112} INFO - [2022-04-11 18:47:38,676] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:38,708] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:38,801] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:38,803] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:38,812] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:38,957] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.291 seconds
[2022-04-11 18:47:44,675] {scheduler_job.py:153} INFO - Started process (PID=21326) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:44,680] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:44,682] {logging_mixin.py:112} INFO - [2022-04-11 18:47:44,682] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:44,721] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:44,815] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:44,817] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:44,824] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:44,962] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.288 seconds
[2022-04-11 18:47:50,688] {scheduler_job.py:153} INFO - Started process (PID=21329) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:50,693] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:50,695] {logging_mixin.py:112} INFO - [2022-04-11 18:47:50,694] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:50,733] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:50,837] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:50,839] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:50,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:51,047] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.359 seconds
[2022-04-11 18:47:56,852] {scheduler_job.py:153} INFO - Started process (PID=21332) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:56,867] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:47:56,875] {logging_mixin.py:112} INFO - [2022-04-11 18:47:56,875] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:57,049] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:47:57,433] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:57,435] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:47:57,458] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:47:57,809] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.958 seconds
[2022-04-11 18:48:03,893] {scheduler_job.py:153} INFO - Started process (PID=21336) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:03,964] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:03,966] {logging_mixin.py:112} INFO - [2022-04-11 18:48:03,966] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:04,232] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:04,836] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:04,848] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:04,887] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:05,714] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.821 seconds
[2022-04-11 18:48:11,446] {scheduler_job.py:153} INFO - Started process (PID=21339) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:11,482] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:11,488] {logging_mixin.py:112} INFO - [2022-04-11 18:48:11,484] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:11,750] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:12,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:12,134] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:12,159] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:12,813] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.367 seconds
[2022-04-11 18:48:15,868] {scheduler_job.py:153} INFO - Started process (PID=21342) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:15,946] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:15,949] {logging_mixin.py:112} INFO - [2022-04-11 18:48:15,949] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:16,299] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:17,014] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:17,018] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:17,060] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:17,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.813 seconds
[2022-04-11 18:48:21,835] {scheduler_job.py:153} INFO - Started process (PID=21345) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:21,861] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:21,863] {logging_mixin.py:112} INFO - [2022-04-11 18:48:21,863] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:22,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:22,546] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:22,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:22,579] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:22,962] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.128 seconds
[2022-04-11 18:48:28,142] {scheduler_job.py:153} INFO - Started process (PID=21348) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:28,175] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:28,180] {logging_mixin.py:112} INFO - [2022-04-11 18:48:28,179] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:28,426] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:28,929] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:28,941] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:28,963] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:29,427] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.285 seconds
[2022-04-11 18:48:33,727] {scheduler_job.py:153} INFO - Started process (PID=21351) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:33,748] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:33,757] {logging_mixin.py:112} INFO - [2022-04-11 18:48:33,757] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:33,898] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:34,107] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:34,110] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:34,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:34,278] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.551 seconds
[2022-04-11 18:48:39,682] {scheduler_job.py:153} INFO - Started process (PID=21354) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:39,690] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:39,692] {logging_mixin.py:112} INFO - [2022-04-11 18:48:39,692] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:39,733] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:39,901] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:39,904] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:39,914] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:40,111] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.430 seconds
[2022-04-11 18:48:45,845] {scheduler_job.py:153} INFO - Started process (PID=21358) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:45,864] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:45,873] {logging_mixin.py:112} INFO - [2022-04-11 18:48:45,873] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:45,946] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:46,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:46,094] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:46,118] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:46,558] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.713 seconds
[2022-04-11 18:48:52,131] {scheduler_job.py:153} INFO - Started process (PID=21361) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:52,152] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:52,154] {logging_mixin.py:112} INFO - [2022-04-11 18:48:52,153] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:52,280] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:52,484] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:52,488] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:52,518] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:52,860] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.729 seconds
[2022-04-11 18:48:57,749] {scheduler_job.py:153} INFO - Started process (PID=21364) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:57,773] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:48:57,788] {logging_mixin.py:112} INFO - [2022-04-11 18:48:57,788] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:58,037] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:48:58,387] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:58,406] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:48:58,451] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:48:59,023] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.274 seconds
[2022-04-11 18:49:03,969] {scheduler_job.py:153} INFO - Started process (PID=21367) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:03,996] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:04,011] {logging_mixin.py:112} INFO - [2022-04-11 18:49:04,010] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:04,105] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:04,246] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:04,261] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:04,277] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:04,644] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.675 seconds
[2022-04-11 18:49:09,753] {scheduler_job.py:153} INFO - Started process (PID=21370) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:09,767] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:09,772] {logging_mixin.py:112} INFO - [2022-04-11 18:49:09,772] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:09,851] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:10,117] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:10,121] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:10,134] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:10,356] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.603 seconds
[2022-04-11 18:49:15,798] {scheduler_job.py:153} INFO - Started process (PID=21373) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:15,827] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:15,834] {logging_mixin.py:112} INFO - [2022-04-11 18:49:15,834] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:16,111] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:16,301] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:16,314] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:16,372] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:16,656] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.858 seconds
[2022-04-11 18:49:21,777] {scheduler_job.py:153} INFO - Started process (PID=21377) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:21,786] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:21,789] {logging_mixin.py:112} INFO - [2022-04-11 18:49:21,788] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:21,864] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:22,024] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:22,026] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:22,041] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:23,267] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.490 seconds
[2022-04-11 18:49:27,976] {scheduler_job.py:153} INFO - Started process (PID=21380) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:28,004] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:28,014] {logging_mixin.py:112} INFO - [2022-04-11 18:49:28,013] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:28,477] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:29,270] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:29,276] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:29,305] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:29,559] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.583 seconds
[2022-04-11 18:49:34,128] {scheduler_job.py:153} INFO - Started process (PID=21383) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:34,137] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:34,139] {logging_mixin.py:112} INFO - [2022-04-11 18:49:34,139] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:34,198] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:34,931] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:34,943] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:34,962] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:35,336] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.209 seconds
[2022-04-11 18:49:40,344] {scheduler_job.py:153} INFO - Started process (PID=21386) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:40,358] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:40,361] {logging_mixin.py:112} INFO - [2022-04-11 18:49:40,360] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:40,462] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:40,695] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:40,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:40,708] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:40,935] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.591 seconds
[2022-04-11 18:49:46,156] {scheduler_job.py:153} INFO - Started process (PID=21389) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:46,172] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:46,175] {logging_mixin.py:112} INFO - [2022-04-11 18:49:46,174] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:46,273] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:46,409] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:46,412] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:46,431] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:46,636] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.481 seconds
[2022-04-11 18:49:53,256] {scheduler_job.py:153} INFO - Started process (PID=21392) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:53,322] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:49:53,351] {logging_mixin.py:112} INFO - [2022-04-11 18:49:53,351] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:54,373] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:49:55,379] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:55,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:49:55,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:49:56,255] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.015 seconds
[2022-04-11 18:50:00,144] {scheduler_job.py:153} INFO - Started process (PID=21396) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:00,166] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:00,170] {logging_mixin.py:112} INFO - [2022-04-11 18:50:00,170] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:00,350] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:00,478] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:00,480] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:00,503] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:00,744] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.609 seconds
[2022-04-11 18:50:05,587] {scheduler_job.py:153} INFO - Started process (PID=21399) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:05,597] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:05,599] {logging_mixin.py:112} INFO - [2022-04-11 18:50:05,599] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:05,710] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:05,847] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:05,850] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:05,867] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:06,180] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.593 seconds
[2022-04-11 18:50:11,632] {scheduler_job.py:153} INFO - Started process (PID=21402) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:11,646] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:11,648] {logging_mixin.py:112} INFO - [2022-04-11 18:50:11,647] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:11,733] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:11,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:11,867] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:11,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:12,089] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.457 seconds
[2022-04-11 18:50:17,588] {scheduler_job.py:153} INFO - Started process (PID=21405) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:17,603] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:17,606] {logging_mixin.py:112} INFO - [2022-04-11 18:50:17,605] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:17,660] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:17,830] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:17,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:17,847] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:18,119] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.531 seconds
[2022-04-11 18:50:23,597] {scheduler_job.py:153} INFO - Started process (PID=21408) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:23,609] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:23,613] {logging_mixin.py:112} INFO - [2022-04-11 18:50:23,612] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:23,695] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:23,830] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:23,833] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:23,846] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:24,055] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.458 seconds
[2022-04-11 18:50:30,025] {scheduler_job.py:153} INFO - Started process (PID=21411) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:30,051] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:30,143] {logging_mixin.py:112} INFO - [2022-04-11 18:50:30,143] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:30,817] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:31,200] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:31,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:31,221] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:32,545] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.520 seconds
[2022-04-11 18:50:36,230] {scheduler_job.py:153} INFO - Started process (PID=21415) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:36,267] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:36,270] {logging_mixin.py:112} INFO - [2022-04-11 18:50:36,269] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:36,357] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:36,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:36,607] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:36,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:36,933] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.703 seconds
[2022-04-11 18:50:42,164] {scheduler_job.py:153} INFO - Started process (PID=21418) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:42,179] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:42,183] {logging_mixin.py:112} INFO - [2022-04-11 18:50:42,182] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:42,234] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:42,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:42,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:42,396] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:42,620] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.456 seconds
[2022-04-11 18:50:48,179] {scheduler_job.py:153} INFO - Started process (PID=21421) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:48,193] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:48,196] {logging_mixin.py:112} INFO - [2022-04-11 18:50:48,195] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:48,247] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:48,434] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:48,441] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:48,458] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:48,715] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.536 seconds
[2022-04-11 18:50:54,213] {scheduler_job.py:153} INFO - Started process (PID=21424) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:54,232] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:50:54,235] {logging_mixin.py:112} INFO - [2022-04-11 18:50:54,234] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:54,399] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:50:54,734] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:54,738] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:50:54,755] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:50:55,097] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.884 seconds
[2022-04-11 18:51:00,179] {scheduler_job.py:153} INFO - Started process (PID=21427) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:00,191] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:00,195] {logging_mixin.py:112} INFO - [2022-04-11 18:51:00,195] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:00,263] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:00,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:00,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:00,474] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:00,728] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.550 seconds
[2022-04-11 18:51:06,777] {scheduler_job.py:153} INFO - Started process (PID=21430) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:06,843] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:06,857] {logging_mixin.py:112} INFO - [2022-04-11 18:51:06,857] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:07,860] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:08,270] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:08,292] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:08,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:10,133] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.356 seconds
[2022-04-11 18:51:17,917] {scheduler_job.py:153} INFO - Started process (PID=21434) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:17,937] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:17,946] {logging_mixin.py:112} INFO - [2022-04-11 18:51:17,946] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:18,313] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:18,667] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:18,699] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:18,741] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:19,023] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.107 seconds
[2022-04-11 18:51:22,314] {scheduler_job.py:153} INFO - Started process (PID=21437) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:22,342] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:22,385] {logging_mixin.py:112} INFO - [2022-04-11 18:51:22,385] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:22,514] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:22,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:22,733] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:22,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:23,236] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.921 seconds
[2022-04-11 18:51:25,597] {scheduler_job.py:153} INFO - Started process (PID=21440) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:25,622] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:25,641] {logging_mixin.py:112} INFO - [2022-04-11 18:51:25,641] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:25,733] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:26,138] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:26,144] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:26,158] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:27,032] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.439 seconds
[2022-04-11 18:51:32,673] {scheduler_job.py:153} INFO - Started process (PID=21443) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:32,691] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:32,694] {logging_mixin.py:112} INFO - [2022-04-11 18:51:32,694] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:32,800] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:32,980] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:32,982] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:32,999] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:33,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.009 seconds
[2022-04-11 18:51:37,591] {scheduler_job.py:153} INFO - Started process (PID=21446) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:37,604] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:37,606] {logging_mixin.py:112} INFO - [2022-04-11 18:51:37,606] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:37,658] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:37,814] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:37,816] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:37,826] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:38,002] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.411 seconds
[2022-04-11 18:51:43,621] {scheduler_job.py:153} INFO - Started process (PID=21449) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:43,627] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:43,629] {logging_mixin.py:112} INFO - [2022-04-11 18:51:43,629] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:43,679] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:43,848] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:43,851] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:43,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:44,051] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.431 seconds
[2022-04-11 18:51:49,675] {scheduler_job.py:153} INFO - Started process (PID=21453) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:49,689] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:49,691] {logging_mixin.py:112} INFO - [2022-04-11 18:51:49,691] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:49,719] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:49,890] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:49,892] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:49,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:50,099] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.424 seconds
[2022-04-11 18:51:55,629] {scheduler_job.py:153} INFO - Started process (PID=21456) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:55,635] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:51:55,637] {logging_mixin.py:112} INFO - [2022-04-11 18:51:55,637] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:55,679] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:51:55,780] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:55,799] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:51:55,822] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:51:55,992] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.363 seconds
[2022-04-11 18:52:01,673] {scheduler_job.py:153} INFO - Started process (PID=21459) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:01,685] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:01,691] {logging_mixin.py:112} INFO - [2022-04-11 18:52:01,690] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:01,743] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:01,956] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:01,958] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:01,967] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:02,187] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.518 seconds
[2022-04-11 18:52:07,646] {scheduler_job.py:153} INFO - Started process (PID=21462) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:07,653] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:07,656] {logging_mixin.py:112} INFO - [2022-04-11 18:52:07,655] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:07,692] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:07,775] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:07,776] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:07,785] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:07,936] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.290 seconds
[2022-04-11 18:52:13,631] {scheduler_job.py:153} INFO - Started process (PID=21465) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:13,639] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:13,641] {logging_mixin.py:112} INFO - [2022-04-11 18:52:13,641] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:13,669] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:13,809] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:13,810] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:13,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:13,962] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.331 seconds
[2022-04-11 18:52:20,082] {scheduler_job.py:153} INFO - Started process (PID=21468) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:20,096] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:20,103] {logging_mixin.py:112} INFO - [2022-04-11 18:52:20,103] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:20,226] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:20,350] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:20,353] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:20,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:20,560] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.478 seconds
[2022-04-11 18:52:25,649] {scheduler_job.py:153} INFO - Started process (PID=21472) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:25,654] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:25,656] {logging_mixin.py:112} INFO - [2022-04-11 18:52:25,655] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:25,701] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:25,792] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:25,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:25,801] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:25,932] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.283 seconds
[2022-04-11 18:52:31,711] {scheduler_job.py:153} INFO - Started process (PID=21475) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:31,724] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:31,726] {logging_mixin.py:112} INFO - [2022-04-11 18:52:31,726] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:31,778] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:32,159] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:32,167] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:32,195] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:32,542] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.830 seconds
[2022-04-11 18:52:37,717] {scheduler_job.py:153} INFO - Started process (PID=21478) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:37,728] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:37,730] {logging_mixin.py:112} INFO - [2022-04-11 18:52:37,730] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:37,791] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:38,956] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:38,959] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:38,991] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:39,402] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.685 seconds
[2022-04-11 18:52:44,154] {scheduler_job.py:153} INFO - Started process (PID=21481) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:44,170] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:44,172] {logging_mixin.py:112} INFO - [2022-04-11 18:52:44,172] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:44,706] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:45,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:45,115] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:45,131] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:45,489] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.335 seconds
[2022-04-11 18:52:49,730] {scheduler_job.py:153} INFO - Started process (PID=21484) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:49,739] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:49,741] {logging_mixin.py:112} INFO - [2022-04-11 18:52:49,741] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:49,770] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:49,898] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:49,900] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:49,908] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:50,041] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.311 seconds
[2022-04-11 18:52:55,862] {scheduler_job.py:153} INFO - Started process (PID=21488) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:55,876] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:52:55,892] {logging_mixin.py:112} INFO - [2022-04-11 18:52:55,892] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:56,056] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:52:56,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:56,298] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:52:56,339] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:52:56,840] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.979 seconds
[2022-04-11 18:53:01,712] {scheduler_job.py:153} INFO - Started process (PID=21491) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:01,721] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:01,723] {logging_mixin.py:112} INFO - [2022-04-11 18:53:01,723] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:01,761] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:01,928] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:01,930] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:01,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:02,131] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.419 seconds
[2022-04-11 18:53:07,786] {scheduler_job.py:153} INFO - Started process (PID=21494) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:07,794] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:07,798] {logging_mixin.py:112} INFO - [2022-04-11 18:53:07,798] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:07,997] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:08,124] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:08,125] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:08,136] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:08,292] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.505 seconds
[2022-04-11 18:53:14,477] {scheduler_job.py:153} INFO - Started process (PID=21497) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:14,507] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:14,509] {logging_mixin.py:112} INFO - [2022-04-11 18:53:14,509] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:14,584] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:14,876] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:14,902] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:14,934] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:15,155] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.678 seconds
[2022-04-11 18:53:19,919] {scheduler_job.py:153} INFO - Started process (PID=21500) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:19,928] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:19,929] {logging_mixin.py:112} INFO - [2022-04-11 18:53:19,929] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:19,982] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:20,127] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:20,129] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:20,143] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:20,330] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.411 seconds
[2022-04-11 18:53:25,768] {scheduler_job.py:153} INFO - Started process (PID=21503) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:25,782] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:25,784] {logging_mixin.py:112} INFO - [2022-04-11 18:53:25,784] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:25,848] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:26,015] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:26,017] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:26,031] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:26,263] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.495 seconds
[2022-04-11 18:53:31,818] {scheduler_job.py:153} INFO - Started process (PID=21507) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:31,831] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:31,833] {logging_mixin.py:112} INFO - [2022-04-11 18:53:31,832] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:31,911] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:32,049] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:32,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:32,066] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:32,248] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.431 seconds
[2022-04-11 18:53:37,801] {scheduler_job.py:153} INFO - Started process (PID=21510) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:37,811] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:37,812] {logging_mixin.py:112} INFO - [2022-04-11 18:53:37,812] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:37,868] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:38,028] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:38,030] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:38,044] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:38,263] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.463 seconds
[2022-04-11 18:53:43,849] {scheduler_job.py:153} INFO - Started process (PID=21513) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:43,863] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:43,865] {logging_mixin.py:112} INFO - [2022-04-11 18:53:43,865] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:43,932] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:44,109] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:44,112] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:44,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:44,359] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.510 seconds
[2022-04-11 18:53:49,865] {scheduler_job.py:153} INFO - Started process (PID=21516) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:49,898] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:49,901] {logging_mixin.py:112} INFO - [2022-04-11 18:53:49,901] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:50,117] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:50,380] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:50,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:50,402] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:50,795] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.930 seconds
[2022-04-11 18:53:55,873] {scheduler_job.py:153} INFO - Started process (PID=21519) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:55,881] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:53:55,883] {logging_mixin.py:112} INFO - [2022-04-11 18:53:55,883] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:55,948] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:53:56,087] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:56,093] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:53:56,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:53:56,501] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.628 seconds
[2022-04-11 18:54:02,019] {scheduler_job.py:153} INFO - Started process (PID=21522) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:02,040] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:02,055] {logging_mixin.py:112} INFO - [2022-04-11 18:54:02,055] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:02,418] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:03,201] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:03,229] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:03,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:06,279] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.260 seconds
[2022-04-11 18:54:09,596] {scheduler_job.py:153} INFO - Started process (PID=21526) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:09,630] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:09,675] {logging_mixin.py:112} INFO - [2022-04-11 18:54:09,674] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:11,051] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:11,341] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:11,343] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:11,442] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:11,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.086 seconds
[2022-04-11 18:54:14,062] {scheduler_job.py:153} INFO - Started process (PID=21529) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:14,087] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:14,095] {logging_mixin.py:112} INFO - [2022-04-11 18:54:14,094] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:14,247] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:14,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:14,462] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:14,487] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:14,842] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.781 seconds
[2022-04-11 18:54:19,858] {scheduler_job.py:153} INFO - Started process (PID=21532) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:19,871] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:19,874] {logging_mixin.py:112} INFO - [2022-04-11 18:54:19,874] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:19,911] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:20,416] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:20,418] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:20,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:20,594] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.737 seconds
[2022-04-11 18:54:25,928] {scheduler_job.py:153} INFO - Started process (PID=21535) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:25,946] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:25,951] {logging_mixin.py:112} INFO - [2022-04-11 18:54:25,951] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:26,029] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:26,248] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:26,250] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:26,272] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:26,478] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.551 seconds
[2022-04-11 18:54:32,001] {scheduler_job.py:153} INFO - Started process (PID=21538) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:32,016] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:32,047] {logging_mixin.py:112} INFO - [2022-04-11 18:54:32,046] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:32,469] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:32,715] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:32,718] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:32,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:33,031] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.031 seconds
[2022-04-11 18:54:39,124] {scheduler_job.py:153} INFO - Started process (PID=21541) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:39,168] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:39,179] {logging_mixin.py:112} INFO - [2022-04-11 18:54:39,179] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:40,066] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:40,752] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:40,762] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:40,796] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:42,797] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.673 seconds
[2022-04-11 18:54:48,752] {scheduler_job.py:153} INFO - Started process (PID=21545) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:48,772] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:48,788] {logging_mixin.py:112} INFO - [2022-04-11 18:54:48,787] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:49,012] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:49,940] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:49,967] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:50,016] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:51,007] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.255 seconds
[2022-04-11 18:54:55,220] {scheduler_job.py:153} INFO - Started process (PID=21548) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:55,229] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:55,232] {logging_mixin.py:112} INFO - [2022-04-11 18:54:55,231] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:55,299] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:55,457] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:55,459] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:55,479] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:55,695] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.476 seconds
[2022-04-11 18:54:59,222] {scheduler_job.py:153} INFO - Started process (PID=21551) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:59,233] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:54:59,234] {logging_mixin.py:112} INFO - [2022-04-11 18:54:59,234] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:59,309] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:54:59,513] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:59,516] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:54:59,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:54:59,778] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.556 seconds
[2022-04-11 18:55:02,908] {scheduler_job.py:153} INFO - Started process (PID=21554) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:02,916] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:02,918] {logging_mixin.py:112} INFO - [2022-04-11 18:55:02,918] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:02,985] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:03,104] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:03,106] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:03,116] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:03,287] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.379 seconds
[2022-04-11 18:55:08,990] {scheduler_job.py:153} INFO - Started process (PID=21558) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:09,006] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:09,008] {logging_mixin.py:112} INFO - [2022-04-11 18:55:09,008] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:09,091] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:09,311] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:09,314] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:09,331] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:09,510] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.520 seconds
[2022-04-11 18:55:15,050] {scheduler_job.py:153} INFO - Started process (PID=21562) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:15,084] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:15,110] {logging_mixin.py:112} INFO - [2022-04-11 18:55:15,109] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:15,290] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:15,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:15,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:15,626] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:15,929] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.879 seconds
[2022-04-11 18:55:20,928] {scheduler_job.py:153} INFO - Started process (PID=21565) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:20,937] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:20,939] {logging_mixin.py:112} INFO - [2022-04-11 18:55:20,939] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:20,975] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:21,079] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:21,081] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:21,090] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:21,251] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.323 seconds
[2022-04-11 18:55:27,758] {scheduler_job.py:153} INFO - Started process (PID=21569) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:27,796] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:27,912] {logging_mixin.py:112} INFO - [2022-04-11 18:55:27,912] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:28,562] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:28,687] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:28,692] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:28,704] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:28,905] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.147 seconds
[2022-04-11 18:55:33,691] {scheduler_job.py:153} INFO - Started process (PID=21572) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:33,708] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:33,710] {logging_mixin.py:112} INFO - [2022-04-11 18:55:33,709] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:33,779] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:33,951] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:33,959] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:33,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:34,200] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.509 seconds
[2022-04-11 18:55:40,045] {scheduler_job.py:153} INFO - Started process (PID=21575) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:40,056] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:40,059] {logging_mixin.py:112} INFO - [2022-04-11 18:55:40,059] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:40,114] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:40,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:40,266] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:40,284] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:40,515] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.470 seconds
[2022-04-11 18:55:45,711] {scheduler_job.py:153} INFO - Started process (PID=21578) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:45,730] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:45,734] {logging_mixin.py:112} INFO - [2022-04-11 18:55:45,734] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:45,801] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:45,949] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:45,951] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:45,965] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:46,217] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.508 seconds
[2022-04-11 18:55:51,709] {scheduler_job.py:153} INFO - Started process (PID=21581) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:51,727] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:51,729] {logging_mixin.py:112} INFO - [2022-04-11 18:55:51,729] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:51,808] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:52,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:52,037] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:52,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:53,168] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.460 seconds
[2022-04-11 18:55:57,838] {scheduler_job.py:153} INFO - Started process (PID=21585) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:57,870] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:55:57,896] {logging_mixin.py:112} INFO - [2022-04-11 18:55:57,896] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:58,751] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:55:59,339] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:59,344] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:55:59,386] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:55:59,850] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.011 seconds
[2022-04-11 18:56:04,336] {scheduler_job.py:153} INFO - Started process (PID=21588) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:04,342] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:04,344] {logging_mixin.py:112} INFO - [2022-04-11 18:56:04,344] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:04,382] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:04,485] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:04,487] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:04,495] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:04,637] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.301 seconds
[2022-04-11 18:56:10,353] {scheduler_job.py:153} INFO - Started process (PID=21591) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:10,365] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:10,368] {logging_mixin.py:112} INFO - [2022-04-11 18:56:10,367] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:10,431] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:10,607] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:10,609] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:10,616] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:10,788] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.435 seconds
[2022-04-11 18:56:16,507] {scheduler_job.py:153} INFO - Started process (PID=21594) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:16,522] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:16,529] {logging_mixin.py:112} INFO - [2022-04-11 18:56:16,529] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:16,594] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:16,702] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:16,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:16,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:16,952] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.445 seconds
[2022-04-11 18:56:22,597] {scheduler_job.py:153} INFO - Started process (PID=21597) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:22,607] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:22,615] {logging_mixin.py:112} INFO - [2022-04-11 18:56:22,613] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:24,877] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:25,086] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:25,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:25,113] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:25,610] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.013 seconds
[2022-04-11 18:56:28,774] {scheduler_job.py:153} INFO - Started process (PID=21600) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:28,790] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:28,793] {logging_mixin.py:112} INFO - [2022-04-11 18:56:28,792] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:28,969] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:29,216] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:29,245] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:29,263] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:29,598] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.824 seconds
[2022-04-11 18:56:34,922] {scheduler_job.py:153} INFO - Started process (PID=21604) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:34,954] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:34,973] {logging_mixin.py:112} INFO - [2022-04-11 18:56:34,972] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:35,349] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:35,770] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:35,783] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:35,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:36,352] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.430 seconds
[2022-04-11 18:56:40,498] {scheduler_job.py:153} INFO - Started process (PID=21607) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:40,517] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:40,519] {logging_mixin.py:112} INFO - [2022-04-11 18:56:40,519] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:40,740] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:40,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:40,926] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:40,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:41,346] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.858 seconds
[2022-04-11 18:56:46,548] {scheduler_job.py:153} INFO - Started process (PID=21610) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:46,565] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:46,568] {logging_mixin.py:112} INFO - [2022-04-11 18:56:46,567] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:46,642] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:46,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:46,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:46,805] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:46,976] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.429 seconds
[2022-04-11 18:56:52,530] {scheduler_job.py:153} INFO - Started process (PID=21613) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:52,561] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:52,563] {logging_mixin.py:112} INFO - [2022-04-11 18:56:52,563] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:52,646] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:52,896] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:52,910] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:52,980] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:53,577] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.048 seconds
[2022-04-11 18:56:59,297] {scheduler_job.py:153} INFO - Started process (PID=21616) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:59,314] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:56:59,323] {logging_mixin.py:112} INFO - [2022-04-11 18:56:59,323] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:56:59,408] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:56:59,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:59,547] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:56:59,587] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:00,565] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.268 seconds
[2022-04-11 18:57:04,547] {scheduler_job.py:153} INFO - Started process (PID=21619) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:04,555] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:04,566] {logging_mixin.py:112} INFO - [2022-04-11 18:57:04,566] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:04,716] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:05,165] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:05,166] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:05,176] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:05,373] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.826 seconds
[2022-04-11 18:57:10,882] {scheduler_job.py:153} INFO - Started process (PID=21622) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:10,899] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:10,901] {logging_mixin.py:112} INFO - [2022-04-11 18:57:10,901] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:10,995] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:11,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:11,335] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:11,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:12,344] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.462 seconds
[2022-04-11 18:57:16,726] {scheduler_job.py:153} INFO - Started process (PID=21626) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:16,739] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:16,760] {logging_mixin.py:112} INFO - [2022-04-11 18:57:16,760] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:16,900] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:17,125] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:17,132] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:17,151] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:18,394] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.668 seconds
[2022-04-11 18:57:22,549] {scheduler_job.py:153} INFO - Started process (PID=21629) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:22,564] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:22,567] {logging_mixin.py:112} INFO - [2022-04-11 18:57:22,566] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:22,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:22,897] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:22,920] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:22,981] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:23,329] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.780 seconds
[2022-04-11 18:57:28,550] {scheduler_job.py:153} INFO - Started process (PID=21632) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:28,557] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:28,559] {logging_mixin.py:112} INFO - [2022-04-11 18:57:28,559] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:28,597] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:28,762] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:28,764] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:28,791] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:29,075] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.525 seconds
[2022-04-11 18:57:34,555] {scheduler_job.py:153} INFO - Started process (PID=21635) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:34,563] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:34,564] {logging_mixin.py:112} INFO - [2022-04-11 18:57:34,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:34,599] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:34,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:34,714] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:34,729] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:34,906] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.350 seconds
[2022-04-11 18:57:40,594] {scheduler_job.py:153} INFO - Started process (PID=21638) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:40,603] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:40,605] {logging_mixin.py:112} INFO - [2022-04-11 18:57:40,605] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:40,802] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:40,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:40,924] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:40,936] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:41,158] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.564 seconds
[2022-04-11 18:57:46,605] {scheduler_job.py:153} INFO - Started process (PID=21641) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:46,613] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:46,614] {logging_mixin.py:112} INFO - [2022-04-11 18:57:46,614] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:46,714] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:46,909] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:46,911] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:46,926] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:47,217] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.612 seconds
[2022-04-11 18:57:52,989] {scheduler_job.py:153} INFO - Started process (PID=21645) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:53,006] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:53,008] {logging_mixin.py:112} INFO - [2022-04-11 18:57:53,008] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:53,064] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:53,209] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:53,211] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:53,220] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:53,395] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.406 seconds
[2022-04-11 18:57:58,688] {scheduler_job.py:153} INFO - Started process (PID=21648) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:58,757] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:57:58,770] {logging_mixin.py:112} INFO - [2022-04-11 18:57:58,769] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:58,834] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:57:58,979] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:58,981] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:57:59,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:57:59,228] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.541 seconds
[2022-04-11 18:58:04,815] {scheduler_job.py:153} INFO - Started process (PID=21651) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:04,867] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:04,877] {logging_mixin.py:112} INFO - [2022-04-11 18:58:04,877] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:05,163] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:05,655] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:05,660] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:05,676] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:05,952] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.137 seconds
[2022-04-11 18:58:10,750] {scheduler_job.py:153} INFO - Started process (PID=21654) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:10,768] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:10,778] {logging_mixin.py:112} INFO - [2022-04-11 18:58:10,777] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:10,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:11,034] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:11,041] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:11,061] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:11,269] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.519 seconds
[2022-04-11 18:58:17,012] {scheduler_job.py:153} INFO - Started process (PID=21657) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:17,123] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:17,181] {logging_mixin.py:112} INFO - [2022-04-11 18:58:17,181] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:17,507] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:18,218] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:18,226] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:18,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:22,095] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 5.084 seconds
[2022-04-11 18:58:25,500] {scheduler_job.py:153} INFO - Started process (PID=21661) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:25,516] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:25,521] {logging_mixin.py:112} INFO - [2022-04-11 18:58:25,521] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:25,593] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:26,336] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:26,353] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:26,426] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:27,030] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.530 seconds
[2022-04-11 18:58:29,221] {scheduler_job.py:153} INFO - Started process (PID=21664) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:29,229] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:29,231] {logging_mixin.py:112} INFO - [2022-04-11 18:58:29,231] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:29,272] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:29,414] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:29,415] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:29,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:29,600] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.377 seconds
[2022-04-11 18:58:35,317] {scheduler_job.py:153} INFO - Started process (PID=21667) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:35,327] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:35,331] {logging_mixin.py:112} INFO - [2022-04-11 18:58:35,331] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:35,401] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:35,600] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:35,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:35,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:35,805] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.488 seconds
[2022-04-11 18:58:41,262] {scheduler_job.py:153} INFO - Started process (PID=21670) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:41,274] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:41,276] {logging_mixin.py:112} INFO - [2022-04-11 18:58:41,276] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:41,335] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:41,424] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:41,425] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:41,433] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:41,592] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.330 seconds
[2022-04-11 18:58:47,278] {scheduler_job.py:153} INFO - Started process (PID=21673) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:47,283] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:47,285] {logging_mixin.py:112} INFO - [2022-04-11 18:58:47,285] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:47,317] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:47,420] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:47,422] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:47,431] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:47,577] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.299 seconds
[2022-04-11 18:58:53,281] {scheduler_job.py:153} INFO - Started process (PID=21676) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:53,292] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:58:53,296] {logging_mixin.py:112} INFO - [2022-04-11 18:58:53,295] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:53,400] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:58:53,567] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:53,569] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:58:53,581] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:58:53,784] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.508 seconds
[2022-04-11 18:59:01,971] {scheduler_job.py:153} INFO - Started process (PID=21680) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:01,979] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:01,980] {logging_mixin.py:112} INFO - [2022-04-11 18:59:01,980] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:02,069] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:02,379] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:02,391] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:02,415] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:02,938] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.967 seconds
[2022-04-11 18:59:06,604] {scheduler_job.py:153} INFO - Started process (PID=21683) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:06,635] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:06,649] {logging_mixin.py:112} INFO - [2022-04-11 18:59:06,649] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:06,838] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:07,176] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:07,178] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:07,200] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:07,518] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.914 seconds
[2022-04-11 18:59:12,599] {scheduler_job.py:153} INFO - Started process (PID=21686) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:12,608] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:12,616] {logging_mixin.py:112} INFO - [2022-04-11 18:59:12,616] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:12,732] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:12,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:12,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:12,895] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:13,142] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.544 seconds
[2022-04-11 18:59:18,651] {scheduler_job.py:153} INFO - Started process (PID=21689) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:18,668] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:18,679] {logging_mixin.py:112} INFO - [2022-04-11 18:59:18,678] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:18,768] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:18,952] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:18,962] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:18,975] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:19,269] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.619 seconds
[2022-04-11 18:59:24,632] {scheduler_job.py:153} INFO - Started process (PID=21692) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:24,643] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:24,645] {logging_mixin.py:112} INFO - [2022-04-11 18:59:24,645] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:24,714] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:24,851] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:24,853] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:24,866] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:25,066] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-04-11 18:59:30,609] {scheduler_job.py:153} INFO - Started process (PID=21695) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:30,618] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:30,624] {logging_mixin.py:112} INFO - [2022-04-11 18:59:30,624] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:30,677] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:30,814] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:30,817] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:30,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:31,012] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.403 seconds
[2022-04-11 18:59:36,631] {scheduler_job.py:153} INFO - Started process (PID=21698) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:36,640] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:36,641] {logging_mixin.py:112} INFO - [2022-04-11 18:59:36,641] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:36,683] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:36,788] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:36,790] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:36,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:36,945] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-04-11 18:59:42,607] {scheduler_job.py:153} INFO - Started process (PID=21702) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:42,616] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:42,618] {logging_mixin.py:112} INFO - [2022-04-11 18:59:42,618] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:42,655] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:42,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:42,769] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:42,778] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:42,935] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.328 seconds
[2022-04-11 18:59:48,634] {scheduler_job.py:153} INFO - Started process (PID=21705) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:48,641] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:48,643] {logging_mixin.py:112} INFO - [2022-04-11 18:59:48,642] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:48,671] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:48,752] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:48,754] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:48,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:48,928] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.294 seconds
[2022-04-11 18:59:54,615] {scheduler_job.py:153} INFO - Started process (PID=21708) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:54,624] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 18:59:54,626] {logging_mixin.py:112} INFO - [2022-04-11 18:59:54,626] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:54,662] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 18:59:54,816] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:54,818] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 18:59:54,828] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 18:59:54,969] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.355 seconds
[2022-04-11 19:00:00,662] {scheduler_job.py:153} INFO - Started process (PID=21711) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:00,667] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:00,669] {logging_mixin.py:112} INFO - [2022-04-11 19:00:00,668] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:00,744] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:00,836] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:00,839] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:00,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:00,991] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.329 seconds
[2022-04-11 19:00:06,624] {scheduler_job.py:153} INFO - Started process (PID=21714) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:06,631] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:06,632] {logging_mixin.py:112} INFO - [2022-04-11 19:00:06,632] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:06,663] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:06,748] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:06,749] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:06,757] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:06,897] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.273 seconds
[2022-04-11 19:00:12,694] {scheduler_job.py:153} INFO - Started process (PID=21718) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:12,702] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:12,704] {logging_mixin.py:112} INFO - [2022-04-11 19:00:12,703] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:12,787] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:12,906] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:12,908] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:12,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:13,127] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-04-11 19:00:18,650] {scheduler_job.py:153} INFO - Started process (PID=21721) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:18,657] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:18,659] {logging_mixin.py:112} INFO - [2022-04-11 19:00:18,659] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:18,689] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:18,797] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:18,798] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:18,806] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:18,937] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.288 seconds
[2022-04-11 19:00:24,687] {scheduler_job.py:153} INFO - Started process (PID=21724) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:24,693] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:24,694] {logging_mixin.py:112} INFO - [2022-04-11 19:00:24,694] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:24,733] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:24,809] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:24,811] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:24,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:24,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.292 seconds
[2022-04-11 19:00:30,661] {scheduler_job.py:153} INFO - Started process (PID=21727) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:30,668] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:30,670] {logging_mixin.py:112} INFO - [2022-04-11 19:00:30,669] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:30,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:30,811] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:30,813] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:30,821] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:30,967] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.306 seconds
[2022-04-11 19:00:36,725] {scheduler_job.py:153} INFO - Started process (PID=21730) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:36,730] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:36,732] {logging_mixin.py:112} INFO - [2022-04-11 19:00:36,732] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:36,770] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:36,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:36,866] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:36,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:37,034] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.309 seconds
[2022-04-11 19:00:42,672] {scheduler_job.py:153} INFO - Started process (PID=21733) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:42,681] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:42,683] {logging_mixin.py:112} INFO - [2022-04-11 19:00:42,683] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:42,719] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:42,841] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:42,843] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:42,849] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:42,989] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.318 seconds
[2022-04-11 19:00:48,733] {scheduler_job.py:153} INFO - Started process (PID=21737) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:48,740] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:48,741] {logging_mixin.py:112} INFO - [2022-04-11 19:00:48,741] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:48,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:48,870] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:48,872] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:48,880] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:49,025] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.292 seconds
[2022-04-11 19:00:54,693] {scheduler_job.py:153} INFO - Started process (PID=21740) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:54,698] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:00:54,700] {logging_mixin.py:112} INFO - [2022-04-11 19:00:54,700] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:54,739] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:00:54,830] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:54,832] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:00:54,841] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:00:54,974] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-04-11 19:01:00,723] {scheduler_job.py:153} INFO - Started process (PID=21743) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:00,728] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:00,729] {logging_mixin.py:112} INFO - [2022-04-11 19:01:00,729] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:00,759] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:00,837] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:00,839] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:00,846] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:00,994] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.271 seconds
[2022-04-11 19:01:06,697] {scheduler_job.py:153} INFO - Started process (PID=21746) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:06,704] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:06,705] {logging_mixin.py:112} INFO - [2022-04-11 19:01:06,705] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:06,739] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:08,182] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:08,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:08,203] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:08,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.031 seconds
[2022-04-11 19:01:13,127] {scheduler_job.py:153} INFO - Started process (PID=21749) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:13,132] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:13,133] {logging_mixin.py:112} INFO - [2022-04-11 19:01:13,133] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:13,178] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:13,275] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:13,276] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:13,284] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:13,418] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.291 seconds
[2022-04-11 19:01:19,131] {scheduler_job.py:153} INFO - Started process (PID=21753) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:19,138] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:19,140] {logging_mixin.py:112} INFO - [2022-04-11 19:01:19,139] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:19,173] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:19,329] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:19,331] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:19,339] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:19,488] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.357 seconds
[2022-04-11 19:01:25,143] {scheduler_job.py:153} INFO - Started process (PID=21756) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:25,149] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:25,150] {logging_mixin.py:112} INFO - [2022-04-11 19:01:25,150] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:25,188] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:25,287] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:25,289] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:25,296] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:25,448] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-04-11 19:01:31,133] {scheduler_job.py:153} INFO - Started process (PID=21759) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:31,142] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:31,143] {logging_mixin.py:112} INFO - [2022-04-11 19:01:31,143] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:31,173] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:31,280] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:31,281] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:31,291] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:31,423] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.291 seconds
[2022-04-11 19:01:37,156] {scheduler_job.py:153} INFO - Started process (PID=21762) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:37,167] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:37,169] {logging_mixin.py:112} INFO - [2022-04-11 19:01:37,169] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:37,227] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:37,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:37,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:37,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:37,598] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.442 seconds
[2022-04-11 19:01:43,146] {scheduler_job.py:153} INFO - Started process (PID=21765) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:43,155] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:43,156] {logging_mixin.py:112} INFO - [2022-04-11 19:01:43,156] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:43,185] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:43,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:43,460] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:43,471] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:43,688] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.542 seconds
[2022-04-11 19:01:49,183] {scheduler_job.py:153} INFO - Started process (PID=21769) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:49,196] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:49,198] {logging_mixin.py:112} INFO - [2022-04-11 19:01:49,197] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:49,249] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:49,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:49,503] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:49,517] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:49,875] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.692 seconds
[2022-04-11 19:01:55,180] {scheduler_job.py:153} INFO - Started process (PID=21772) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:55,189] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:01:55,191] {logging_mixin.py:112} INFO - [2022-04-11 19:01:55,190] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:55,222] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:01:55,393] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:55,395] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:01:55,404] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:01:55,607] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.427 seconds
[2022-04-11 19:02:01,166] {scheduler_job.py:153} INFO - Started process (PID=21775) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:01,177] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:01,179] {logging_mixin.py:112} INFO - [2022-04-11 19:02:01,179] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:01,214] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:01,441] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:01,443] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:01,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:01,619] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-04-11 19:02:07,187] {scheduler_job.py:153} INFO - Started process (PID=21778) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:07,196] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:07,197] {logging_mixin.py:112} INFO - [2022-04-11 19:02:07,197] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:07,229] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:07,350] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:07,376] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:07,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:07,591] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.404 seconds
[2022-04-11 19:02:13,200] {scheduler_job.py:153} INFO - Started process (PID=21781) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:13,208] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:13,210] {logging_mixin.py:112} INFO - [2022-04-11 19:02:13,210] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:13,259] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:13,359] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:13,361] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:13,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:13,531] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.331 seconds
[2022-04-11 19:02:19,201] {scheduler_job.py:153} INFO - Started process (PID=21784) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:19,208] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:19,209] {logging_mixin.py:112} INFO - [2022-04-11 19:02:19,209] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:19,249] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:19,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:19,347] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:19,356] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:19,497] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.296 seconds
[2022-04-11 19:02:25,205] {scheduler_job.py:153} INFO - Started process (PID=21788) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:25,211] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:25,213] {logging_mixin.py:112} INFO - [2022-04-11 19:02:25,212] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:25,261] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:25,369] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:25,371] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:25,379] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:25,542] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.338 seconds
[2022-04-11 19:02:31,221] {scheduler_job.py:153} INFO - Started process (PID=21791) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:31,227] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:31,229] {logging_mixin.py:112} INFO - [2022-04-11 19:02:31,229] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:31,311] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:31,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:31,405] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:31,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:31,652] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.431 seconds
[2022-04-11 19:02:37,221] {scheduler_job.py:153} INFO - Started process (PID=21794) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:37,226] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:37,228] {logging_mixin.py:112} INFO - [2022-04-11 19:02:37,227] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:37,264] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:37,361] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:37,363] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:37,371] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:37,527] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.307 seconds
[2022-04-11 19:02:43,217] {scheduler_job.py:153} INFO - Started process (PID=21797) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:43,223] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:43,224] {logging_mixin.py:112} INFO - [2022-04-11 19:02:43,224] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:43,255] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:43,350] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:43,352] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:43,359] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:43,514] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.297 seconds
[2022-04-11 19:02:49,231] {scheduler_job.py:153} INFO - Started process (PID=21800) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:49,242] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:49,243] {logging_mixin.py:112} INFO - [2022-04-11 19:02:49,243] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:49,280] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:49,377] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:49,378] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:49,387] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:49,536] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-04-11 19:02:55,235] {scheduler_job.py:153} INFO - Started process (PID=21804) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:55,243] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:02:55,252] {logging_mixin.py:112} INFO - [2022-04-11 19:02:55,252] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:55,327] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:02:55,520] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:55,523] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:02:55,533] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:02:55,743] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.509 seconds
[2022-04-11 19:03:01,254] {scheduler_job.py:153} INFO - Started process (PID=21807) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:01,270] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:01,273] {logging_mixin.py:112} INFO - [2022-04-11 19:03:01,272] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:01,307] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:01,420] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:01,422] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:01,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:01,596] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.343 seconds
[2022-04-11 19:03:07,258] {scheduler_job.py:153} INFO - Started process (PID=21810) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:07,265] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:07,267] {logging_mixin.py:112} INFO - [2022-04-11 19:03:07,266] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:07,305] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:07,437] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:07,438] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:07,445] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:07,572] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 19:03:13,289] {scheduler_job.py:153} INFO - Started process (PID=21813) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:13,295] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:13,296] {logging_mixin.py:112} INFO - [2022-04-11 19:03:13,296] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:13,326] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:13,421] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:13,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:13,430] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:13,564] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.276 seconds
[2022-04-11 19:03:19,288] {scheduler_job.py:153} INFO - Started process (PID=21816) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:19,296] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:19,297] {logging_mixin.py:112} INFO - [2022-04-11 19:03:19,297] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:19,330] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:19,417] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:19,419] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:19,427] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:19,573] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.285 seconds
[2022-04-11 19:03:25,300] {scheduler_job.py:153} INFO - Started process (PID=21819) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:25,306] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:25,308] {logging_mixin.py:112} INFO - [2022-04-11 19:03:25,308] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:25,336] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:25,429] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:25,431] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:25,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:25,588] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.288 seconds
[2022-04-11 19:03:31,304] {scheduler_job.py:153} INFO - Started process (PID=21823) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:31,312] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:31,313] {logging_mixin.py:112} INFO - [2022-04-11 19:03:31,313] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:31,344] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:31,440] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:31,442] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:31,450] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:31,629] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.325 seconds
[2022-04-11 19:03:37,302] {scheduler_job.py:153} INFO - Started process (PID=21826) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:37,315] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:37,317] {logging_mixin.py:112} INFO - [2022-04-11 19:03:37,317] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:37,360] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:37,677] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:37,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:37,686] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:38,042] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.740 seconds
[2022-04-11 19:03:43,322] {scheduler_job.py:153} INFO - Started process (PID=21829) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:43,329] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:43,331] {logging_mixin.py:112} INFO - [2022-04-11 19:03:43,330] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:43,361] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:43,490] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:43,491] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:43,498] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:43,654] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.332 seconds
[2022-04-11 19:03:49,333] {scheduler_job.py:153} INFO - Started process (PID=21832) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:49,343] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:49,345] {logging_mixin.py:112} INFO - [2022-04-11 19:03:49,345] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:49,392] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:49,496] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:49,498] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:49,505] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:49,648] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-04-11 19:03:55,342] {scheduler_job.py:153} INFO - Started process (PID=21835) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:55,348] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:03:55,350] {logging_mixin.py:112} INFO - [2022-04-11 19:03:55,350] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:55,395] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:03:55,510] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:55,512] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:03:55,522] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:03:55,663] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.322 seconds
[2022-04-11 19:04:01,435] {scheduler_job.py:153} INFO - Started process (PID=21839) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:01,465] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:01,467] {logging_mixin.py:112} INFO - [2022-04-11 19:04:01,467] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:01,604] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:01,870] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:01,878] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:01,898] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:02,165] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.730 seconds
[2022-04-11 19:04:07,403] {scheduler_job.py:153} INFO - Started process (PID=21842) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:07,422] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:07,424] {logging_mixin.py:112} INFO - [2022-04-11 19:04:07,424] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:07,467] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:07,596] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:07,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:07,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:07,819] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.418 seconds
[2022-04-11 19:04:13,366] {scheduler_job.py:153} INFO - Started process (PID=21845) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:13,373] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:13,374] {logging_mixin.py:112} INFO - [2022-04-11 19:04:13,374] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:13,410] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:13,511] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:13,513] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:13,521] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:13,677] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.311 seconds
[2022-04-11 19:04:19,371] {scheduler_job.py:153} INFO - Started process (PID=21848) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:19,376] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:19,377] {logging_mixin.py:112} INFO - [2022-04-11 19:04:19,377] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:19,411] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:19,521] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:19,523] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:19,531] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:19,660] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.290 seconds
[2022-04-11 19:04:25,372] {scheduler_job.py:153} INFO - Started process (PID=21851) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:25,383] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:25,385] {logging_mixin.py:112} INFO - [2022-04-11 19:04:25,385] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:25,421] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:25,522] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:25,523] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:25,531] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:25,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.310 seconds
[2022-04-11 19:04:31,387] {scheduler_job.py:153} INFO - Started process (PID=21854) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:31,398] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:31,400] {logging_mixin.py:112} INFO - [2022-04-11 19:04:31,399] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:31,450] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:31,552] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:31,554] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:31,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:31,706] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-04-11 19:04:37,430] {scheduler_job.py:153} INFO - Started process (PID=21858) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:37,451] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:37,453] {logging_mixin.py:112} INFO - [2022-04-11 19:04:37,452] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:37,510] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:37,981] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:37,984] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:37,994] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:39,709] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.287 seconds
[2022-04-11 19:04:43,385] {scheduler_job.py:153} INFO - Started process (PID=21861) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:43,394] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:43,396] {logging_mixin.py:112} INFO - [2022-04-11 19:04:43,396] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:43,429] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:43,859] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:43,860] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:43,868] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:44,075] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.691 seconds
[2022-04-11 19:04:49,421] {scheduler_job.py:153} INFO - Started process (PID=21864) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:49,435] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:49,437] {logging_mixin.py:112} INFO - [2022-04-11 19:04:49,437] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:49,503] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:49,746] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:49,748] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:49,757] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:49,991] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.571 seconds
[2022-04-11 19:04:55,400] {scheduler_job.py:153} INFO - Started process (PID=21867) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:55,409] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:04:55,411] {logging_mixin.py:112} INFO - [2022-04-11 19:04:55,411] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:55,442] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:04:55,669] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:55,671] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:04:55,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:04:55,959] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.560 seconds
[2022-04-11 19:05:01,417] {scheduler_job.py:153} INFO - Started process (PID=21870) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:01,426] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:01,427] {logging_mixin.py:112} INFO - [2022-04-11 19:05:01,427] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:01,455] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:01,578] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:01,580] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:01,589] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:01,764] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.347 seconds
[2022-04-11 19:05:07,424] {scheduler_job.py:153} INFO - Started process (PID=21873) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:07,436] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:07,440] {logging_mixin.py:112} INFO - [2022-04-11 19:05:07,440] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:07,477] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:07,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:07,600] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:07,608] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:07,760] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.337 seconds
[2022-04-11 19:05:13,430] {scheduler_job.py:153} INFO - Started process (PID=21877) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:13,437] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:13,438] {logging_mixin.py:112} INFO - [2022-04-11 19:05:13,438] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:13,468] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:13,563] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:13,565] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:13,576] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:13,743] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-04-11 19:05:19,458] {scheduler_job.py:153} INFO - Started process (PID=21880) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:19,473] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:19,475] {logging_mixin.py:112} INFO - [2022-04-11 19:05:19,475] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:19,508] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:19,618] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:19,621] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:19,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:19,785] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.327 seconds
[2022-04-11 19:05:25,449] {scheduler_job.py:153} INFO - Started process (PID=21883) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:25,457] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:25,458] {logging_mixin.py:112} INFO - [2022-04-11 19:05:25,458] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:25,500] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:25,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:25,601] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:25,608] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:25,765] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-04-11 19:05:31,473] {scheduler_job.py:153} INFO - Started process (PID=21886) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:31,479] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:31,481] {logging_mixin.py:112} INFO - [2022-04-11 19:05:31,480] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:31,527] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:31,623] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:31,625] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:31,632] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:31,789] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-04-11 19:05:37,456] {scheduler_job.py:153} INFO - Started process (PID=21889) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:37,464] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:37,465] {logging_mixin.py:112} INFO - [2022-04-11 19:05:37,465] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:37,493] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:37,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:37,632] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:37,641] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:37,776] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-04-11 19:05:43,722] {scheduler_job.py:153} INFO - Started process (PID=21893) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:43,730] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:43,737] {logging_mixin.py:112} INFO - [2022-04-11 19:05:43,736] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:43,986] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:44,328] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:44,331] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:44,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:44,554] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.833 seconds
[2022-04-11 19:05:49,478] {scheduler_job.py:153} INFO - Started process (PID=21896) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:49,484] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:49,485] {logging_mixin.py:112} INFO - [2022-04-11 19:05:49,485] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:49,522] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:49,617] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:49,619] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:49,629] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:49,792] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 19:05:55,481] {scheduler_job.py:153} INFO - Started process (PID=21899) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:55,489] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:05:55,490] {logging_mixin.py:112} INFO - [2022-04-11 19:05:55,490] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:55,519] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:05:55,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:55,631] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:05:55,639] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:05:55,799] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.318 seconds
[2022-04-11 19:06:01,495] {scheduler_job.py:153} INFO - Started process (PID=21902) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:01,502] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:01,504] {logging_mixin.py:112} INFO - [2022-04-11 19:06:01,504] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:01,536] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:01,623] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:01,625] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:01,632] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:01,809] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 19:06:07,497] {scheduler_job.py:153} INFO - Started process (PID=21905) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:07,507] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:07,508] {logging_mixin.py:112} INFO - [2022-04-11 19:06:07,508] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:07,537] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:07,645] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:07,646] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:07,655] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:07,788] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.291 seconds
[2022-04-11 19:06:13,511] {scheduler_job.py:153} INFO - Started process (PID=21908) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:13,516] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:13,518] {logging_mixin.py:112} INFO - [2022-04-11 19:06:13,517] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:13,546] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:13,658] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:13,660] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:13,667] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:13,815] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-04-11 19:06:19,513] {scheduler_job.py:153} INFO - Started process (PID=21912) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:19,520] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:19,521] {logging_mixin.py:112} INFO - [2022-04-11 19:06:19,521] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:19,556] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:19,706] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:19,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:19,716] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:19,888] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.376 seconds
[2022-04-11 19:06:25,520] {scheduler_job.py:153} INFO - Started process (PID=21915) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:25,528] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:25,529] {logging_mixin.py:112} INFO - [2022-04-11 19:06:25,529] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:25,559] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:25,667] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:25,668] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:25,676] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:25,834] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 19:06:31,527] {scheduler_job.py:153} INFO - Started process (PID=21918) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:31,534] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:31,536] {logging_mixin.py:112} INFO - [2022-04-11 19:06:31,536] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:31,572] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:31,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:31,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:31,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:31,890] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.363 seconds
[2022-04-11 19:06:37,537] {scheduler_job.py:153} INFO - Started process (PID=21921) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:37,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:37,550] {logging_mixin.py:112} INFO - [2022-04-11 19:06:37,549] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:37,585] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:37,690] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:37,691] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:37,699] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:37,875] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.338 seconds
[2022-04-11 19:06:43,541] {scheduler_job.py:153} INFO - Started process (PID=21924) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:43,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:43,550] {logging_mixin.py:112} INFO - [2022-04-11 19:06:43,549] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:43,584] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:43,692] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:43,694] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:43,701] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:43,863] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.323 seconds
[2022-04-11 19:06:49,577] {scheduler_job.py:153} INFO - Started process (PID=21928) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:49,589] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:49,591] {logging_mixin.py:112} INFO - [2022-04-11 19:06:49,591] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:49,649] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:49,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:49,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:49,806] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:50,037] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.460 seconds
[2022-04-11 19:06:55,551] {scheduler_job.py:153} INFO - Started process (PID=21931) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:55,563] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:06:55,564] {logging_mixin.py:112} INFO - [2022-04-11 19:06:55,564] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:55,595] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:06:55,724] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:55,725] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:06:55,732] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:06:55,871] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.320 seconds
[2022-04-11 19:07:01,571] {scheduler_job.py:153} INFO - Started process (PID=21934) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:01,576] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:01,578] {logging_mixin.py:112} INFO - [2022-04-11 19:07:01,578] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:01,618] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:01,716] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:01,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:01,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:01,867] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.296 seconds
[2022-04-11 19:07:07,575] {scheduler_job.py:153} INFO - Started process (PID=21937) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:07,583] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:07,585] {logging_mixin.py:112} INFO - [2022-04-11 19:07:07,585] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:07,613] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:07,747] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:07,749] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:07,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:07,912] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.338 seconds
[2022-04-11 19:07:13,588] {scheduler_job.py:153} INFO - Started process (PID=21940) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:13,594] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:13,596] {logging_mixin.py:112} INFO - [2022-04-11 19:07:13,595] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:13,639] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:13,741] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:13,743] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:13,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:13,896] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.309 seconds
[2022-04-11 19:07:19,592] {scheduler_job.py:153} INFO - Started process (PID=21943) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:19,598] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:19,600] {logging_mixin.py:112} INFO - [2022-04-11 19:07:19,599] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:19,632] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:19,747] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:19,749] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:19,758] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:19,914] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.322 seconds
[2022-04-11 19:07:25,590] {scheduler_job.py:153} INFO - Started process (PID=21947) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:25,598] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:25,600] {logging_mixin.py:112} INFO - [2022-04-11 19:07:25,600] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:25,631] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:25,738] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:25,739] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:25,747] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:25,901] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.311 seconds
[2022-04-11 19:07:31,609] {scheduler_job.py:153} INFO - Started process (PID=21950) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:31,614] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:31,615] {logging_mixin.py:112} INFO - [2022-04-11 19:07:31,615] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:31,658] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:31,755] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:31,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:31,765] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:31,917] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.308 seconds
[2022-04-11 19:07:37,614] {scheduler_job.py:153} INFO - Started process (PID=21953) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:37,623] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:37,624] {logging_mixin.py:112} INFO - [2022-04-11 19:07:37,624] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:37,654] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:37,747] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:37,749] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:37,760] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:37,913] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.300 seconds
[2022-04-11 19:07:43,617] {scheduler_job.py:153} INFO - Started process (PID=21956) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:43,624] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:43,625] {logging_mixin.py:112} INFO - [2022-04-11 19:07:43,625] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:43,655] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:43,771] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:43,773] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:43,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:43,945] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.328 seconds
[2022-04-11 19:07:49,617] {scheduler_job.py:153} INFO - Started process (PID=21959) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:49,624] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:49,625] {logging_mixin.py:112} INFO - [2022-04-11 19:07:49,625] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:49,656] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:49,783] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:49,785] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:49,795] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:49,957] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.340 seconds
[2022-04-11 19:07:55,646] {scheduler_job.py:153} INFO - Started process (PID=21963) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:55,658] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:07:55,660] {logging_mixin.py:112} INFO - [2022-04-11 19:07:55,659] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:55,707] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:07:55,870] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:55,873] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:07:55,885] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:07:56,115] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.469 seconds
[2022-04-11 19:08:01,640] {scheduler_job.py:153} INFO - Started process (PID=21966) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:01,646] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:01,648] {logging_mixin.py:112} INFO - [2022-04-11 19:08:01,647] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:01,683] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:01,807] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:01,809] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:01,818] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:01,964] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-04-11 19:08:07,643] {scheduler_job.py:153} INFO - Started process (PID=21969) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:07,650] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:07,651] {logging_mixin.py:112} INFO - [2022-04-11 19:08:07,651] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:07,693] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:07,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:07,776] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:07,784] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:07,928] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.285 seconds
[2022-04-11 19:08:13,654] {scheduler_job.py:153} INFO - Started process (PID=21972) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:13,663] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:13,665] {logging_mixin.py:112} INFO - [2022-04-11 19:08:13,664] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:13,702] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:13,791] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:13,793] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:13,801] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:13,944] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.291 seconds
[2022-04-11 19:08:19,675] {scheduler_job.py:153} INFO - Started process (PID=21975) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:19,682] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:19,683] {logging_mixin.py:112} INFO - [2022-04-11 19:08:19,683] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:19,732] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:19,859] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:19,861] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:19,868] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:20,018] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.343 seconds
[2022-04-11 19:08:25,676] {scheduler_job.py:153} INFO - Started process (PID=21978) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:25,682] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:25,684] {logging_mixin.py:112} INFO - [2022-04-11 19:08:25,684] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:25,727] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:25,826] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:25,827] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:25,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:25,976] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.300 seconds
[2022-04-11 19:08:31,669] {scheduler_job.py:153} INFO - Started process (PID=21982) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:31,683] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:31,684] {logging_mixin.py:112} INFO - [2022-04-11 19:08:31,684] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:31,725] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:31,847] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:31,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:31,857] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:32,013] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.344 seconds
[2022-04-11 19:08:37,686] {scheduler_job.py:153} INFO - Started process (PID=21985) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:37,694] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:37,696] {logging_mixin.py:112} INFO - [2022-04-11 19:08:37,696] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:37,731] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:37,840] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:37,841] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:37,848] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:37,997] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-04-11 19:08:43,693] {scheduler_job.py:153} INFO - Started process (PID=21988) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:43,697] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:43,699] {logging_mixin.py:112} INFO - [2022-04-11 19:08:43,699] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:43,727] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:43,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:43,865] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:43,874] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:44,017] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.325 seconds
[2022-04-11 19:08:49,718] {scheduler_job.py:153} INFO - Started process (PID=21991) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:49,725] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:49,727] {logging_mixin.py:112} INFO - [2022-04-11 19:08:49,726] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:49,765] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:49,875] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:49,877] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:49,888] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:50,050] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.332 seconds
[2022-04-11 19:08:55,704] {scheduler_job.py:153} INFO - Started process (PID=21994) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:55,709] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:08:55,711] {logging_mixin.py:112} INFO - [2022-04-11 19:08:55,710] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:55,744] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:08:55,852] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:55,854] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:08:55,862] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:08:56,005] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.301 seconds
[2022-04-11 19:09:01,747] {scheduler_job.py:153} INFO - Started process (PID=21998) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:01,755] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:01,757] {logging_mixin.py:112} INFO - [2022-04-11 19:09:01,756] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:02,272] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:02,420] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:02,423] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:02,441] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:02,680] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.940 seconds
[2022-04-11 19:09:07,730] {scheduler_job.py:153} INFO - Started process (PID=22001) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:07,739] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:07,740] {logging_mixin.py:112} INFO - [2022-04-11 19:09:07,740] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:07,768] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:07,877] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:07,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:07,889] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:08,042] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.313 seconds
[2022-04-11 19:09:13,740] {scheduler_job.py:153} INFO - Started process (PID=22004) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:13,748] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:13,750] {logging_mixin.py:112} INFO - [2022-04-11 19:09:13,750] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:13,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:13,903] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:13,905] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:13,912] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:14,070] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.330 seconds
[2022-04-11 19:09:19,735] {scheduler_job.py:153} INFO - Started process (PID=22007) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:19,749] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:19,751] {logging_mixin.py:112} INFO - [2022-04-11 19:09:19,750] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:19,784] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:19,909] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:19,911] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:19,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:20,058] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.323 seconds
[2022-04-11 19:09:25,742] {scheduler_job.py:153} INFO - Started process (PID=22010) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:25,752] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:25,754] {logging_mixin.py:112} INFO - [2022-04-11 19:09:25,754] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:25,785] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:25,893] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:25,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:25,903] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:26,054] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-04-11 19:09:31,745] {scheduler_job.py:153} INFO - Started process (PID=22013) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:31,753] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:31,755] {logging_mixin.py:112} INFO - [2022-04-11 19:09:31,754] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:31,788] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:31,893] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:31,894] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:31,902] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:32,070] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-04-11 19:09:37,761] {scheduler_job.py:153} INFO - Started process (PID=22017) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:37,767] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:37,768] {logging_mixin.py:112} INFO - [2022-04-11 19:09:37,768] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:37,803] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:37,905] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:37,906] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:37,913] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:38,064] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-04-11 19:09:43,760] {scheduler_job.py:153} INFO - Started process (PID=22020) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:43,767] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:43,769] {logging_mixin.py:112} INFO - [2022-04-11 19:09:43,769] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:43,799] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:43,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:43,887] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:43,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:44,036] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.275 seconds
[2022-04-11 19:09:49,766] {scheduler_job.py:153} INFO - Started process (PID=22023) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:49,772] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:49,773] {logging_mixin.py:112} INFO - [2022-04-11 19:09:49,773] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:49,802] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:49,925] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:49,927] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:49,934] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:50,098] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.332 seconds
[2022-04-11 19:09:55,764] {scheduler_job.py:153} INFO - Started process (PID=22026) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:55,776] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:09:55,778] {logging_mixin.py:112} INFO - [2022-04-11 19:09:55,778] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:55,810] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:09:55,899] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:55,900] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:09:55,907] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:09:56,068] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-04-11 19:10:01,784] {scheduler_job.py:153} INFO - Started process (PID=22029) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:01,792] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:01,793] {logging_mixin.py:112} INFO - [2022-04-11 19:10:01,793] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:01,823] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:01,902] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:01,904] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:01,911] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:02,098] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.314 seconds
[2022-04-11 19:10:07,821] {scheduler_job.py:153} INFO - Started process (PID=22033) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:07,830] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:07,833] {logging_mixin.py:112} INFO - [2022-04-11 19:10:07,832] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:07,887] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:08,025] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:08,027] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:08,040] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:08,234] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.413 seconds
[2022-04-11 19:10:13,802] {scheduler_job.py:153} INFO - Started process (PID=22036) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:13,807] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:13,809] {logging_mixin.py:112} INFO - [2022-04-11 19:10:13,808] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:13,837] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:13,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:13,966] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:13,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:14,118] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.317 seconds
[2022-04-11 19:10:19,807] {scheduler_job.py:153} INFO - Started process (PID=22039) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:19,813] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:19,815] {logging_mixin.py:112} INFO - [2022-04-11 19:10:19,814] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:19,845] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:19,971] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:19,973] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:19,980] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:20,158] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.351 seconds
[2022-04-11 19:10:25,816] {scheduler_job.py:153} INFO - Started process (PID=22042) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:25,826] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:25,828] {logging_mixin.py:112} INFO - [2022-04-11 19:10:25,828] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:25,857] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:25,962] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:25,963] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:25,970] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:26,117] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.301 seconds
[2022-04-11 19:10:31,823] {scheduler_job.py:153} INFO - Started process (PID=22045) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:31,829] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:31,833] {logging_mixin.py:112} INFO - [2022-04-11 19:10:31,830] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:31,865] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:31,967] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:31,968] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:31,976] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:32,124] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.301 seconds
[2022-04-11 19:10:37,825] {scheduler_job.py:153} INFO - Started process (PID=22048) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:37,831] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:37,833] {logging_mixin.py:112} INFO - [2022-04-11 19:10:37,833] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:37,864] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:37,959] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:37,961] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:37,968] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:38,128] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.303 seconds
[2022-04-11 19:10:43,843] {scheduler_job.py:153} INFO - Started process (PID=22052) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:43,848] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:43,850] {logging_mixin.py:112} INFO - [2022-04-11 19:10:43,850] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:43,886] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:43,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:43,967] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:43,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:44,135] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.292 seconds
[2022-04-11 19:10:49,849] {scheduler_job.py:153} INFO - Started process (PID=22055) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:49,854] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:49,855] {logging_mixin.py:112} INFO - [2022-04-11 19:10:49,855] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:49,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:50,007] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:50,009] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:50,017] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:50,172] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.323 seconds
[2022-04-11 19:10:55,861] {scheduler_job.py:153} INFO - Started process (PID=22058) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:55,867] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:10:55,868] {logging_mixin.py:112} INFO - [2022-04-11 19:10:55,868] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:55,898] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:10:56,025] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:56,027] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:10:56,034] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:10:56,197] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-04-11 19:11:01,864] {scheduler_job.py:153} INFO - Started process (PID=22061) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:01,870] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:01,871] {logging_mixin.py:112} INFO - [2022-04-11 19:11:01,871] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:01,898] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:02,014] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:02,016] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:02,023] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:02,322] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.459 seconds
[2022-04-11 19:11:07,917] {scheduler_job.py:153} INFO - Started process (PID=22064) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:07,922] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:07,923] {logging_mixin.py:112} INFO - [2022-04-11 19:11:07,923] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:07,955] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:08,033] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:08,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:08,042] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:08,183] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.266 seconds
[2022-04-11 19:11:13,900] {scheduler_job.py:153} INFO - Started process (PID=22068) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:13,907] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:13,909] {logging_mixin.py:112} INFO - [2022-04-11 19:11:13,909] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:13,944] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:14,023] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:14,025] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:14,032] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:14,215] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-04-11 19:11:19,927] {scheduler_job.py:153} INFO - Started process (PID=22071) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:19,933] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:19,934] {logging_mixin.py:112} INFO - [2022-04-11 19:11:19,934] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:19,979] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:20,063] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:20,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:20,072] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:20,236] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.308 seconds
[2022-04-11 19:11:25,915] {scheduler_job.py:153} INFO - Started process (PID=22074) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:25,922] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:25,924] {logging_mixin.py:112} INFO - [2022-04-11 19:11:25,924] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:25,951] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:26,081] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:26,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:26,090] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:26,231] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.316 seconds
[2022-04-11 19:11:31,943] {scheduler_job.py:153} INFO - Started process (PID=22077) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:31,948] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:31,949] {logging_mixin.py:112} INFO - [2022-04-11 19:11:31,949] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:31,979] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:32,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:32,053] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:32,060] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:32,193] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.250 seconds
[2022-04-11 19:11:37,933] {scheduler_job.py:153} INFO - Started process (PID=22080) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:37,939] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:37,940] {logging_mixin.py:112} INFO - [2022-04-11 19:11:37,940] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:37,980] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:38,062] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:38,063] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:38,071] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:38,213] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.280 seconds
[2022-04-11 19:11:43,971] {scheduler_job.py:153} INFO - Started process (PID=22084) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:43,978] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:43,979] {logging_mixin.py:112} INFO - [2022-04-11 19:11:43,979] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:44,037] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:44,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:44,133] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:44,147] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:44,325] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.354 seconds
[2022-04-11 19:11:49,951] {scheduler_job.py:153} INFO - Started process (PID=22087) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:49,960] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:49,962] {logging_mixin.py:112} INFO - [2022-04-11 19:11:49,962] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:49,991] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:50,091] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:50,093] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:50,099] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:50,239] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.288 seconds
[2022-04-11 19:11:55,975] {scheduler_job.py:153} INFO - Started process (PID=22090) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:55,980] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:11:55,981] {logging_mixin.py:112} INFO - [2022-04-11 19:11:55,981] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:56,017] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:11:56,116] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:56,118] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:11:56,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:11:56,279] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-04-11 19:12:01,974] {scheduler_job.py:153} INFO - Started process (PID=22093) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:01,980] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:01,981] {logging_mixin.py:112} INFO - [2022-04-11 19:12:01,981] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:02,010] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:02,119] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:02,121] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:02,127] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:02,271] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.297 seconds
[2022-04-11 19:12:08,019] {scheduler_job.py:153} INFO - Started process (PID=22096) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:08,026] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:08,028] {logging_mixin.py:112} INFO - [2022-04-11 19:12:08,028] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:08,069] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:08,148] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:08,149] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:08,158] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:08,328] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.309 seconds
[2022-04-11 19:12:13,994] {scheduler_job.py:153} INFO - Started process (PID=22099) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:14,001] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:14,002] {logging_mixin.py:112} INFO - [2022-04-11 19:12:14,002] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:14,034] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:14,129] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:14,131] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:14,139] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:14,318] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-04-11 19:12:20,035] {scheduler_job.py:153} INFO - Started process (PID=22103) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:20,040] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:20,041] {logging_mixin.py:112} INFO - [2022-04-11 19:12:20,041] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:20,078] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:20,159] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:20,161] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:20,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:20,314] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.279 seconds
[2022-04-11 19:12:26,023] {scheduler_job.py:153} INFO - Started process (PID=22106) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:26,038] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:26,039] {logging_mixin.py:112} INFO - [2022-04-11 19:12:26,039] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:26,074] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:26,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:26,204] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:26,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:26,373] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.350 seconds
[2022-04-11 19:12:32,025] {scheduler_job.py:153} INFO - Started process (PID=22109) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:32,033] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:32,034] {logging_mixin.py:112} INFO - [2022-04-11 19:12:32,034] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:32,062] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:32,186] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:32,188] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:32,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:32,523] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.498 seconds
[2022-04-11 19:12:38,024] {scheduler_job.py:153} INFO - Started process (PID=22112) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:38,030] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:38,031] {logging_mixin.py:112} INFO - [2022-04-11 19:12:38,031] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:38,061] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:38,161] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:38,163] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:38,172] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:38,324] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.300 seconds
[2022-04-11 19:12:44,050] {scheduler_job.py:153} INFO - Started process (PID=22115) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:44,057] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:44,058] {logging_mixin.py:112} INFO - [2022-04-11 19:12:44,058] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:44,086] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:44,161] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:44,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:44,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:44,314] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.264 seconds
[2022-04-11 19:12:50,043] {scheduler_job.py:153} INFO - Started process (PID=22119) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:50,051] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:50,053] {logging_mixin.py:112} INFO - [2022-04-11 19:12:50,052] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:50,091] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:50,233] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:50,235] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:50,244] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:50,411] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.368 seconds
[2022-04-11 19:12:56,079] {scheduler_job.py:153} INFO - Started process (PID=22122) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:56,083] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:12:56,084] {logging_mixin.py:112} INFO - [2022-04-11 19:12:56,084] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:56,115] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:12:56,247] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:56,252] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:12:56,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:12:56,402] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-04-11 19:13:02,061] {scheduler_job.py:153} INFO - Started process (PID=22125) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:02,065] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:02,067] {logging_mixin.py:112} INFO - [2022-04-11 19:13:02,067] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:02,109] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:02,215] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:02,216] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:02,226] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:02,367] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.306 seconds
[2022-04-11 19:13:08,088] {scheduler_job.py:153} INFO - Started process (PID=22128) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:08,094] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:08,095] {logging_mixin.py:112} INFO - [2022-04-11 19:13:08,095] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:08,126] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:08,205] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:08,207] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:08,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:08,336] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.248 seconds
[2022-04-11 19:13:14,058] {scheduler_job.py:153} INFO - Started process (PID=22131) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:14,065] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:14,067] {logging_mixin.py:112} INFO - [2022-04-11 19:13:14,067] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:14,115] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:14,335] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:14,337] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:14,351] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:14,659] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.601 seconds
[2022-04-11 19:13:20,087] {scheduler_job.py:153} INFO - Started process (PID=22134) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:20,094] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:20,096] {logging_mixin.py:112} INFO - [2022-04-11 19:13:20,096] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:20,133] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:20,227] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:20,228] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:20,238] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:20,445] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.358 seconds
[2022-04-11 19:13:26,083] {scheduler_job.py:153} INFO - Started process (PID=22138) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:26,093] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:26,094] {logging_mixin.py:112} INFO - [2022-04-11 19:13:26,094] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:26,121] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:26,240] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:26,242] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:26,249] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:26,385] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.302 seconds
[2022-04-11 19:13:32,160] {scheduler_job.py:153} INFO - Started process (PID=22141) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:32,172] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:32,174] {logging_mixin.py:112} INFO - [2022-04-11 19:13:32,174] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:32,240] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:32,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:32,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:32,460] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:32,746] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.586 seconds
[2022-04-11 19:13:38,119] {scheduler_job.py:153} INFO - Started process (PID=22144) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:38,134] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:38,136] {logging_mixin.py:112} INFO - [2022-04-11 19:13:38,136] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:38,226] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:38,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:38,452] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:38,475] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:38,761] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.642 seconds
[2022-04-11 19:13:45,494] {scheduler_job.py:153} INFO - Started process (PID=22147) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:45,520] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:45,527] {logging_mixin.py:112} INFO - [2022-04-11 19:13:45,527] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:45,753] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:46,659] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:46,690] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:46,718] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:48,203] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.709 seconds
[2022-04-11 19:13:51,189] {scheduler_job.py:153} INFO - Started process (PID=22150) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:51,249] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:13:51,269] {logging_mixin.py:112} INFO - [2022-04-11 19:13:51,269] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:51,593] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:13:52,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:52,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:13:52,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:13:53,032] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.842 seconds
[2022-04-11 19:14:01,130] {scheduler_job.py:153} INFO - Started process (PID=22154) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:01,152] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:01,159] {logging_mixin.py:112} INFO - [2022-04-11 19:14:01,159] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:01,218] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:01,389] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:01,396] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:01,425] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:03,526] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.396 seconds
[2022-04-11 19:14:12,478] {scheduler_job.py:153} INFO - Started process (PID=22157) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:12,497] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:12,508] {logging_mixin.py:112} INFO - [2022-04-11 19:14:12,508] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:12,632] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:12,914] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:12,917] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:12,948] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:13,483] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.005 seconds
[2022-04-11 19:14:15,146] {scheduler_job.py:153} INFO - Started process (PID=22160) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:15,175] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:15,183] {logging_mixin.py:112} INFO - [2022-04-11 19:14:15,183] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:15,409] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:15,545] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:15,547] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:15,561] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:15,967] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.821 seconds
[2022-04-11 19:14:17,340] {scheduler_job.py:153} INFO - Started process (PID=22163) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:17,358] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:17,360] {logging_mixin.py:112} INFO - [2022-04-11 19:14:17,359] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:17,418] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:17,719] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:17,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:17,743] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:18,034] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.694 seconds
[2022-04-11 19:14:23,452] {scheduler_job.py:153} INFO - Started process (PID=22166) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:23,474] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:23,477] {logging_mixin.py:112} INFO - [2022-04-11 19:14:23,477] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:23,637] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:24,318] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:24,326] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:24,389] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:25,232] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.781 seconds
[2022-04-11 19:14:29,443] {scheduler_job.py:153} INFO - Started process (PID=22169) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:29,455] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:29,466] {logging_mixin.py:112} INFO - [2022-04-11 19:14:29,465] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:29,763] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:30,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:30,500] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:30,538] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:31,417] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.974 seconds
[2022-04-11 19:14:35,642] {scheduler_job.py:153} INFO - Started process (PID=22172) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:35,668] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:35,682] {logging_mixin.py:112} INFO - [2022-04-11 19:14:35,682] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:35,809] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:36,082] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:36,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:36,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:36,500] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.865 seconds
[2022-04-11 19:14:41,698] {scheduler_job.py:153} INFO - Started process (PID=22176) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:41,730] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:41,762] {logging_mixin.py:112} INFO - [2022-04-11 19:14:41,762] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:41,835] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:42,666] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:42,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:42,751] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:43,317] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.629 seconds
[2022-04-11 19:14:47,469] {scheduler_job.py:153} INFO - Started process (PID=22179) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:47,484] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:47,486] {logging_mixin.py:112} INFO - [2022-04-11 19:14:47,485] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:47,543] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:47,718] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:47,723] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:47,733] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:47,983] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.514 seconds
[2022-04-11 19:14:53,479] {scheduler_job.py:153} INFO - Started process (PID=22182) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:53,493] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:53,496] {logging_mixin.py:112} INFO - [2022-04-11 19:14:53,495] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:53,549] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:53,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:53,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:53,745] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:53,985] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.507 seconds
[2022-04-11 19:14:59,553] {scheduler_job.py:153} INFO - Started process (PID=22185) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:59,567] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:14:59,575] {logging_mixin.py:112} INFO - [2022-04-11 19:14:59,569] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:14:59,678] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:14:59,896] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:59,899] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:14:59,927] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:00,263] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.711 seconds
[2022-04-11 19:15:05,732] {scheduler_job.py:153} INFO - Started process (PID=22188) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:05,741] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:05,745] {logging_mixin.py:112} INFO - [2022-04-11 19:15:05,745] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:05,812] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:05,987] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:05,990] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:06,012] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:06,228] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.496 seconds
[2022-04-11 19:15:11,494] {scheduler_job.py:153} INFO - Started process (PID=22191) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:11,524] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:11,627] {logging_mixin.py:112} INFO - [2022-04-11 19:15:11,627] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:11,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:12,204] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:12,213] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:12,234] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:12,534] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.040 seconds
[2022-04-11 19:15:17,641] {scheduler_job.py:153} INFO - Started process (PID=22195) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:17,686] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:17,715] {logging_mixin.py:112} INFO - [2022-04-11 19:15:17,714] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:17,869] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:18,329] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:18,331] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:18,360] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:18,632] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.992 seconds
[2022-04-11 19:15:23,503] {scheduler_job.py:153} INFO - Started process (PID=22198) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:23,523] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:23,528] {logging_mixin.py:112} INFO - [2022-04-11 19:15:23,528] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:23,583] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:23,723] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:23,726] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:23,735] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:23,963] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.461 seconds
[2022-04-11 19:15:29,520] {scheduler_job.py:153} INFO - Started process (PID=22201) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:29,530] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:29,532] {logging_mixin.py:112} INFO - [2022-04-11 19:15:29,532] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:29,597] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:29,752] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:29,755] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:29,768] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:29,966] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.446 seconds
[2022-04-11 19:15:35,574] {scheduler_job.py:153} INFO - Started process (PID=22204) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:35,589] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:35,593] {logging_mixin.py:112} INFO - [2022-04-11 19:15:35,593] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:35,647] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:35,882] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:35,884] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:35,897] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:36,158] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.584 seconds
[2022-04-11 19:15:41,592] {scheduler_job.py:153} INFO - Started process (PID=22207) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:41,601] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:41,602] {logging_mixin.py:112} INFO - [2022-04-11 19:15:41,602] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:41,698] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:41,823] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:41,829] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:41,842] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:42,068] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.476 seconds
[2022-04-11 19:15:47,578] {scheduler_job.py:153} INFO - Started process (PID=22210) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:47,585] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:47,587] {logging_mixin.py:112} INFO - [2022-04-11 19:15:47,586] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:47,636] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:47,778] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:47,781] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:47,798] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:48,029] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.452 seconds
[2022-04-11 19:15:54,098] {scheduler_job.py:153} INFO - Started process (PID=22214) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:54,131] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:15:54,135] {logging_mixin.py:112} INFO - [2022-04-11 19:15:54,134] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:54,341] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:15:54,788] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:54,798] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:15:54,831] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:15:55,708] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.610 seconds
[2022-04-11 19:16:00,685] {scheduler_job.py:153} INFO - Started process (PID=22217) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:00,692] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:00,694] {logging_mixin.py:112} INFO - [2022-04-11 19:16:00,693] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:00,798] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:00,942] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:00,944] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:00,957] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:01,163] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.478 seconds
[2022-04-11 19:16:05,919] {scheduler_job.py:153} INFO - Started process (PID=22220) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:05,962] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:05,978] {logging_mixin.py:112} INFO - [2022-04-11 19:16:05,978] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:06,258] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:06,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:06,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:06,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:06,649] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.731 seconds
[2022-04-11 19:16:11,735] {scheduler_job.py:153} INFO - Started process (PID=22223) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:11,742] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:11,743] {logging_mixin.py:112} INFO - [2022-04-11 19:16:11,743] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:11,782] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:11,877] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:11,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:11,888] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:12,054] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.319 seconds
[2022-04-11 19:16:17,777] {scheduler_job.py:153} INFO - Started process (PID=22226) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:17,783] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:17,785] {logging_mixin.py:112} INFO - [2022-04-11 19:16:17,785] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:17,825] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:17,919] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:17,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:17,929] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:18,077] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.300 seconds
[2022-04-11 19:16:23,806] {scheduler_job.py:153} INFO - Started process (PID=22229) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:23,818] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:23,823] {logging_mixin.py:112} INFO - [2022-04-11 19:16:23,822] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:23,901] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:24,143] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:24,145] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:24,154] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:24,430] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.624 seconds
[2022-04-11 19:16:29,793] {scheduler_job.py:153} INFO - Started process (PID=22232) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:29,798] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:29,800] {logging_mixin.py:112} INFO - [2022-04-11 19:16:29,800] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:29,837] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:29,920] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:29,923] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:29,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:30,097] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-04-11 19:16:35,898] {scheduler_job.py:153} INFO - Started process (PID=22236) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:35,917] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:35,921] {logging_mixin.py:112} INFO - [2022-04-11 19:16:35,921] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:36,003] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:36,272] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:36,274] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:36,283] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:36,445] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.547 seconds
[2022-04-11 19:16:41,982] {scheduler_job.py:153} INFO - Started process (PID=22239) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:41,989] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:41,991] {logging_mixin.py:112} INFO - [2022-04-11 19:16:41,990] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:42,055] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:42,177] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:42,179] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:42,190] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:42,491] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.509 seconds
[2022-04-11 19:16:47,865] {scheduler_job.py:153} INFO - Started process (PID=22242) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:47,884] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:47,886] {logging_mixin.py:112} INFO - [2022-04-11 19:16:47,886] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:48,005] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:48,206] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:48,213] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:48,232] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:48,684] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.827 seconds
[2022-04-11 19:16:53,860] {scheduler_job.py:153} INFO - Started process (PID=22245) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:53,867] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:53,870] {logging_mixin.py:112} INFO - [2022-04-11 19:16:53,869] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:53,984] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:16:54,122] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:54,126] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:16:54,139] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:54,346] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.486 seconds
[2022-04-11 19:16:59,833] {scheduler_job.py:153} INFO - Started process (PID=22248) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:59,857] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:16:59,860] {logging_mixin.py:112} INFO - [2022-04-11 19:16:59,860] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:16:59,911] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:00,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:00,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:00,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:00,408] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.575 seconds
[2022-04-11 19:17:05,927] {scheduler_job.py:153} INFO - Started process (PID=22252) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:05,939] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:05,943] {logging_mixin.py:112} INFO - [2022-04-11 19:17:05,943] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:06,043] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:06,231] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:06,237] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:06,260] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:06,498] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.572 seconds
[2022-04-11 19:17:11,853] {scheduler_job.py:153} INFO - Started process (PID=22255) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:11,864] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:11,865] {logging_mixin.py:112} INFO - [2022-04-11 19:17:11,865] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:11,933] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:12,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:12,088] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:12,101] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:12,334] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.481 seconds
[2022-04-11 19:17:17,912] {scheduler_job.py:153} INFO - Started process (PID=22258) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:17,942] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:17,947] {logging_mixin.py:112} INFO - [2022-04-11 19:17:17,947] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:18,059] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:18,175] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:18,177] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:18,186] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:18,414] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.502 seconds
[2022-04-11 19:17:25,773] {scheduler_job.py:153} INFO - Started process (PID=22261) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:25,785] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:25,791] {logging_mixin.py:112} INFO - [2022-04-11 19:17:25,790] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:25,864] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:25,970] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:25,973] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:25,988] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:26,380] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.606 seconds
[2022-04-11 19:17:30,824] {scheduler_job.py:153} INFO - Started process (PID=22264) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:30,841] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:30,855] {logging_mixin.py:112} INFO - [2022-04-11 19:17:30,855] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:30,908] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:31,081] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:31,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:31,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:31,264] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.440 seconds
[2022-04-11 19:17:36,801] {scheduler_job.py:153} INFO - Started process (PID=22267) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:36,810] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:36,812] {logging_mixin.py:112} INFO - [2022-04-11 19:17:36,811] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:36,896] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:37,186] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:37,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:37,223] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:37,500] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.699 seconds
[2022-04-11 19:17:42,797] {scheduler_job.py:153} INFO - Started process (PID=22271) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:42,810] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:42,812] {logging_mixin.py:112} INFO - [2022-04-11 19:17:42,811] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:42,846] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:42,962] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:42,964] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:42,973] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:43,116] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.319 seconds
[2022-04-11 19:17:48,894] {scheduler_job.py:153} INFO - Started process (PID=22274) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:48,914] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:48,918] {logging_mixin.py:112} INFO - [2022-04-11 19:17:48,918] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:49,031] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:49,246] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:49,249] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:49,278] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:49,568] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.674 seconds
[2022-04-11 19:17:54,841] {scheduler_job.py:153} INFO - Started process (PID=22277) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:54,861] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:17:54,873] {logging_mixin.py:112} INFO - [2022-04-11 19:17:54,868] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:54,926] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:17:55,075] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:55,077] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:17:55,092] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:17:55,299] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.459 seconds
[2022-04-11 19:18:00,835] {scheduler_job.py:153} INFO - Started process (PID=22280) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:00,847] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:00,850] {logging_mixin.py:112} INFO - [2022-04-11 19:18:00,850] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:00,920] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:01,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:01,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:01,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:01,283] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.448 seconds
[2022-04-11 19:18:06,854] {scheduler_job.py:153} INFO - Started process (PID=22283) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:06,863] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:06,866] {logging_mixin.py:112} INFO - [2022-04-11 19:18:06,865] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:06,961] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:07,112] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:07,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:07,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:07,434] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.580 seconds
[2022-04-11 19:18:12,942] {scheduler_job.py:153} INFO - Started process (PID=22287) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:12,964] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:12,966] {logging_mixin.py:112} INFO - [2022-04-11 19:18:12,966] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:13,051] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:13,288] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:13,295] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:13,308] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:13,595] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.653 seconds
[2022-04-11 19:18:18,864] {scheduler_job.py:153} INFO - Started process (PID=22290) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:18,877] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:18,879] {logging_mixin.py:112} INFO - [2022-04-11 19:18:18,878] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:18,933] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:19,081] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:19,084] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:19,097] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:19,313] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.450 seconds
[2022-04-11 19:18:24,931] {scheduler_job.py:153} INFO - Started process (PID=22293) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:24,946] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:24,948] {logging_mixin.py:112} INFO - [2022-04-11 19:18:24,948] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:25,014] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:25,152] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:25,155] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:25,165] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:25,372] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.441 seconds
[2022-04-11 19:18:30,952] {scheduler_job.py:153} INFO - Started process (PID=22296) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:30,969] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:30,983] {logging_mixin.py:112} INFO - [2022-04-11 19:18:30,976] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:31,221] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:31,468] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:31,476] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:31,501] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:33,096] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.151 seconds
[2022-04-11 19:18:42,751] {scheduler_job.py:153} INFO - Started process (PID=22299) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:42,770] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:42,778] {logging_mixin.py:112} INFO - [2022-04-11 19:18:42,778] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:42,845] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:43,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:43,047] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:43,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:43,326] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.575 seconds
[2022-04-11 19:18:47,343] {scheduler_job.py:153} INFO - Started process (PID=22303) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:47,356] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:47,371] {logging_mixin.py:112} INFO - [2022-04-11 19:18:47,370] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:47,578] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:47,869] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:47,880] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:47,904] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:48,244] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.901 seconds
[2022-04-11 19:18:53,301] {scheduler_job.py:153} INFO - Started process (PID=22306) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:53,312] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:53,314] {logging_mixin.py:112} INFO - [2022-04-11 19:18:53,313] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:53,401] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:53,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:53,541] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:53,552] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:53,763] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.462 seconds
[2022-04-11 19:18:59,276] {scheduler_job.py:153} INFO - Started process (PID=22309) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:59,284] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:18:59,286] {logging_mixin.py:112} INFO - [2022-04-11 19:18:59,285] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:59,347] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:18:59,524] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:59,526] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:18:59,542] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:18:59,746] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.470 seconds
[2022-04-11 19:19:05,332] {scheduler_job.py:153} INFO - Started process (PID=22312) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:05,344] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:05,346] {logging_mixin.py:112} INFO - [2022-04-11 19:19:05,345] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:05,413] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:05,567] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:05,569] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:05,593] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:05,806] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.474 seconds
[2022-04-11 19:19:11,314] {scheduler_job.py:153} INFO - Started process (PID=22315) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:11,331] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:11,333] {logging_mixin.py:112} INFO - [2022-04-11 19:19:11,333] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:11,481] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:11,634] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:11,636] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:11,654] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:12,134] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.821 seconds
[2022-04-11 19:19:17,550] {scheduler_job.py:153} INFO - Started process (PID=22318) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:17,597] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:17,604] {logging_mixin.py:112} INFO - [2022-04-11 19:19:17,604] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:17,866] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:18,560] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:18,563] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:18,595] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:19,247] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.698 seconds
[2022-04-11 19:19:24,475] {scheduler_job.py:153} INFO - Started process (PID=22322) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:24,499] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:24,511] {logging_mixin.py:112} INFO - [2022-04-11 19:19:24,511] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:24,635] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:24,946] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:24,968] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:24,989] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:25,998] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.523 seconds
[2022-04-11 19:19:29,362] {scheduler_job.py:153} INFO - Started process (PID=22325) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:29,372] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:29,375] {logging_mixin.py:112} INFO - [2022-04-11 19:19:29,374] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:29,445] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:29,584] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:29,586] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:29,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:29,812] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.452 seconds
[2022-04-11 19:19:35,427] {scheduler_job.py:153} INFO - Started process (PID=22328) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:35,444] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:35,456] {logging_mixin.py:112} INFO - [2022-04-11 19:19:35,456] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:35,543] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:35,647] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:35,649] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:35,663] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:35,877] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.450 seconds
[2022-04-11 19:19:41,348] {scheduler_job.py:153} INFO - Started process (PID=22331) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:41,355] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:41,357] {logging_mixin.py:112} INFO - [2022-04-11 19:19:41,357] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:41,423] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:41,511] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:41,513] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:41,523] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:42,046] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.699 seconds
[2022-04-11 19:19:47,343] {scheduler_job.py:153} INFO - Started process (PID=22334) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:47,355] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:47,358] {logging_mixin.py:112} INFO - [2022-04-11 19:19:47,358] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:47,398] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:47,530] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:47,532] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:47,544] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:47,706] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.363 seconds
[2022-04-11 19:19:53,556] {scheduler_job.py:153} INFO - Started process (PID=22337) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:53,563] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:53,565] {logging_mixin.py:112} INFO - [2022-04-11 19:19:53,565] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:53,662] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:54,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:54,061] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:54,080] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:54,340] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.784 seconds
[2022-04-11 19:19:59,585] {scheduler_job.py:153} INFO - Started process (PID=22345) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:59,620] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:19:59,623] {logging_mixin.py:112} INFO - [2022-04-11 19:19:59,622] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:19:59,680] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:19:59,849] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:59,851] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:19:59,869] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:00,114] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.530 seconds
[2022-04-11 19:20:05,410] {scheduler_job.py:153} INFO - Started process (PID=22348) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:05,419] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:05,422] {logging_mixin.py:112} INFO - [2022-04-11 19:20:05,422] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:05,465] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:05,634] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:05,636] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:05,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:05,834] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.424 seconds
[2022-04-11 19:20:11,369] {scheduler_job.py:153} INFO - Started process (PID=22351) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:11,382] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:11,383] {logging_mixin.py:112} INFO - [2022-04-11 19:20:11,383] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:11,443] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:11,598] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:11,600] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:11,614] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:11,824] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.456 seconds
[2022-04-11 19:20:17,567] {scheduler_job.py:153} INFO - Started process (PID=22354) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:17,593] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:17,596] {logging_mixin.py:112} INFO - [2022-04-11 19:20:17,595] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:17,648] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:17,819] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:17,825] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:17,839] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:18,220] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.654 seconds
[2022-04-11 19:20:23,361] {scheduler_job.py:153} INFO - Started process (PID=22357) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:23,381] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:23,390] {logging_mixin.py:112} INFO - [2022-04-11 19:20:23,390] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:23,472] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:23,657] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:23,660] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:23,682] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:23,941] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.580 seconds
[2022-04-11 19:20:29,466] {scheduler_job.py:153} INFO - Started process (PID=22360) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:29,475] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:29,477] {logging_mixin.py:112} INFO - [2022-04-11 19:20:29,477] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:29,530] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:29,695] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:29,698] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:29,749] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:29,959] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.493 seconds
[2022-04-11 19:20:35,387] {scheduler_job.py:153} INFO - Started process (PID=22364) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:35,396] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:35,398] {logging_mixin.py:112} INFO - [2022-04-11 19:20:35,397] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:35,497] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:35,648] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:35,651] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:35,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:35,922] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.535 seconds
[2022-04-11 19:20:41,418] {scheduler_job.py:153} INFO - Started process (PID=22367) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:41,435] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:41,439] {logging_mixin.py:112} INFO - [2022-04-11 19:20:41,438] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:41,541] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:41,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:41,631] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:41,646] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:41,850] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.433 seconds
[2022-04-11 19:20:47,383] {scheduler_job.py:153} INFO - Started process (PID=22370) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:47,391] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:47,392] {logging_mixin.py:112} INFO - [2022-04-11 19:20:47,392] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:47,428] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:47,516] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:47,518] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:47,526] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:47,664] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-04-11 19:20:53,434] {scheduler_job.py:153} INFO - Started process (PID=22373) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:53,441] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:53,443] {logging_mixin.py:112} INFO - [2022-04-11 19:20:53,442] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:53,480] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:53,574] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:53,576] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:53,585] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:53,787] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.353 seconds
[2022-04-11 19:20:59,437] {scheduler_job.py:153} INFO - Started process (PID=22376) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:59,469] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:20:59,473] {logging_mixin.py:112} INFO - [2022-04-11 19:20:59,473] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:59,529] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:20:59,635] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:59,638] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:20:59,647] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:20:59,804] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.367 seconds
[2022-04-11 19:21:07,044] {scheduler_job.py:153} INFO - Started process (PID=22380) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:07,053] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:07,056] {logging_mixin.py:112} INFO - [2022-04-11 19:21:07,055] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:07,261] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:07,685] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:07,688] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:07,725] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:08,628] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.584 seconds
[2022-04-11 19:21:12,751] {scheduler_job.py:153} INFO - Started process (PID=22383) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:12,818] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:12,837] {logging_mixin.py:112} INFO - [2022-04-11 19:21:12,836] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:13,199] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:13,417] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:13,419] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:13,435] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:13,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.930 seconds
[2022-04-11 19:21:18,499] {scheduler_job.py:153} INFO - Started process (PID=22386) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:18,514] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:18,516] {logging_mixin.py:112} INFO - [2022-04-11 19:21:18,516] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:18,627] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:19,337] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:19,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:19,361] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:19,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.230 seconds
[2022-04-11 19:21:24,522] {scheduler_job.py:153} INFO - Started process (PID=22389) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:24,543] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:24,561] {logging_mixin.py:112} INFO - [2022-04-11 19:21:24,561] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:24,794] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:25,054] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:25,061] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:25,081] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:25,354] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.831 seconds
[2022-04-11 19:21:30,617] {scheduler_job.py:153} INFO - Started process (PID=22392) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:30,633] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:30,644] {logging_mixin.py:112} INFO - [2022-04-11 19:21:30,644] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:30,867] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:31,028] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:31,031] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:31,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:31,298] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.682 seconds
[2022-04-11 19:21:36,497] {scheduler_job.py:153} INFO - Started process (PID=22395) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:36,509] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:36,514] {logging_mixin.py:112} INFO - [2022-04-11 19:21:36,513] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:36,599] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:36,802] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:36,808] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:36,819] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:37,026] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.529 seconds
[2022-04-11 19:21:42,512] {scheduler_job.py:153} INFO - Started process (PID=22398) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:42,519] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:42,526] {logging_mixin.py:112} INFO - [2022-04-11 19:21:42,526] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:42,581] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:42,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:42,761] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:42,775] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:42,993] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.481 seconds
[2022-04-11 19:21:49,405] {scheduler_job.py:153} INFO - Started process (PID=22402) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:49,447] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:49,459] {logging_mixin.py:112} INFO - [2022-04-11 19:21:49,453] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:49,708] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:49,954] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:49,958] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:49,974] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:50,243] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.839 seconds
[2022-04-11 19:21:54,815] {scheduler_job.py:153} INFO - Started process (PID=22405) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:54,832] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:21:54,846] {logging_mixin.py:112} INFO - [2022-04-11 19:21:54,846] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:54,947] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:21:55,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:55,102] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:21:55,116] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:21:55,463] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.648 seconds
[2022-04-11 19:22:00,842] {scheduler_job.py:153} INFO - Started process (PID=22408) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:00,877] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:00,894] {logging_mixin.py:112} INFO - [2022-04-11 19:22:00,893] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:01,134] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:01,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:01,267] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:01,277] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:01,481] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.640 seconds
[2022-04-11 19:22:06,978] {scheduler_job.py:153} INFO - Started process (PID=22411) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:07,004] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:07,012] {logging_mixin.py:112} INFO - [2022-04-11 19:22:07,009] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:08,598] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:08,935] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:08,948] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:08,977] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:13,187] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 6.209 seconds
[2022-04-11 19:22:18,719] {scheduler_job.py:153} INFO - Started process (PID=22414) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:18,734] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:18,736] {logging_mixin.py:112} INFO - [2022-04-11 19:22:18,735] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:19,333] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:20,183] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:20,192] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:20,319] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:24,755] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 6.035 seconds
[2022-04-11 19:22:28,446] {scheduler_job.py:153} INFO - Started process (PID=22418) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:28,455] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:28,458] {logging_mixin.py:112} INFO - [2022-04-11 19:22:28,456] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:28,533] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:28,706] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:28,709] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:28,723] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:29,332] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.887 seconds
[2022-04-11 19:22:31,284] {scheduler_job.py:153} INFO - Started process (PID=22421) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:31,322] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:31,325] {logging_mixin.py:112} INFO - [2022-04-11 19:22:31,324] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:31,521] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:31,625] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:31,630] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:31,644] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:31,937] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.653 seconds
[2022-04-11 19:22:33,006] {scheduler_job.py:153} INFO - Started process (PID=22424) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:33,017] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:33,019] {logging_mixin.py:112} INFO - [2022-04-11 19:22:33,019] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:33,064] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:33,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:33,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:33,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:33,343] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.337 seconds
[2022-04-11 19:22:38,555] {scheduler_job.py:153} INFO - Started process (PID=22427) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:38,566] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:38,567] {logging_mixin.py:112} INFO - [2022-04-11 19:22:38,567] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:38,619] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:38,765] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:38,768] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:38,782] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:40,165] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.610 seconds
[2022-04-11 19:22:49,233] {scheduler_job.py:153} INFO - Started process (PID=22430) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:49,238] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:22:49,240] {logging_mixin.py:112} INFO - [2022-04-11 19:22:49,239] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:49,293] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:22:49,397] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:49,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:22:49,408] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:22:50,689] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.456 seconds
[2022-04-11 19:23:06,601] {scheduler_job.py:153} INFO - Started process (PID=22434) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:06,617] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:23:06,622] {logging_mixin.py:112} INFO - [2022-04-11 19:23:06,622] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:06,714] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:23:06,977] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:06,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:07,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:08,308] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.707 seconds
[2022-04-11 19:23:15,900] {scheduler_job.py:153} INFO - Started process (PID=22438) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:15,915] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:23:15,926] {logging_mixin.py:112} INFO - [2022-04-11 19:23:15,925] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:16,047] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:23:16,213] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:16,215] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:16,224] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:17,396] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.496 seconds
[2022-04-11 19:23:18,868] {scheduler_job.py:153} INFO - Started process (PID=22441) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:18,874] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:23:18,876] {logging_mixin.py:112} INFO - [2022-04-11 19:23:18,876] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:18,914] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:23:19,154] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:19,158] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:19,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:20,066] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.198 seconds
[2022-04-11 19:23:22,449] {scheduler_job.py:153} INFO - Started process (PID=22445) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:22,457] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:23:22,459] {logging_mixin.py:112} INFO - [2022-04-11 19:23:22,459] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:22,496] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:23:22,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:22,609] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:22,620] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:22,898] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.448 seconds
[2022-04-11 19:23:27,335] {scheduler_job.py:153} INFO - Started process (PID=22448) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:27,448] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:23:27,485] {logging_mixin.py:112} INFO - [2022-04-11 19:23:27,485] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:28,447] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:23:28,907] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:28,909] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:28,918] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:29,425] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.091 seconds
[2022-04-11 19:23:37,864] {scheduler_job.py:153} INFO - Started process (PID=22451) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:37,872] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:23:37,873] {logging_mixin.py:112} INFO - [2022-04-11 19:23:37,873] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:23:38,984] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:23:40,472] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:40,481] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:23:40,573] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:08,545] {scheduler_job.py:1649} ERROR - Error logging import errors!
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1647, in process_file
    self.update_import_errors(session, dagbag)
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 604, in update_import_errors
    session.query(errors.ImportError).filter(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3926, in delete
    delete_op.exec_()
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1697, in exec_
    self._do_exec()
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1930, in _do_exec
    self._execute_stmt(delete_stmt)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py", line 1702, in _execute_stmt
    self.result = self.query._execute_crud(stmt, self.mapper)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3568, in _execute_crud
    return conn.execute(stmt, self._params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: DELETE FROM import_error WHERE import_error.filename = ?]
[parameters: ('/c/users/dan/airflow/dags/big_query_data_load.py',)]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-04-11 19:24:09,584] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 31.721 seconds
[2022-04-11 19:24:16,470] {scheduler_job.py:153} INFO - Started process (PID=22455) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:16,497] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:16,501] {logging_mixin.py:112} INFO - [2022-04-11 19:24:16,501] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:16,625] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:17,337] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:17,345] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:17,370] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:19,882] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.412 seconds
[2022-04-11 19:24:23,429] {scheduler_job.py:153} INFO - Started process (PID=22459) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:23,437] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:23,440] {logging_mixin.py:112} INFO - [2022-04-11 19:24:23,439] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:23,917] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:24,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:24,169] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:24,181] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:24,590] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.161 seconds
[2022-04-11 19:24:26,541] {scheduler_job.py:153} INFO - Started process (PID=22462) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:26,549] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:26,551] {logging_mixin.py:112} INFO - [2022-04-11 19:24:26,551] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:26,609] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:26,750] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:26,752] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:26,774] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:27,308] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.768 seconds
[2022-04-11 19:24:28,740] {scheduler_job.py:153} INFO - Started process (PID=22465) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:28,751] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:28,753] {logging_mixin.py:112} INFO - [2022-04-11 19:24:28,753] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:28,829] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:28,980] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:28,983] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:28,997] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:29,333] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.593 seconds
[2022-04-11 19:24:30,920] {scheduler_job.py:153} INFO - Started process (PID=22468) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:30,932] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:30,933] {logging_mixin.py:112} INFO - [2022-04-11 19:24:30,933] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:30,967] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:31,327] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:31,329] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:31,348] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:31,737] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.817 seconds
[2022-04-11 19:24:36,964] {scheduler_job.py:153} INFO - Started process (PID=22472) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:36,982] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:36,984] {logging_mixin.py:112} INFO - [2022-04-11 19:24:36,984] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:37,027] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:37,294] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:37,297] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:37,314] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:37,580] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.625 seconds
[2022-04-11 19:24:42,976] {scheduler_job.py:153} INFO - Started process (PID=22475) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:42,986] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:42,988] {logging_mixin.py:112} INFO - [2022-04-11 19:24:42,988] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:43,023] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:43,292] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:43,294] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:43,304] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:43,565] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.590 seconds
[2022-04-11 19:24:48,967] {scheduler_job.py:153} INFO - Started process (PID=22478) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:48,975] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:48,978] {logging_mixin.py:112} INFO - [2022-04-11 19:24:48,977] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:49,032] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:24:49,855] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:49,859] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:24:49,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:50,218] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.251 seconds
[2022-04-11 19:24:55,709] {scheduler_job.py:153} INFO - Started process (PID=22482) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:55,764] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:24:55,775] {logging_mixin.py:112} INFO - [2022-04-11 19:24:55,775] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:24:56,300] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:01,651] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:01,656] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:01,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:04,148] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 8.439 seconds
[2022-04-11 19:25:08,295] {scheduler_job.py:153} INFO - Started process (PID=22485) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:08,307] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:08,310] {logging_mixin.py:112} INFO - [2022-04-11 19:25:08,309] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:08,394] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:08,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:08,612] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:08,628] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:09,162] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.868 seconds
[2022-04-11 19:25:10,814] {scheduler_job.py:153} INFO - Started process (PID=22488) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:10,832] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:10,834] {logging_mixin.py:112} INFO - [2022-04-11 19:25:10,834] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:11,020] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:11,723] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:11,732] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:11,764] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:12,168] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.362 seconds
[2022-04-11 19:25:14,902] {scheduler_job.py:153} INFO - Started process (PID=22491) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:14,913] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:14,915] {logging_mixin.py:112} INFO - [2022-04-11 19:25:14,915] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:14,966] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:15,172] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:15,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:15,224] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:15,689] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.788 seconds
[2022-04-11 19:25:20,886] {scheduler_job.py:153} INFO - Started process (PID=22494) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:20,915] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:20,959] {logging_mixin.py:112} INFO - [2022-04-11 19:25:20,959] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:21,163] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:21,413] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:21,415] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:21,481] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:21,931] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.046 seconds
[2022-04-11 19:25:26,841] {scheduler_job.py:153} INFO - Started process (PID=22497) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:26,846] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:26,848] {logging_mixin.py:112} INFO - [2022-04-11 19:25:26,847] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:26,894] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:26,976] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:26,977] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:26,984] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:27,212] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.372 seconds
[2022-04-11 19:25:32,954] {scheduler_job.py:153} INFO - Started process (PID=22500) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:32,968] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:32,970] {logging_mixin.py:112} INFO - [2022-04-11 19:25:32,970] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:33,093] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:33,468] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:33,476] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:33,494] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:33,952] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.999 seconds
[2022-04-11 19:25:38,834] {scheduler_job.py:153} INFO - Started process (PID=22504) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:38,840] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:38,842] {logging_mixin.py:112} INFO - [2022-04-11 19:25:38,842] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:38,901] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:38,992] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:38,994] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:39,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:39,149] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.315 seconds
[2022-04-11 19:25:44,854] {scheduler_job.py:153} INFO - Started process (PID=22507) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:44,867] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:44,868] {logging_mixin.py:112} INFO - [2022-04-11 19:25:44,868] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:44,958] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:45,257] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:45,259] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:45,280] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:45,530] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.676 seconds
[2022-04-11 19:25:50,866] {scheduler_job.py:153} INFO - Started process (PID=22510) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:50,871] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:50,873] {logging_mixin.py:112} INFO - [2022-04-11 19:25:50,873] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:50,904] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:50,985] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:50,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:50,996] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:51,144] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.279 seconds
[2022-04-11 19:25:57,379] {scheduler_job.py:153} INFO - Started process (PID=22513) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:57,397] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:25:57,399] {logging_mixin.py:112} INFO - [2022-04-11 19:25:57,399] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:57,498] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:25:57,697] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:57,700] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:25:57,733] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:25:58,052] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.674 seconds
[2022-04-11 19:26:02,937] {scheduler_job.py:153} INFO - Started process (PID=22516) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:02,953] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:02,959] {logging_mixin.py:112} INFO - [2022-04-11 19:26:02,959] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:03,027] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:03,231] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:03,234] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:03,267] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:03,528] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.592 seconds
[2022-04-11 19:26:09,086] {scheduler_job.py:153} INFO - Started process (PID=22520) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:09,168] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:09,173] {logging_mixin.py:112} INFO - [2022-04-11 19:26:09,173] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:09,517] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:10,164] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:10,167] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:10,200] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:11,420] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.334 seconds
[2022-04-11 19:26:17,484] {scheduler_job.py:153} INFO - Started process (PID=22523) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:17,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:17,520] {logging_mixin.py:112} INFO - [2022-04-11 19:26:17,520] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:17,731] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:18,251] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:18,268] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:18,311] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:20,825] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.342 seconds
[2022-04-11 19:26:24,311] {scheduler_job.py:153} INFO - Started process (PID=22526) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:24,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:24,321] {logging_mixin.py:112} INFO - [2022-04-11 19:26:24,319] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:24,366] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:24,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:24,556] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:24,574] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:24,847] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.537 seconds
[2022-04-11 19:26:28,723] {scheduler_job.py:153} INFO - Started process (PID=22529) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:28,739] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:28,741] {logging_mixin.py:112} INFO - [2022-04-11 19:26:28,741] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:28,831] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:28,963] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:28,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:28,977] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:29,182] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.460 seconds
[2022-04-11 19:26:34,771] {scheduler_job.py:153} INFO - Started process (PID=22532) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:34,779] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:34,784] {logging_mixin.py:112} INFO - [2022-04-11 19:26:34,783] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:34,903] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:35,080] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:35,082] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:35,104] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:35,598] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.828 seconds
[2022-04-11 19:26:40,837] {scheduler_job.py:153} INFO - Started process (PID=22535) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:40,852] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:40,854] {logging_mixin.py:112} INFO - [2022-04-11 19:26:40,854] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:40,915] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:41,187] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:41,190] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:41,240] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:41,662] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.825 seconds
[2022-04-11 19:26:46,764] {scheduler_job.py:153} INFO - Started process (PID=22538) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:46,773] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:46,774] {logging_mixin.py:112} INFO - [2022-04-11 19:26:46,774] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:46,867] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:47,225] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:47,227] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:47,256] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:47,542] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.778 seconds
[2022-04-11 19:26:52,723] {scheduler_job.py:153} INFO - Started process (PID=22542) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:52,734] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:52,737] {logging_mixin.py:112} INFO - [2022-04-11 19:26:52,736] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:52,774] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:52,885] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:52,887] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:52,896] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:53,089] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.366 seconds
[2022-04-11 19:26:58,779] {scheduler_job.py:153} INFO - Started process (PID=22545) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:58,786] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:26:58,788] {logging_mixin.py:112} INFO - [2022-04-11 19:26:58,788] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:26:58,832] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:26:59,257] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:59,259] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:26:59,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:00,214] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.435 seconds
[2022-04-11 19:27:04,759] {scheduler_job.py:153} INFO - Started process (PID=22549) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:04,769] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:04,772] {logging_mixin.py:112} INFO - [2022-04-11 19:27:04,771] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:04,814] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:04,929] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:04,932] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:04,943] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:05,111] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.352 seconds
[2022-04-11 19:27:10,837] {scheduler_job.py:153} INFO - Started process (PID=22552) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:10,851] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:10,853] {logging_mixin.py:112} INFO - [2022-04-11 19:27:10,852] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:10,929] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:11,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:11,055] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:11,106] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:11,362] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.525 seconds
[2022-04-11 19:27:16,789] {scheduler_job.py:153} INFO - Started process (PID=22556) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:16,806] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:16,808] {logging_mixin.py:112} INFO - [2022-04-11 19:27:16,808] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:16,879] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:17,044] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:17,046] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:17,056] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:17,234] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.446 seconds
[2022-04-11 19:27:22,935] {scheduler_job.py:153} INFO - Started process (PID=22560) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:22,956] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:22,970] {logging_mixin.py:112} INFO - [2022-04-11 19:27:22,969] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:23,030] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:23,299] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:23,304] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:23,318] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:23,708] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.773 seconds
[2022-04-11 19:27:34,849] {scheduler_job.py:153} INFO - Started process (PID=22566) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:34,859] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:34,860] {logging_mixin.py:112} INFO - [2022-04-11 19:27:34,860] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:34,903] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:34,996] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:34,998] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:35,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:35,200] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.351 seconds
[2022-04-11 19:27:42,792] {scheduler_job.py:153} INFO - Started process (PID=22570) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:42,802] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:42,805] {logging_mixin.py:112} INFO - [2022-04-11 19:27:42,805] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:42,864] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:42,987] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:42,995] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:43,009] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:43,212] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.421 seconds
[2022-04-11 19:27:50,804] {scheduler_job.py:153} INFO - Started process (PID=22574) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:50,813] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:27:50,816] {logging_mixin.py:112} INFO - [2022-04-11 19:27:50,816] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:50,863] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:27:50,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:50,993] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:27:51,003] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:27:51,193] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.389 seconds
[2022-04-11 19:28:02,889] {scheduler_job.py:153} INFO - Started process (PID=22580) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:02,898] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:02,900] {logging_mixin.py:112} INFO - [2022-04-11 19:28:02,899] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:02,954] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:03,097] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:03,099] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:03,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:03,432] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.543 seconds
[2022-04-11 19:28:09,242] {scheduler_job.py:153} INFO - Started process (PID=22585) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:09,250] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:09,252] {logging_mixin.py:112} INFO - [2022-04-11 19:28:09,252] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:09,288] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:09,404] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:09,407] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:09,418] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:09,659] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.417 seconds
[2022-04-11 19:28:17,329] {scheduler_job.py:153} INFO - Started process (PID=22589) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:17,339] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:17,348] {logging_mixin.py:112} INFO - [2022-04-11 19:28:17,348] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:17,453] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:17,716] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:17,719] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:17,745] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:18,096] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.767 seconds
[2022-04-11 19:28:25,326] {scheduler_job.py:153} INFO - Started process (PID=22593) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:25,335] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:25,338] {logging_mixin.py:112} INFO - [2022-04-11 19:28:25,337] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:25,426] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:25,551] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:25,553] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:25,567] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:25,783] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.458 seconds
[2022-04-11 19:28:33,278] {scheduler_job.py:153} INFO - Started process (PID=22597) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:33,293] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:33,295] {logging_mixin.py:112} INFO - [2022-04-11 19:28:33,295] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:33,354] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:33,497] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:33,499] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:33,515] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:33,728] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.449 seconds
[2022-04-11 19:28:41,287] {scheduler_job.py:153} INFO - Started process (PID=22602) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:41,298] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:41,300] {logging_mixin.py:112} INFO - [2022-04-11 19:28:41,299] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:41,351] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:41,492] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:41,495] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:41,509] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:41,717] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.430 seconds
[2022-04-11 19:28:49,353] {scheduler_job.py:153} INFO - Started process (PID=22606) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:49,364] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:49,366] {logging_mixin.py:112} INFO - [2022-04-11 19:28:49,365] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:49,428] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:49,587] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:49,592] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:49,601] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:49,983] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.631 seconds
[2022-04-11 19:28:57,346] {scheduler_job.py:153} INFO - Started process (PID=22610) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:57,358] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:28:57,364] {logging_mixin.py:112} INFO - [2022-04-11 19:28:57,364] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:57,551] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:28:57,666] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:57,668] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:28:57,679] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:28:57,832] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.492 seconds
[2022-04-11 19:29:05,341] {scheduler_job.py:153} INFO - Started process (PID=22614) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:05,349] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:05,351] {logging_mixin.py:112} INFO - [2022-04-11 19:29:05,350] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:05,428] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:05,675] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:05,678] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:05,699] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:06,202] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.861 seconds
[2022-04-11 19:29:13,357] {scheduler_job.py:153} INFO - Started process (PID=22619) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:13,362] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:13,363] {logging_mixin.py:112} INFO - [2022-04-11 19:29:13,363] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:13,394] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:13,478] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:13,479] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:13,488] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:13,636] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.280 seconds
[2022-04-11 19:29:21,530] {scheduler_job.py:153} INFO - Started process (PID=22623) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:21,539] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:21,570] {logging_mixin.py:112} INFO - [2022-04-11 19:29:21,548] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:21,640] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:22,019] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:22,023] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:22,050] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:22,691] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.161 seconds
[2022-04-11 19:29:29,370] {scheduler_job.py:153} INFO - Started process (PID=22627) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:29,377] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:29,378] {logging_mixin.py:112} INFO - [2022-04-11 19:29:29,378] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:29,417] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:29,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:29,504] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:29,513] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:29,681] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.311 seconds
[2022-04-11 19:29:37,394] {scheduler_job.py:153} INFO - Started process (PID=22631) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:37,410] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:37,413] {logging_mixin.py:112} INFO - [2022-04-11 19:29:37,412] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:37,462] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:37,601] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:37,606] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:37,617] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:37,828] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.434 seconds
[2022-04-11 19:29:45,402] {scheduler_job.py:153} INFO - Started process (PID=22636) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:45,413] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:45,418] {logging_mixin.py:112} INFO - [2022-04-11 19:29:45,416] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:45,502] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:45,654] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:45,662] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:45,681] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:46,032] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.630 seconds
[2022-04-11 19:29:54,394] {scheduler_job.py:153} INFO - Started process (PID=22640) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:54,410] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:29:54,417] {logging_mixin.py:112} INFO - [2022-04-11 19:29:54,416] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:29:54,512] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:29:54,651] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:54,656] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:29:54,669] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:03,770] {scheduler_job.py:166} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: database is locked

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 156, in _run_file_processor
    result = scheduler_job.process_file(file_path,
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1584, in process_file
    paused_dag_ids = [dag.dag_id for dag in dagbag.dags.values()
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job.py", line 1585, in <listcomp>
    if dag.is_paused]
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 646, in is_paused
    return self._get_is_paused()
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/collid/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 639, in _get_is_paused
    return qry.value(DagModel.is_paused)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1544, in value
    return next(self.values(column))[0]
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 1534, in values
    return iter(q)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3535, in __iter__
    return self._execute_and_instances(context)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/orm/query.py", line 3560, in _execute_and_instances
    result = conn.execute(querycontext.statement, self._params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1124, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1316, in _execute_context
    self._handle_dbapi_exception(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1510, in _handle_dbapi_exception
    util.raise_(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1276, in _execute_context
    self.dialect.do_execute(
  File "/home/collid/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) database is locked
[SQL: SELECT dag.is_paused AS dag_is_paused 
FROM dag 
WHERE dag.dag_id = ?]
[parameters: ('bigquery_data_load',)]
(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-04-11 19:30:26,896] {scheduler_job.py:153} INFO - Started process (PID=22645) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:26,934] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:30:26,937] {logging_mixin.py:112} INFO - [2022-04-11 19:30:26,937] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:27,075] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:30:27,263] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:27,273] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:27,306] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:28,051] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.155 seconds
[2022-04-11 19:30:31,693] {scheduler_job.py:153} INFO - Started process (PID=22649) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:31,709] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:30:31,718] {logging_mixin.py:112} INFO - [2022-04-11 19:30:31,718] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:31,794] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:30:31,939] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:31,942] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:31,953] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:32,284] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.592 seconds
[2022-04-11 19:30:39,687] {scheduler_job.py:153} INFO - Started process (PID=22653) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:39,700] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:30:39,706] {logging_mixin.py:112} INFO - [2022-04-11 19:30:39,702] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:39,843] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:30:40,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:40,006] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:40,017] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:40,390] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.703 seconds
[2022-04-11 19:30:56,699] {scheduler_job.py:153} INFO - Started process (PID=22657) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:56,717] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:30:56,729] {logging_mixin.py:112} INFO - [2022-04-11 19:30:56,728] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:56,956] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:30:57,236] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:57,245] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:30:57,265] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:30:57,883] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.184 seconds
[2022-04-11 19:31:02,000] {scheduler_job.py:153} INFO - Started process (PID=22662) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:02,015] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:02,029] {logging_mixin.py:112} INFO - [2022-04-11 19:31:02,029] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:02,202] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:02,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:02,419] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:02,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:03,690] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.690 seconds
[2022-04-11 19:31:09,986] {scheduler_job.py:153} INFO - Started process (PID=22666) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:09,992] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:09,994] {logging_mixin.py:112} INFO - [2022-04-11 19:31:09,994] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:10,030] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:10,118] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:10,121] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:10,129] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:10,284] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.299 seconds
[2022-04-11 19:31:18,521] {scheduler_job.py:153} INFO - Started process (PID=22670) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:18,528] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:18,529] {logging_mixin.py:112} INFO - [2022-04-11 19:31:18,529] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:18,969] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:19,191] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:19,194] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:19,204] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:19,521] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.000 seconds
[2022-04-11 19:31:26,020] {scheduler_job.py:153} INFO - Started process (PID=22674) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:26,026] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:26,028] {logging_mixin.py:112} INFO - [2022-04-11 19:31:26,028] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:26,063] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:26,163] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:26,165] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:26,175] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:26,344] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.324 seconds
[2022-04-11 19:31:34,025] {scheduler_job.py:153} INFO - Started process (PID=22678) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:34,046] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:34,050] {logging_mixin.py:112} INFO - [2022-04-11 19:31:34,050] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:34,101] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:34,202] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:34,204] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:34,213] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:34,361] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-04-11 19:31:42,248] {scheduler_job.py:153} INFO - Started process (PID=22683) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:42,255] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:42,258] {logging_mixin.py:112} INFO - [2022-04-11 19:31:42,258] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:42,335] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:42,609] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:42,611] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:42,623] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:43,183] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.935 seconds
[2022-04-11 19:31:50,054] {scheduler_job.py:153} INFO - Started process (PID=22687) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:50,060] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:50,061] {logging_mixin.py:112} INFO - [2022-04-11 19:31:50,061] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:50,111] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:50,233] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:50,235] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:50,245] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:50,643] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.589 seconds
[2022-04-11 19:31:58,077] {scheduler_job.py:153} INFO - Started process (PID=22691) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:58,082] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:31:58,083] {logging_mixin.py:112} INFO - [2022-04-11 19:31:58,083] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:31:58,121] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:31:58,313] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:58,315] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:31:58,340] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:00,625] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.549 seconds
[2022-04-11 19:32:06,152] {scheduler_job.py:153} INFO - Started process (PID=22695) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:06,158] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:06,162] {logging_mixin.py:112} INFO - [2022-04-11 19:32:06,161] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:06,197] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:06,711] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:06,713] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:06,727] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:07,326] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.175 seconds
[2022-04-11 19:32:14,111] {scheduler_job.py:153} INFO - Started process (PID=22700) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:14,117] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:14,118] {logging_mixin.py:112} INFO - [2022-04-11 19:32:14,118] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:14,149] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:14,235] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:14,237] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:14,245] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:14,524] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.412 seconds
[2022-04-11 19:32:22,208] {scheduler_job.py:153} INFO - Started process (PID=22704) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:22,235] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:22,245] {logging_mixin.py:112} INFO - [2022-04-11 19:32:22,244] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:22,358] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:22,515] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:22,518] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:22,532] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:22,748] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.540 seconds
[2022-04-11 19:32:31,139] {scheduler_job.py:153} INFO - Started process (PID=22709) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:31,151] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:31,159] {logging_mixin.py:112} INFO - [2022-04-11 19:32:31,158] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:31,250] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:31,417] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:31,420] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:31,434] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:31,767] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.631 seconds
[2022-04-11 19:32:39,372] {scheduler_job.py:153} INFO - Started process (PID=22713) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:39,410] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:39,420] {logging_mixin.py:112} INFO - [2022-04-11 19:32:39,419] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:39,565] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:40,010] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:40,021] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:40,065] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:40,424] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.052 seconds
[2022-04-11 19:32:47,174] {scheduler_job.py:153} INFO - Started process (PID=22718) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:47,220] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:47,231] {logging_mixin.py:112} INFO - [2022-04-11 19:32:47,231] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:47,330] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:47,634] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:47,638] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:47,661] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:47,844] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.670 seconds
[2022-04-11 19:32:55,087] {scheduler_job.py:153} INFO - Started process (PID=22722) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:55,096] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:32:55,098] {logging_mixin.py:112} INFO - [2022-04-11 19:32:55,097] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:55,130] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:32:55,335] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:55,341] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:32:55,350] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:32:55,508] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.421 seconds
[2022-04-11 19:33:03,393] {scheduler_job.py:153} INFO - Started process (PID=22726) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:03,408] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:03,411] {logging_mixin.py:112} INFO - [2022-04-11 19:33:03,411] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:03,468] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:03,599] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:03,601] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:03,611] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:03,785] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.392 seconds
[2022-04-11 19:33:11,125] {scheduler_job.py:153} INFO - Started process (PID=22730) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:11,156] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:11,162] {logging_mixin.py:112} INFO - [2022-04-11 19:33:11,161] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:11,210] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:11,355] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:11,357] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:11,368] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:11,602] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.477 seconds
[2022-04-11 19:33:19,197] {scheduler_job.py:153} INFO - Started process (PID=22735) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:19,217] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:19,219] {logging_mixin.py:112} INFO - [2022-04-11 19:33:19,219] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:19,282] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:19,450] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:19,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:19,470] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:19,698] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.501 seconds
[2022-04-11 19:33:27,268] {scheduler_job.py:153} INFO - Started process (PID=22739) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:27,286] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:27,288] {logging_mixin.py:112} INFO - [2022-04-11 19:33:27,288] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:27,350] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:27,540] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:27,546] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:27,571] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:27,817] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.549 seconds
[2022-04-11 19:33:35,351] {scheduler_job.py:153} INFO - Started process (PID=22743) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:35,361] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:35,364] {logging_mixin.py:112} INFO - [2022-04-11 19:33:35,364] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:35,432] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:35,546] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:35,549] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:35,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:35,808] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.458 seconds
[2022-04-11 19:33:43,841] {scheduler_job.py:153} INFO - Started process (PID=22747) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:43,873] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:43,894] {logging_mixin.py:112} INFO - [2022-04-11 19:33:43,892] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:44,073] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:44,263] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:44,268] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:44,285] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:44,611] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.773 seconds
[2022-04-11 19:33:52,769] {scheduler_job.py:153} INFO - Started process (PID=22752) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:52,794] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:33:52,796] {logging_mixin.py:112} INFO - [2022-04-11 19:33:52,795] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:52,864] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:33:53,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:53,096] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:33:53,114] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:33:53,930] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.162 seconds
[2022-04-11 19:34:00,180] {scheduler_job.py:153} INFO - Started process (PID=22756) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:00,257] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:00,269] {logging_mixin.py:112} INFO - [2022-04-11 19:34:00,269] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:00,483] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:00,692] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:00,701] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:00,738] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:02,820] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.641 seconds
[2022-04-11 19:34:08,847] {scheduler_job.py:153} INFO - Started process (PID=22760) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:08,876] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:08,903] {logging_mixin.py:112} INFO - [2022-04-11 19:34:08,903] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:09,065] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:09,339] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:09,354] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:09,401] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:09,694] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.848 seconds
[2022-04-11 19:34:21,658] {scheduler_job.py:153} INFO - Started process (PID=22764) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:21,665] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:21,667] {logging_mixin.py:112} INFO - [2022-04-11 19:34:21,667] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:21,713] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:21,899] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:21,902] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:21,919] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:22,121] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.464 seconds
[2022-04-11 19:34:24,589] {scheduler_job.py:153} INFO - Started process (PID=22768) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:24,595] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:24,596] {logging_mixin.py:112} INFO - [2022-04-11 19:34:24,596] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:24,630] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:24,719] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:24,722] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:24,731] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:25,013] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.425 seconds
[2022-04-11 19:34:33,920] {scheduler_job.py:153} INFO - Started process (PID=22773) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:33,936] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:33,942] {logging_mixin.py:112} INFO - [2022-04-11 19:34:33,942] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:33,981] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:34,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:34,072] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:34,081] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:34,880] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.960 seconds
[2022-04-11 19:34:41,108] {scheduler_job.py:153} INFO - Started process (PID=22777) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:41,120] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:41,122] {logging_mixin.py:112} INFO - [2022-04-11 19:34:41,122] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:41,192] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:41,370] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:41,372] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:41,384] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:41,664] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.556 seconds
[2022-04-11 19:34:49,133] {scheduler_job.py:153} INFO - Started process (PID=22781) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:49,142] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:49,144] {logging_mixin.py:112} INFO - [2022-04-11 19:34:49,143] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:49,186] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:49,728] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:49,730] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:49,861] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:50,416] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.283 seconds
[2022-04-11 19:34:57,139] {scheduler_job.py:153} INFO - Started process (PID=22785) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:57,147] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:34:57,148] {logging_mixin.py:112} INFO - [2022-04-11 19:34:57,148] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:57,180] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:34:57,283] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:57,284] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:34:57,294] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:34:57,443] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.305 seconds
[2022-04-11 19:35:05,162] {scheduler_job.py:153} INFO - Started process (PID=22790) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:05,171] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:05,177] {logging_mixin.py:112} INFO - [2022-04-11 19:35:05,176] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:05,237] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:05,377] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:05,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:05,413] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:05,676] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.514 seconds
[2022-04-11 19:35:13,193] {scheduler_job.py:153} INFO - Started process (PID=22794) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:13,206] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:13,214] {logging_mixin.py:112} INFO - [2022-04-11 19:35:13,214] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:13,330] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:13,522] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:13,536] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:13,553] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:13,927] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.735 seconds
[2022-04-11 19:35:21,206] {scheduler_job.py:153} INFO - Started process (PID=22798) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:21,224] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:21,227] {logging_mixin.py:112} INFO - [2022-04-11 19:35:21,227] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:21,272] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:21,382] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:21,384] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:21,394] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:21,584] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.378 seconds
[2022-04-11 19:35:29,182] {scheduler_job.py:153} INFO - Started process (PID=22802) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:29,191] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:29,194] {logging_mixin.py:112} INFO - [2022-04-11 19:35:29,193] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:29,235] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:29,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:29,764] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:29,777] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:29,996] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.815 seconds
[2022-04-11 19:35:37,258] {scheduler_job.py:153} INFO - Started process (PID=22807) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:37,267] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:37,270] {logging_mixin.py:112} INFO - [2022-04-11 19:35:37,269] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:37,324] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:37,535] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:37,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:37,557] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:37,825] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.567 seconds
[2022-04-11 19:35:45,257] {scheduler_job.py:153} INFO - Started process (PID=22812) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:45,274] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:45,296] {logging_mixin.py:112} INFO - [2022-04-11 19:35:45,296] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:45,486] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:46,748] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:46,754] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:46,835] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:47,235] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.979 seconds
[2022-04-11 19:35:53,215] {scheduler_job.py:153} INFO - Started process (PID=22862) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:53,221] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:35:53,222] {logging_mixin.py:112} INFO - [2022-04-11 19:35:53,222] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:53,252] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:35:53,330] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:53,331] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:35:53,341] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:35:53,496] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.281 seconds
[2022-04-11 19:36:01,251] {scheduler_job.py:153} INFO - Started process (PID=22871) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:01,260] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:01,262] {logging_mixin.py:112} INFO - [2022-04-11 19:36:01,262] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:01,330] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:01,461] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:01,463] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:01,473] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:01,650] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.399 seconds
[2022-04-11 19:36:09,282] {scheduler_job.py:153} INFO - Started process (PID=22905) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:09,309] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:09,311] {logging_mixin.py:112} INFO - [2022-04-11 19:36:09,311] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:09,385] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:09,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:09,550] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:09,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:09,773] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.491 seconds
[2022-04-11 19:36:32,193] {scheduler_job.py:153} INFO - Started process (PID=22915) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:32,206] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:32,211] {logging_mixin.py:112} INFO - [2022-04-11 19:36:32,210] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:32,263] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:32,437] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:32,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:32,484] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:33,069] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.876 seconds
[2022-04-11 19:36:36,119] {scheduler_job.py:153} INFO - Started process (PID=22919) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:36,129] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:36,130] {logging_mixin.py:112} INFO - [2022-04-11 19:36:36,130] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:36,181] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:36,327] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:36,329] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:36,343] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:36,680] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.561 seconds
[2022-04-11 19:36:44,119] {scheduler_job.py:153} INFO - Started process (PID=22923) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:44,174] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:44,185] {logging_mixin.py:112} INFO - [2022-04-11 19:36:44,184] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:44,713] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:44,869] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:44,876] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:44,890] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:45,300] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.181 seconds
[2022-04-11 19:36:48,281] {scheduler_job.py:153} INFO - Started process (PID=22927) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:48,292] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:48,294] {logging_mixin.py:112} INFO - [2022-04-11 19:36:48,294] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:48,346] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:48,468] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:48,471] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:48,488] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:48,903] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.622 seconds
[2022-04-11 19:36:57,247] {scheduler_job.py:153} INFO - Started process (PID=22931) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:57,259] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:36:57,261] {logging_mixin.py:112} INFO - [2022-04-11 19:36:57,261] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:57,318] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:36:57,466] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:57,468] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:36:57,482] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:36:57,844] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.597 seconds
[2022-04-11 19:37:04,562] {scheduler_job.py:153} INFO - Started process (PID=22936) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:04,599] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:04,613] {logging_mixin.py:112} INFO - [2022-04-11 19:37:04,612] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:04,711] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:05,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:05,091] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:05,109] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:05,656] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.095 seconds
[2022-04-11 19:37:12,574] {scheduler_job.py:153} INFO - Started process (PID=22940) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:12,583] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:12,585] {logging_mixin.py:112} INFO - [2022-04-11 19:37:12,585] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:12,647] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:12,774] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:12,776] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:12,784] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:13,100] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.526 seconds
[2022-04-11 19:37:20,547] {scheduler_job.py:153} INFO - Started process (PID=22944) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:20,552] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:20,554] {logging_mixin.py:112} INFO - [2022-04-11 19:37:20,554] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:20,587] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:20,663] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:20,664] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:20,673] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:20,857] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.310 seconds
[2022-04-11 19:37:29,074] {scheduler_job.py:153} INFO - Started process (PID=22948) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:29,082] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:29,091] {logging_mixin.py:112} INFO - [2022-04-11 19:37:29,090] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:29,714] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:30,383] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:30,385] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:30,398] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:30,561] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.487 seconds
[2022-04-11 19:37:36,591] {scheduler_job.py:153} INFO - Started process (PID=22952) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:36,601] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:36,602] {logging_mixin.py:112} INFO - [2022-04-11 19:37:36,602] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:36,661] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:36,816] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:36,818] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:36,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:37,032] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.441 seconds
[2022-04-11 19:37:48,047] {scheduler_job.py:153} INFO - Started process (PID=22957) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:48,086] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:48,100] {logging_mixin.py:112} INFO - [2022-04-11 19:37:48,100] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:48,189] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:49,349] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:49,375] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:49,417] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:49,647] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.600 seconds
[2022-04-11 19:37:54,698] {scheduler_job.py:153} INFO - Started process (PID=22961) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:54,707] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:37:54,709] {logging_mixin.py:112} INFO - [2022-04-11 19:37:54,709] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:54,810] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:37:54,930] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:54,932] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:37:54,947] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:37:55,259] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.561 seconds
[2022-04-11 19:38:05,604] {scheduler_job.py:153} INFO - Started process (PID=22965) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:05,624] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:05,636] {logging_mixin.py:112} INFO - [2022-04-11 19:38:05,635] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:05,919] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:08,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:08,614] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:08,744] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:10,496] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.893 seconds
[2022-04-11 19:38:13,779] {scheduler_job.py:153} INFO - Started process (PID=22969) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:13,790] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:13,799] {logging_mixin.py:112} INFO - [2022-04-11 19:38:13,799] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:13,867] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:14,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:14,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:14,074] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:14,569] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.792 seconds
[2022-04-11 19:38:21,182] {scheduler_job.py:153} INFO - Started process (PID=22974) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:21,199] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:21,211] {logging_mixin.py:112} INFO - [2022-04-11 19:38:21,202] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:21,291] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:22,264] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:22,275] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:22,316] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:22,682] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.500 seconds
[2022-04-11 19:38:29,893] {scheduler_job.py:153} INFO - Started process (PID=22978) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:29,900] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:29,903] {logging_mixin.py:112} INFO - [2022-04-11 19:38:29,902] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:29,954] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:30,113] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:30,116] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:30,128] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:30,394] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.500 seconds
[2022-04-11 19:38:38,030] {scheduler_job.py:153} INFO - Started process (PID=22982) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:38,083] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:38,097] {logging_mixin.py:112} INFO - [2022-04-11 19:38:38,097] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:38,735] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:39,401] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:39,403] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:39,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:39,777] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.747 seconds
[2022-04-11 19:38:45,925] {scheduler_job.py:153} INFO - Started process (PID=22986) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:45,942] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:45,945] {logging_mixin.py:112} INFO - [2022-04-11 19:38:45,944] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:46,009] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:46,157] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:46,159] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:46,168] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:46,346] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.421 seconds
[2022-04-11 19:38:53,908] {scheduler_job.py:153} INFO - Started process (PID=22990) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:53,916] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:38:53,918] {logging_mixin.py:112} INFO - [2022-04-11 19:38:53,918] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:53,973] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:38:54,080] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:54,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:38:54,095] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:38:54,306] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.398 seconds
[2022-04-11 19:39:03,352] {scheduler_job.py:153} INFO - Started process (PID=22995) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:03,423] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:03,472] {logging_mixin.py:112} INFO - [2022-04-11 19:39:03,471] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:03,934] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:05,780] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:05,783] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:05,795] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:05,995] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.644 seconds
[2022-04-11 19:39:10,858] {scheduler_job.py:153} INFO - Started process (PID=22999) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:10,870] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:10,876] {logging_mixin.py:112} INFO - [2022-04-11 19:39:10,876] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:10,929] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:11,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:11,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:11,103] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:11,332] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.475 seconds
[2022-04-11 19:39:18,811] {scheduler_job.py:153} INFO - Started process (PID=23003) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:18,819] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:18,823] {logging_mixin.py:112} INFO - [2022-04-11 19:39:18,822] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:18,861] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:18,969] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:18,976] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:18,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:19,147] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-04-11 19:39:26,818] {scheduler_job.py:153} INFO - Started process (PID=23007) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:26,826] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:26,828] {logging_mixin.py:112} INFO - [2022-04-11 19:39:26,827] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:26,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:26,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:26,999] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:27,021] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:27,229] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.412 seconds
[2022-04-11 19:39:34,843] {scheduler_job.py:153} INFO - Started process (PID=23011) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:34,850] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:34,852] {logging_mixin.py:112} INFO - [2022-04-11 19:39:34,852] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:34,892] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:35,151] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:35,154] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:35,162] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:35,552] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.709 seconds
[2022-04-11 19:39:43,082] {scheduler_job.py:153} INFO - Started process (PID=23016) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:43,104] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:43,118] {logging_mixin.py:112} INFO - [2022-04-11 19:39:43,118] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:43,293] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:43,389] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:43,391] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:43,414] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:43,615] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.533 seconds
[2022-04-11 19:39:50,870] {scheduler_job.py:153} INFO - Started process (PID=23020) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:50,884] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:50,893] {logging_mixin.py:112} INFO - [2022-04-11 19:39:50,893] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:50,976] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:51,060] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:51,062] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:51,072] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:51,583] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.713 seconds
[2022-04-11 19:39:58,880] {scheduler_job.py:153} INFO - Started process (PID=23024) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:58,889] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:39:58,890] {logging_mixin.py:112} INFO - [2022-04-11 19:39:58,890] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:58,941] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:39:59,083] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:59,085] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:39:59,094] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:39:59,288] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.408 seconds
[2022-04-11 19:40:06,877] {scheduler_job.py:153} INFO - Started process (PID=23028) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:06,884] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:06,885] {logging_mixin.py:112} INFO - [2022-04-11 19:40:06,885] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:06,917] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:07,022] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:07,024] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:07,032] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:07,180] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.304 seconds
[2022-04-11 19:40:14,891] {scheduler_job.py:153} INFO - Started process (PID=23033) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:14,898] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:14,900] {logging_mixin.py:112} INFO - [2022-04-11 19:40:14,900] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:14,936] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:15,029] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:15,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:15,045] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:15,187] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.296 seconds
[2022-04-11 19:40:22,909] {scheduler_job.py:153} INFO - Started process (PID=23037) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:22,917] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:22,919] {logging_mixin.py:112} INFO - [2022-04-11 19:40:22,919] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:22,951] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:23,043] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:23,045] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:23,054] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:23,260] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.351 seconds
[2022-04-11 19:40:30,928] {scheduler_job.py:153} INFO - Started process (PID=23041) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:30,935] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:30,936] {logging_mixin.py:112} INFO - [2022-04-11 19:40:30,936] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:30,966] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:31,056] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:31,059] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:31,075] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:31,253] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.325 seconds
[2022-04-11 19:40:39,094] {scheduler_job.py:153} INFO - Started process (PID=23045) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:39,106] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:39,117] {logging_mixin.py:112} INFO - [2022-04-11 19:40:39,117] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:39,284] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:40,050] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:40,070] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:40,108] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:42,646] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.558 seconds
[2022-04-11 19:40:47,727] {scheduler_job.py:153} INFO - Started process (PID=23050) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:47,809] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:47,856] {logging_mixin.py:112} INFO - [2022-04-11 19:40:47,856] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:48,074] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:48,721] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:48,731] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:48,763] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:50,294] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.566 seconds
[2022-04-11 19:40:56,369] {scheduler_job.py:153} INFO - Started process (PID=23054) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:56,403] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:40:56,479] {logging_mixin.py:112} INFO - [2022-04-11 19:40:56,478] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:56,751] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:40:57,533] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:57,536] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:40:57,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:40:58,954] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.585 seconds
[2022-04-11 19:41:04,080] {scheduler_job.py:153} INFO - Started process (PID=23058) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:04,109] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:04,111] {logging_mixin.py:112} INFO - [2022-04-11 19:41:04,111] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:04,202] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:04,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:04,459] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:04,478] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:04,895] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.816 seconds
[2022-04-11 19:41:12,059] {scheduler_job.py:153} INFO - Started process (PID=23062) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:12,069] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:12,071] {logging_mixin.py:112} INFO - [2022-04-11 19:41:12,071] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:12,114] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:12,226] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:12,228] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:12,243] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:12,507] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.449 seconds
[2022-04-11 19:41:20,098] {scheduler_job.py:153} INFO - Started process (PID=23066) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:20,117] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:20,163] {logging_mixin.py:112} INFO - [2022-04-11 19:41:20,139] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:20,480] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:21,820] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:21,846] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:21,894] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:25,399] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 5.301 seconds
[2022-04-11 19:41:30,097] {scheduler_job.py:153} INFO - Started process (PID=23071) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:30,110] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:30,112] {logging_mixin.py:112} INFO - [2022-04-11 19:41:30,112] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:30,203] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:30,616] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:30,633] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:30,705] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:33,653] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.556 seconds
[2022-04-11 19:41:38,310] {scheduler_job.py:153} INFO - Started process (PID=23075) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:38,335] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:38,372] {logging_mixin.py:112} INFO - [2022-04-11 19:41:38,371] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:38,603] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:39,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:39,099] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:39,125] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:39,412] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.108 seconds
[2022-04-11 19:41:46,471] {scheduler_job.py:153} INFO - Started process (PID=23080) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:46,488] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:46,497] {logging_mixin.py:112} INFO - [2022-04-11 19:41:46,497] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:46,571] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:46,769] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:46,777] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:46,795] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:47,228] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.758 seconds
[2022-04-11 19:41:54,284] {scheduler_job.py:153} INFO - Started process (PID=23085) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:54,292] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:41:54,293] {logging_mixin.py:112} INFO - [2022-04-11 19:41:54,293] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:54,336] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:41:54,464] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:54,466] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:41:54,476] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:41:54,673] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.389 seconds
[2022-04-11 19:42:02,356] {scheduler_job.py:153} INFO - Started process (PID=23089) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:02,371] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:02,383] {logging_mixin.py:112} INFO - [2022-04-11 19:42:02,382] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:02,618] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:02,916] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:02,918] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:02,932] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:04,044] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.689 seconds
[2022-04-11 19:42:11,484] {scheduler_job.py:153} INFO - Started process (PID=23094) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:11,518] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:11,537] {logging_mixin.py:112} INFO - [2022-04-11 19:42:11,537] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:11,783] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:12,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:12,200] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:12,218] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:12,665] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.182 seconds
[2022-04-11 19:42:19,418] {scheduler_job.py:153} INFO - Started process (PID=23098) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:19,447] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:19,449] {logging_mixin.py:112} INFO - [2022-04-11 19:42:19,449] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:19,588] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:19,923] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:19,937] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:19,972] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:20,260] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.842 seconds
[2022-04-11 19:42:27,446] {scheduler_job.py:153} INFO - Started process (PID=23102) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:27,459] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:27,465] {logging_mixin.py:112} INFO - [2022-04-11 19:42:27,465] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:27,644] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:27,810] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:27,815] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:27,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:28,070] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.624 seconds
[2022-04-11 19:42:35,257] {scheduler_job.py:153} INFO - Started process (PID=23106) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:35,267] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:35,269] {logging_mixin.py:112} INFO - [2022-04-11 19:42:35,269] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:35,304] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:35,408] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:35,410] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:35,417] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:35,627] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.370 seconds
[2022-04-11 19:42:43,277] {scheduler_job.py:153} INFO - Started process (PID=23110) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:43,284] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:43,286] {logging_mixin.py:112} INFO - [2022-04-11 19:42:43,286] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:43,346] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:43,502] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:43,505] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:43,517] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:43,720] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.443 seconds
[2022-04-11 19:42:51,361] {scheduler_job.py:153} INFO - Started process (PID=23115) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:51,369] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:51,371] {logging_mixin.py:112} INFO - [2022-04-11 19:42:51,371] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:51,440] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:42:51,581] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:51,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:42:51,599] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:51,815] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.454 seconds
[2022-04-11 19:42:59,381] {scheduler_job.py:153} INFO - Started process (PID=23119) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:59,406] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:42:59,435] {logging_mixin.py:112} INFO - [2022-04-11 19:42:59,435] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:42:59,567] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:00,100] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:00,108] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:00,126] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:00,361] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.980 seconds
[2022-04-11 19:43:07,442] {scheduler_job.py:153} INFO - Started process (PID=23123) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:07,455] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:07,458] {logging_mixin.py:112} INFO - [2022-04-11 19:43:07,458] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:07,531] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:07,735] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:07,737] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:07,747] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:08,063] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.621 seconds
[2022-04-11 19:43:15,486] {scheduler_job.py:153} INFO - Started process (PID=23127) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:15,496] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:15,500] {logging_mixin.py:112} INFO - [2022-04-11 19:43:15,500] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:15,903] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:16,671] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:16,674] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:16,688] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:17,734] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.252 seconds
[2022-04-11 19:43:23,626] {scheduler_job.py:153} INFO - Started process (PID=23132) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:23,634] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:23,641] {logging_mixin.py:112} INFO - [2022-04-11 19:43:23,640] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:23,712] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:24,041] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:24,043] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:24,055] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:24,720] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.096 seconds
[2022-04-11 19:43:31,399] {scheduler_job.py:153} INFO - Started process (PID=23136) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:31,411] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:31,426] {logging_mixin.py:112} INFO - [2022-04-11 19:43:31,426] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:31,544] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:31,643] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:31,645] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:31,656] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:31,846] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.447 seconds
[2022-04-11 19:43:39,574] {scheduler_job.py:153} INFO - Started process (PID=23140) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:39,597] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:39,602] {logging_mixin.py:112} INFO - [2022-04-11 19:43:39,602] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:39,828] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:40,004] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:40,007] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:40,022] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:40,274] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.700 seconds
[2022-04-11 19:43:47,412] {scheduler_job.py:153} INFO - Started process (PID=23144) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:47,422] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:47,428] {logging_mixin.py:112} INFO - [2022-04-11 19:43:47,427] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:47,500] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:47,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:47,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:47,719] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:47,882] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.470 seconds
[2022-04-11 19:43:55,420] {scheduler_job.py:153} INFO - Started process (PID=23148) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:55,430] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:43:55,432] {logging_mixin.py:112} INFO - [2022-04-11 19:43:55,432] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:55,483] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:43:55,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:55,622] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:43:55,641] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:43:55,848] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.428 seconds
[2022-04-11 19:44:03,502] {scheduler_job.py:153} INFO - Started process (PID=23153) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:03,511] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:03,514] {logging_mixin.py:112} INFO - [2022-04-11 19:44:03,514] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:03,577] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:03,726] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:03,729] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:03,742] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:03,955] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.453 seconds
[2022-04-11 19:44:11,504] {scheduler_job.py:153} INFO - Started process (PID=23157) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:11,515] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:11,517] {logging_mixin.py:112} INFO - [2022-04-11 19:44:11,517] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:11,624] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:12,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:12,051] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:12,079] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:12,756] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.252 seconds
[2022-04-11 19:44:19,514] {scheduler_job.py:153} INFO - Started process (PID=23161) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:19,527] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:19,529] {logging_mixin.py:112} INFO - [2022-04-11 19:44:19,528] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:19,638] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:20,044] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:20,047] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:20,074] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:20,366] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.852 seconds
[2022-04-11 19:44:27,542] {scheduler_job.py:153} INFO - Started process (PID=23165) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:27,552] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:27,554] {logging_mixin.py:112} INFO - [2022-04-11 19:44:27,554] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:27,608] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:27,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:27,798] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:27,807] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:28,093] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.552 seconds
[2022-04-11 19:44:35,543] {scheduler_job.py:153} INFO - Started process (PID=23170) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:35,581] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:35,583] {logging_mixin.py:112} INFO - [2022-04-11 19:44:35,583] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:35,660] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:36,157] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:36,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:36,189] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:36,472] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.938 seconds
[2022-04-11 19:44:43,480] {scheduler_job.py:153} INFO - Started process (PID=23174) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:43,487] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:43,490] {logging_mixin.py:112} INFO - [2022-04-11 19:44:43,489] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:43,530] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:43,640] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:43,642] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:43,652] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:43,881] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.401 seconds
[2022-04-11 19:44:51,566] {scheduler_job.py:153} INFO - Started process (PID=23178) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:51,576] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:51,580] {logging_mixin.py:112} INFO - [2022-04-11 19:44:51,580] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:51,819] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:44:52,035] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:52,037] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:44:52,047] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:52,568] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.003 seconds
[2022-04-11 19:44:59,530] {scheduler_job.py:153} INFO - Started process (PID=23182) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:59,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:44:59,550] {logging_mixin.py:112} INFO - [2022-04-11 19:44:59,550] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:44:59,661] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:00,324] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:00,351] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:00,387] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:00,936] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.406 seconds
[2022-04-11 19:45:07,571] {scheduler_job.py:153} INFO - Started process (PID=23187) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:07,587] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:07,590] {logging_mixin.py:112} INFO - [2022-04-11 19:45:07,590] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:07,620] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:07,987] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:08,003] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:08,030] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:08,544] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.973 seconds
[2022-04-11 19:45:15,609] {scheduler_job.py:153} INFO - Started process (PID=23191) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:15,616] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:15,617] {logging_mixin.py:112} INFO - [2022-04-11 19:45:15,617] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:15,681] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:15,860] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:15,887] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:15,957] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:16,443] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.834 seconds
[2022-04-11 19:45:23,535] {scheduler_job.py:153} INFO - Started process (PID=23195) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:23,542] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:23,544] {logging_mixin.py:112} INFO - [2022-04-11 19:45:23,543] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:23,575] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:23,664] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:23,665] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:23,678] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:23,847] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.312 seconds
[2022-04-11 19:45:31,601] {scheduler_job.py:153} INFO - Started process (PID=23199) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:31,617] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:31,630] {logging_mixin.py:112} INFO - [2022-04-11 19:45:31,630] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:32,697] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:33,195] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:33,198] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:33,211] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:33,418] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.817 seconds
[2022-04-11 19:45:39,703] {scheduler_job.py:153} INFO - Started process (PID=23203) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:39,748] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:39,750] {logging_mixin.py:112} INFO - [2022-04-11 19:45:39,750] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:40,045] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:40,288] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:40,291] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:40,301] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:40,571] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.867 seconds
[2022-04-11 19:45:47,626] {scheduler_job.py:153} INFO - Started process (PID=23208) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:47,647] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:47,657] {logging_mixin.py:112} INFO - [2022-04-11 19:45:47,657] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:47,809] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:47,995] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:47,997] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:48,008] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:48,256] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.631 seconds
[2022-04-11 19:45:55,626] {scheduler_job.py:153} INFO - Started process (PID=23212) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:55,635] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:45:55,637] {logging_mixin.py:112} INFO - [2022-04-11 19:45:55,636] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:55,945] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:45:56,145] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:56,148] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:45:56,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:45:56,376] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.750 seconds
[2022-04-11 19:46:03,662] {scheduler_job.py:153} INFO - Started process (PID=23216) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:03,669] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:03,672] {logging_mixin.py:112} INFO - [2022-04-11 19:46:03,672] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:03,700] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:03,797] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:03,799] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:03,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:03,988] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.326 seconds
[2022-04-11 19:46:11,693] {scheduler_job.py:153} INFO - Started process (PID=23220) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:11,712] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:11,714] {logging_mixin.py:112} INFO - [2022-04-11 19:46:11,714] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:11,774] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:11,883] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:11,886] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:11,900] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:12,076] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.382 seconds
[2022-04-11 19:46:20,132] {scheduler_job.py:153} INFO - Started process (PID=23225) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:20,194] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:20,197] {logging_mixin.py:112} INFO - [2022-04-11 19:46:20,197] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:20,433] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:21,433] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:21,437] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:21,458] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:22,179] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.047 seconds
[2022-04-11 19:46:28,267] {scheduler_job.py:153} INFO - Started process (PID=23229) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:28,287] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:28,297] {logging_mixin.py:112} INFO - [2022-04-11 19:46:28,297] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:28,411] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:29,533] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:29,542] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:29,564] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:29,863] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.596 seconds
[2022-04-11 19:46:35,949] {scheduler_job.py:153} INFO - Started process (PID=23233) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:35,969] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:35,981] {logging_mixin.py:112} INFO - [2022-04-11 19:46:35,981] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:36,046] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:36,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:36,451] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:36,496] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:37,549] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.600 seconds
[2022-04-11 19:46:44,778] {scheduler_job.py:153} INFO - Started process (PID=23237) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:44,788] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:44,790] {logging_mixin.py:112} INFO - [2022-04-11 19:46:44,790] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:44,861] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:44,973] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:44,975] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:44,986] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:45,181] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.403 seconds
[2022-04-11 19:46:53,586] {scheduler_job.py:153} INFO - Started process (PID=23241) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:53,599] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:46:53,601] {logging_mixin.py:112} INFO - [2022-04-11 19:46:53,601] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:53,687] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:46:53,952] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:53,959] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:46:53,987] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:46:54,329] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.743 seconds
[2022-04-11 19:47:00,999] {scheduler_job.py:153} INFO - Started process (PID=23246) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:01,016] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:01,018] {logging_mixin.py:112} INFO - [2022-04-11 19:47:01,018] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:01,084] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:01,395] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:01,407] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:01,453] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:02,366] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.367 seconds
[2022-04-11 19:47:08,980] {scheduler_job.py:153} INFO - Started process (PID=23250) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:08,986] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:08,989] {logging_mixin.py:112} INFO - [2022-04-11 19:47:08,989] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:09,026] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:09,113] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:09,114] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:09,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:09,367] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.387 seconds
[2022-04-11 19:47:17,002] {scheduler_job.py:153} INFO - Started process (PID=23254) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:17,007] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:17,009] {logging_mixin.py:112} INFO - [2022-04-11 19:47:17,008] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:17,057] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:17,188] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:17,190] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:17,199] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:17,464] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.463 seconds
[2022-04-11 19:47:25,006] {scheduler_job.py:153} INFO - Started process (PID=23258) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:25,012] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:25,013] {logging_mixin.py:112} INFO - [2022-04-11 19:47:25,013] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:25,042] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:25,112] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:25,113] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:25,121] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:25,273] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.267 seconds
[2022-04-11 19:47:33,027] {scheduler_job.py:153} INFO - Started process (PID=23262) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:33,032] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:33,037] {logging_mixin.py:112} INFO - [2022-04-11 19:47:33,037] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:33,072] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:33,170] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:33,173] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:33,182] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:33,398] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.371 seconds
[2022-04-11 19:47:41,060] {scheduler_job.py:153} INFO - Started process (PID=23267) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:41,068] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:41,070] {logging_mixin.py:112} INFO - [2022-04-11 19:47:41,070] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:41,130] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:41,285] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:41,287] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:41,300] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:41,532] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.472 seconds
[2022-04-11 19:47:49,053] {scheduler_job.py:153} INFO - Started process (PID=23271) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:49,062] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:49,065] {logging_mixin.py:112} INFO - [2022-04-11 19:47:49,064] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:49,127] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:49,242] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:49,245] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:49,261] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:49,446] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.393 seconds
[2022-04-11 19:47:58,329] {scheduler_job.py:153} INFO - Started process (PID=23275) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:58,347] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:47:58,349] {logging_mixin.py:112} INFO - [2022-04-11 19:47:58,349] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:58,533] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:47:59,139] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:59,154] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:47:59,214] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:47:59,671] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.343 seconds
[2022-04-11 19:48:06,570] {scheduler_job.py:153} INFO - Started process (PID=23279) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:06,581] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:06,583] {logging_mixin.py:112} INFO - [2022-04-11 19:48:06,583] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:06,669] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:06,812] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:06,815] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:06,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:07,085] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.515 seconds
[2022-04-11 19:48:18,151] {scheduler_job.py:153} INFO - Started process (PID=23284) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:18,215] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:18,245] {logging_mixin.py:112} INFO - [2022-04-11 19:48:18,245] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:18,869] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:19,032] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:19,034] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:19,049] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:19,429] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.278 seconds
[2022-04-11 19:48:23,353] {scheduler_job.py:153} INFO - Started process (PID=23288) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:23,361] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:23,364] {logging_mixin.py:112} INFO - [2022-04-11 19:48:23,363] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:23,415] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:23,537] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:23,543] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:23,563] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:23,804] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.451 seconds
[2022-04-11 19:48:31,417] {scheduler_job.py:153} INFO - Started process (PID=23292) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:31,435] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:31,438] {logging_mixin.py:112} INFO - [2022-04-11 19:48:31,437] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:31,518] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:31,707] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:31,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:31,721] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:32,001] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.584 seconds
[2022-04-11 19:48:39,452] {scheduler_job.py:153} INFO - Started process (PID=23297) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:39,467] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:39,469] {logging_mixin.py:112} INFO - [2022-04-11 19:48:39,468] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:39,550] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:39,697] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:39,699] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:39,718] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:39,947] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.495 seconds
[2022-04-11 19:48:47,377] {scheduler_job.py:153} INFO - Started process (PID=23301) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:47,386] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:47,387] {logging_mixin.py:112} INFO - [2022-04-11 19:48:47,387] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:47,435] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:47,558] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:47,560] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:47,569] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:47,831] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.456 seconds
[2022-04-11 19:48:55,465] {scheduler_job.py:153} INFO - Started process (PID=23306) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:55,484] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:48:55,501] {logging_mixin.py:112} INFO - [2022-04-11 19:48:55,500] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:55,661] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:48:55,901] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:55,903] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:48:55,920] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:48:56,137] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.672 seconds
[2022-04-11 19:49:03,434] {scheduler_job.py:153} INFO - Started process (PID=23310) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:03,445] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:03,447] {logging_mixin.py:112} INFO - [2022-04-11 19:49:03,446] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:03,512] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:03,619] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:03,620] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:03,630] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:03,812] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.379 seconds
[2022-04-11 19:49:11,828] {scheduler_job.py:153} INFO - Started process (PID=23314) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:11,850] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:11,853] {logging_mixin.py:112} INFO - [2022-04-11 19:49:11,853] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:12,010] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:12,148] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:12,151] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:12,170] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:12,584] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.757 seconds
[2022-04-11 19:49:19,441] {scheduler_job.py:153} INFO - Started process (PID=23318) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:19,454] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:19,459] {logging_mixin.py:112} INFO - [2022-04-11 19:49:19,458] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:19,505] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:19,767] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:19,769] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:19,781] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:20,019] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.578 seconds
[2022-04-11 19:49:27,811] {scheduler_job.py:153} INFO - Started process (PID=23323) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:27,899] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:27,961] {logging_mixin.py:112} INFO - [2022-04-11 19:49:27,961] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:28,243] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:28,446] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:28,448] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:28,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:28,671] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.861 seconds
[2022-04-11 19:49:35,525] {scheduler_job.py:153} INFO - Started process (PID=23327) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:35,532] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:35,534] {logging_mixin.py:112} INFO - [2022-04-11 19:49:35,534] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:35,597] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:35,715] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:35,717] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:35,736] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:36,017] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.492 seconds
[2022-04-11 19:49:43,593] {scheduler_job.py:153} INFO - Started process (PID=23331) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:43,607] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:43,631] {logging_mixin.py:112} INFO - [2022-04-11 19:49:43,631] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:43,832] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:43,998] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:44,000] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:44,023] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:44,781] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.188 seconds
[2022-04-11 19:49:51,517] {scheduler_job.py:153} INFO - Started process (PID=23335) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:51,523] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:51,525] {logging_mixin.py:112} INFO - [2022-04-11 19:49:51,525] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:51,557] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:51,646] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:51,648] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:51,658] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:51,895] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.378 seconds
[2022-04-11 19:49:59,498] {scheduler_job.py:153} INFO - Started process (PID=23340) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:59,506] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:49:59,508] {logging_mixin.py:112} INFO - [2022-04-11 19:49:59,508] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:49:59,547] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:49:59,656] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:59,667] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:49:59,689] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:00,030] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.532 seconds
[2022-04-11 19:50:07,574] {scheduler_job.py:153} INFO - Started process (PID=23344) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:07,591] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:07,607] {logging_mixin.py:112} INFO - [2022-04-11 19:50:07,607] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:07,663] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:07,812] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:07,814] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:07,825] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:07,982] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.409 seconds
[2022-04-11 19:50:15,582] {scheduler_job.py:153} INFO - Started process (PID=23348) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:15,593] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:15,594] {logging_mixin.py:112} INFO - [2022-04-11 19:50:15,594] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:15,653] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:15,831] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:15,834] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:15,849] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:16,060] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.479 seconds
[2022-04-11 19:50:23,538] {scheduler_job.py:153} INFO - Started process (PID=23352) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:23,548] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:23,551] {logging_mixin.py:112} INFO - [2022-04-11 19:50:23,550] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:23,598] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:23,708] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:23,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:23,718] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:23,979] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.441 seconds
[2022-04-11 19:50:31,558] {scheduler_job.py:153} INFO - Started process (PID=23356) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:31,564] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:31,566] {logging_mixin.py:112} INFO - [2022-04-11 19:50:31,566] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:31,647] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:31,757] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:31,759] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:31,767] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:31,967] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.409 seconds
[2022-04-11 19:50:39,589] {scheduler_job.py:153} INFO - Started process (PID=23361) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:39,595] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:39,596] {logging_mixin.py:112} INFO - [2022-04-11 19:50:39,596] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:39,627] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:39,710] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:39,712] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:39,722] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:39,865] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.276 seconds
[2022-04-11 19:50:47,576] {scheduler_job.py:153} INFO - Started process (PID=23365) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:47,583] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:47,584] {logging_mixin.py:112} INFO - [2022-04-11 19:50:47,584] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:47,643] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:47,741] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:47,744] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:47,759] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:48,035] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.459 seconds
[2022-04-11 19:50:55,612] {scheduler_job.py:153} INFO - Started process (PID=23369) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:55,621] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:50:55,624] {logging_mixin.py:112} INFO - [2022-04-11 19:50:55,624] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:55,662] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:50:55,794] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:55,796] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:50:55,810] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:50:56,034] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.423 seconds
[2022-04-11 19:51:03,612] {scheduler_job.py:153} INFO - Started process (PID=23373) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:03,619] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:03,623] {logging_mixin.py:112} INFO - [2022-04-11 19:51:03,622] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:03,682] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:03,815] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:03,817] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:03,830] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:04,126] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.513 seconds
[2022-04-11 19:51:11,643] {scheduler_job.py:153} INFO - Started process (PID=23378) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:11,649] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:11,651] {logging_mixin.py:112} INFO - [2022-04-11 19:51:11,651] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:11,770] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:12,080] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:12,098] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:12,150] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:12,697] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.054 seconds
[2022-04-11 19:51:19,649] {scheduler_job.py:153} INFO - Started process (PID=23382) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:19,659] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:19,661] {logging_mixin.py:112} INFO - [2022-04-11 19:51:19,661] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:19,699] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:19,797] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:19,799] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:19,808] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:19,985] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.336 seconds
[2022-04-11 19:51:27,637] {scheduler_job.py:153} INFO - Started process (PID=23386) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:27,643] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:27,644] {logging_mixin.py:112} INFO - [2022-04-11 19:51:27,644] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:27,698] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:27,853] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:27,858] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:27,872] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:28,116] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.479 seconds
[2022-04-11 19:51:35,679] {scheduler_job.py:153} INFO - Started process (PID=23390) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:35,693] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:35,696] {logging_mixin.py:112} INFO - [2022-04-11 19:51:35,696] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:35,780] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:35,962] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:35,965] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:35,978] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:36,415] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.736 seconds
[2022-04-11 19:51:44,000] {scheduler_job.py:153} INFO - Started process (PID=23395) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:44,019] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:44,032] {logging_mixin.py:112} INFO - [2022-04-11 19:51:44,032] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:44,412] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:46,330] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:46,348] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:46,408] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:48,892] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 4.892 seconds
[2022-04-11 19:51:53,269] {scheduler_job.py:153} INFO - Started process (PID=23399) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:53,286] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:51:53,288] {logging_mixin.py:112} INFO - [2022-04-11 19:51:53,288] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:53,349] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:51:53,579] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:53,583] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:51:53,621] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:51:55,264] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.995 seconds
[2022-04-11 19:52:01,403] {scheduler_job.py:153} INFO - Started process (PID=23403) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:01,421] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:01,428] {logging_mixin.py:112} INFO - [2022-04-11 19:52:01,427] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:01,567] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:01,679] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:01,681] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:01,695] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:02,284] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.882 seconds
[2022-04-11 19:52:09,259] {scheduler_job.py:153} INFO - Started process (PID=23407) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:09,269] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:09,274] {logging_mixin.py:112} INFO - [2022-04-11 19:52:09,274] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:09,320] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:09,444] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:09,447] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:09,461] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:09,659] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.400 seconds
[2022-04-11 19:52:17,249] {scheduler_job.py:153} INFO - Started process (PID=23411) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:17,256] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:17,257] {logging_mixin.py:112} INFO - [2022-04-11 19:52:17,257] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:17,355] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:17,732] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:17,734] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:17,750] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:18,005] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.755 seconds
[2022-04-11 19:52:25,301] {scheduler_job.py:153} INFO - Started process (PID=23416) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:25,335] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:25,357] {logging_mixin.py:112} INFO - [2022-04-11 19:52:25,352] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:25,497] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:25,736] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:25,751] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:25,832] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:26,150] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.849 seconds
[2022-04-11 19:52:34,486] {scheduler_job.py:153} INFO - Started process (PID=23420) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:34,500] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:34,502] {logging_mixin.py:112} INFO - [2022-04-11 19:52:34,502] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:34,562] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:34,695] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:34,699] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:34,714] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:35,265] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.779 seconds
[2022-04-11 19:52:42,966] {scheduler_job.py:153} INFO - Started process (PID=23424) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:42,981] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:42,983] {logging_mixin.py:112} INFO - [2022-04-11 19:52:42,983] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:43,042] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:43,240] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:43,248] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:43,268] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:43,483] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.518 seconds
[2022-04-11 19:52:51,204] {scheduler_job.py:153} INFO - Started process (PID=23428) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:51,225] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:51,234] {logging_mixin.py:112} INFO - [2022-04-11 19:52:51,234] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:51,396] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:51,666] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:51,669] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:51,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:52,021] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.818 seconds
[2022-04-11 19:52:59,309] {scheduler_job.py:153} INFO - Started process (PID=23432) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:59,343] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:52:59,362] {logging_mixin.py:112} INFO - [2022-04-11 19:52:59,362] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:52:59,569] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:52:59,891] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:59,899] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:52:59,940] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:00,568] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.259 seconds
[2022-04-11 19:53:07,111] {scheduler_job.py:153} INFO - Started process (PID=23437) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:07,129] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:07,133] {logging_mixin.py:112} INFO - [2022-04-11 19:53:07,132] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:07,318] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:07,548] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:07,551] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:07,609] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:08,335] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.224 seconds
[2022-04-11 19:53:15,566] {scheduler_job.py:153} INFO - Started process (PID=23441) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:15,586] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:15,588] {logging_mixin.py:112} INFO - [2022-04-11 19:53:15,588] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:15,679] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:15,879] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:15,883] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:15,916] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:16,387] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.821 seconds
[2022-04-11 19:53:24,482] {scheduler_job.py:153} INFO - Started process (PID=23445) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:24,493] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:24,495] {logging_mixin.py:112} INFO - [2022-04-11 19:53:24,495] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:24,630] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:24,988] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:24,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:25,015] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:25,462] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.980 seconds
[2022-04-11 19:53:32,209] {scheduler_job.py:153} INFO - Started process (PID=23449) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:32,225] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:32,236] {logging_mixin.py:112} INFO - [2022-04-11 19:53:32,236] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:32,309] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:32,519] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:32,529] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:32,549] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:32,820] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.612 seconds
[2022-04-11 19:53:40,216] {scheduler_job.py:153} INFO - Started process (PID=23453) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:40,224] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:40,226] {logging_mixin.py:112} INFO - [2022-04-11 19:53:40,226] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:40,292] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:40,474] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:40,488] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:40,508] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:40,836] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.620 seconds
[2022-04-11 19:53:48,273] {scheduler_job.py:153} INFO - Started process (PID=23458) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:48,279] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:48,281] {logging_mixin.py:112} INFO - [2022-04-11 19:53:48,281] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:48,327] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:48,462] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:48,465] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:48,475] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:48,645] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.373 seconds
[2022-04-11 19:53:56,257] {scheduler_job.py:153} INFO - Started process (PID=23463) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:56,272] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:53:56,274] {logging_mixin.py:112} INFO - [2022-04-11 19:53:56,274] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:56,407] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:53:56,602] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:56,605] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:53:56,622] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:53:56,892] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.635 seconds
[2022-04-11 19:54:04,526] {scheduler_job.py:153} INFO - Started process (PID=23467) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:04,545] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:04,552] {logging_mixin.py:112} INFO - [2022-04-11 19:54:04,552] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:04,653] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:05,008] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:05,013] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:05,029] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:05,288] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.762 seconds
[2022-04-11 19:54:12,313] {scheduler_job.py:153} INFO - Started process (PID=23471) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:12,319] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:12,325] {logging_mixin.py:112} INFO - [2022-04-11 19:54:12,324] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:12,637] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:12,966] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:12,969] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:13,002] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:13,405] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.092 seconds
[2022-04-11 19:54:20,264] {scheduler_job.py:153} INFO - Started process (PID=23476) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:20,272] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:20,274] {logging_mixin.py:112} INFO - [2022-04-11 19:54:20,274] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:20,323] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:20,453] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:20,458] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:20,481] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:20,714] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.450 seconds
[2022-04-11 19:54:28,286] {scheduler_job.py:153} INFO - Started process (PID=23480) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:28,298] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:28,300] {logging_mixin.py:112} INFO - [2022-04-11 19:54:28,300] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:28,351] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:28,455] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:28,457] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:28,468] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:28,656] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.370 seconds
[2022-04-11 19:54:36,318] {scheduler_job.py:153} INFO - Started process (PID=23484) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:36,335] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:36,336] {logging_mixin.py:112} INFO - [2022-04-11 19:54:36,336] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:36,391] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:36,473] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:36,475] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:36,483] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:36,650] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.332 seconds
[2022-04-11 19:54:44,308] {scheduler_job.py:153} INFO - Started process (PID=23489) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:44,318] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:44,320] {logging_mixin.py:112} INFO - [2022-04-11 19:54:44,320] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:44,354] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:44,482] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:44,484] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:44,495] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:44,663] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.355 seconds
[2022-04-11 19:54:52,336] {scheduler_job.py:153} INFO - Started process (PID=23494) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:52,345] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:54:52,347] {logging_mixin.py:112} INFO - [2022-04-11 19:54:52,346] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:52,392] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:54:52,562] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:52,564] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:54:52,581] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:54:52,766] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.430 seconds
[2022-04-11 19:55:00,375] {scheduler_job.py:153} INFO - Started process (PID=23498) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:00,387] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:00,392] {logging_mixin.py:112} INFO - [2022-04-11 19:55:00,391] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:00,443] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:00,529] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:00,530] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:00,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:00,691] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.317 seconds
[2022-04-11 19:55:08,324] {scheduler_job.py:153} INFO - Started process (PID=23502) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:08,341] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:08,348] {logging_mixin.py:112} INFO - [2022-04-11 19:55:08,348] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:08,397] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:08,521] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:08,529] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:08,550] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:08,741] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.417 seconds
[2022-04-11 19:55:16,378] {scheduler_job.py:153} INFO - Started process (PID=23506) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:16,386] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:16,393] {logging_mixin.py:112} INFO - [2022-04-11 19:55:16,392] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:16,455] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:16,629] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:16,632] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:16,650] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:16,917] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.539 seconds
[2022-04-11 19:55:25,067] {scheduler_job.py:153} INFO - Started process (PID=23511) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:25,105] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:25,121] {logging_mixin.py:112} INFO - [2022-04-11 19:55:25,120] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:25,266] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:25,519] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:25,522] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:25,540] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:25,930] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.864 seconds
[2022-04-11 19:55:32,395] {scheduler_job.py:153} INFO - Started process (PID=23515) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:32,404] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:32,408] {logging_mixin.py:112} INFO - [2022-04-11 19:55:32,407] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:32,454] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:32,586] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:32,590] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:32,606] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:32,809] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.414 seconds
[2022-04-11 19:55:40,994] {scheduler_job.py:153} INFO - Started process (PID=23519) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:41,020] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:41,032] {logging_mixin.py:112} INFO - [2022-04-11 19:55:41,032] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:41,270] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:42,285] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:42,299] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:42,324] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:43,167] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.173 seconds
[2022-04-11 19:55:50,518] {scheduler_job.py:153} INFO - Started process (PID=23523) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:50,533] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:55:50,535] {logging_mixin.py:112} INFO - [2022-04-11 19:55:50,534] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:50,620] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:55:50,854] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:50,863] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:55:50,903] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:55:51,482] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.964 seconds
[2022-04-11 19:56:00,818] {scheduler_job.py:153} INFO - Started process (PID=23527) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:56:00,831] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:56:00,833] {logging_mixin.py:112} INFO - [2022-04-11 19:56:00,833] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:56:00,913] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:56:01,091] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:56:01,098] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:56:01,112] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:56:01,526] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.708 seconds
[2022-04-11 19:56:46,106] {scheduler_job.py:153} INFO - Started process (PID=23538) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:56:46,217] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:56:46,220] {logging_mixin.py:112} INFO - [2022-04-11 19:56:46,219] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:56:46,392] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:56:46,926] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:56:46,929] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:56:46,945] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:56:50,054] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.948 seconds
[2022-04-11 19:57:21,839] {scheduler_job.py:153} INFO - Started process (PID=23550) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:21,857] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:57:21,885] {logging_mixin.py:112} INFO - [2022-04-11 19:57:21,885] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:22,115] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:57:22,471] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:22,475] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:22,486] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:22,702] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.863 seconds
[2022-04-11 19:57:29,767] {scheduler_job.py:153} INFO - Started process (PID=23554) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:29,774] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:57:29,776] {logging_mixin.py:112} INFO - [2022-04-11 19:57:29,775] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:29,816] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:57:29,912] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:29,914] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:29,925] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:30,084] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.317 seconds
[2022-04-11 19:57:37,911] {scheduler_job.py:153} INFO - Started process (PID=23558) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:37,943] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:57:37,954] {logging_mixin.py:112} INFO - [2022-04-11 19:57:37,954] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:38,115] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:57:38,518] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:38,520] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:38,539] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:40,196] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.285 seconds
[2022-04-11 19:57:47,981] {scheduler_job.py:153} INFO - Started process (PID=23563) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:48,001] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:57:48,003] {logging_mixin.py:112} INFO - [2022-04-11 19:57:48,002] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:48,098] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:57:48,301] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:48,303] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:48,329] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:48,660] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.679 seconds
[2022-04-11 19:57:53,786] {scheduler_job.py:153} INFO - Started process (PID=23567) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:53,801] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:57:53,803] {logging_mixin.py:112} INFO - [2022-04-11 19:57:53,803] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:53,881] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:57:54,055] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:54,064] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:57:54,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:57:54,368] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.583 seconds
[2022-04-11 19:58:01,805] {scheduler_job.py:153} INFO - Started process (PID=23571) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:01,815] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:58:01,818] {logging_mixin.py:112} INFO - [2022-04-11 19:58:01,817] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:01,869] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:58:01,991] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:01,993] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:02,006] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:02,214] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.409 seconds
[2022-04-11 19:58:25,471] {scheduler_job.py:153} INFO - Started process (PID=23575) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:25,534] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:58:25,558] {logging_mixin.py:112} INFO - [2022-04-11 19:58:25,558] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:26,196] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:58:28,072] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:28,104] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:28,135] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:28,546] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 3.075 seconds
[2022-04-11 19:58:32,386] {scheduler_job.py:153} INFO - Started process (PID=23579) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:32,415] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:58:32,417] {logging_mixin.py:112} INFO - [2022-04-11 19:58:32,417] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:32,485] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:58:32,665] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:32,667] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:32,698] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:33,330] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.944 seconds
[2022-04-11 19:58:40,423] {scheduler_job.py:153} INFO - Started process (PID=23583) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:40,441] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:58:40,453] {logging_mixin.py:112} INFO - [2022-04-11 19:58:40,452] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:40,605] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:58:40,797] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:40,802] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:40,833] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:41,835] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.412 seconds
[2022-04-11 19:58:55,639] {scheduler_job.py:153} INFO - Started process (PID=23588) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:55,668] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:58:55,672] {logging_mixin.py:112} INFO - [2022-04-11 19:58:55,671] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:56,076] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:58:56,396] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:56,398] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:56,429] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:56,869] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.230 seconds
[2022-04-11 19:58:59,199] {scheduler_job.py:153} INFO - Started process (PID=23592) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:59,208] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:58:59,210] {logging_mixin.py:112} INFO - [2022-04-11 19:58:59,209] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:59,273] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:58:59,416] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:59,425] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:58:59,439] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:58:59,752] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.554 seconds
[2022-04-11 19:59:06,457] {scheduler_job.py:153} INFO - Started process (PID=23596) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:06,468] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:06,469] {logging_mixin.py:112} INFO - [2022-04-11 19:59:06,469] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:06,549] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:06,740] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:06,743] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:06,762] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:07,083] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.627 seconds
[2022-04-11 19:59:14,494] {scheduler_job.py:153} INFO - Started process (PID=23600) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:14,503] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:14,529] {logging_mixin.py:112} INFO - [2022-04-11 19:59:14,529] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:14,618] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:14,922] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:14,931] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:14,962] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:15,266] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.772 seconds
[2022-04-11 19:59:28,818] {scheduler_job.py:153} INFO - Started process (PID=23605) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:28,843] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:28,847] {logging_mixin.py:112} INFO - [2022-04-11 19:59:28,845] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:28,904] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:29,053] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:29,055] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:29,073] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:29,286] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.468 seconds
[2022-04-11 19:59:31,317] {scheduler_job.py:153} INFO - Started process (PID=23609) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:31,328] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:31,330] {logging_mixin.py:112} INFO - [2022-04-11 19:59:31,330] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:31,381] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:31,512] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:31,515] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:31,529] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:31,753] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.436 seconds
[2022-04-11 19:59:43,256] {scheduler_job.py:153} INFO - Started process (PID=23614) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:43,275] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:43,283] {logging_mixin.py:112} INFO - [2022-04-11 19:59:43,282] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:43,388] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:43,552] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:43,557] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:43,572] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:43,999] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.743 seconds
[2022-04-11 19:59:49,338] {scheduler_job.py:153} INFO - Started process (PID=23618) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:49,351] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:49,353] {logging_mixin.py:112} INFO - [2022-04-11 19:59:49,353] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:49,412] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:49,539] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:49,543] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:49,553] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:49,780] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.443 seconds
[2022-04-11 19:59:57,245] {scheduler_job.py:153} INFO - Started process (PID=23622) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:57,261] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 19:59:57,264] {logging_mixin.py:112} INFO - [2022-04-11 19:59:57,264] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:57,396] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 19:59:57,521] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:57,529] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 19:59:57,547] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 19:59:58,187] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.941 seconds
[2022-04-11 20:00:05,785] {scheduler_job.py:153} INFO - Started process (PID=23627) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:05,801] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:05,804] {logging_mixin.py:112} INFO - [2022-04-11 20:00:05,803] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:05,949] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:06,138] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:06,168] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:06,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:06,737] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.953 seconds
[2022-04-11 20:00:14,181] {scheduler_job.py:153} INFO - Started process (PID=23632) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:14,195] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:14,197] {logging_mixin.py:112} INFO - [2022-04-11 20:00:14,197] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:14,286] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:14,477] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:14,480] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:14,534] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:14,820] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.640 seconds
[2022-04-11 20:00:21,389] {scheduler_job.py:153} INFO - Started process (PID=23636) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:21,404] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:21,412] {logging_mixin.py:112} INFO - [2022-04-11 20:00:21,411] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:21,546] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:21,953] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:22,048] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:22,082] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:22,802] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.413 seconds
[2022-04-11 20:00:31,840] {scheduler_job.py:153} INFO - Started process (PID=23641) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:31,890] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:31,903] {logging_mixin.py:112} INFO - [2022-04-11 20:00:31,902] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:32,218] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:33,069] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:33,082] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:33,119] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:34,553] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.714 seconds
[2022-04-11 20:00:37,646] {scheduler_job.py:153} INFO - Started process (PID=23645) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:37,666] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:37,669] {logging_mixin.py:112} INFO - [2022-04-11 20:00:37,668] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:37,736] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:38,167] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:38,169] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:38,194] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:38,649] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.003 seconds
[2022-04-11 20:00:45,665] {scheduler_job.py:153} INFO - Started process (PID=23649) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:45,705] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:45,716] {logging_mixin.py:112} INFO - [2022-04-11 20:00:45,715] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:45,828] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:46,092] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:46,099] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:46,124] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:48,638] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 2.973 seconds
[2022-04-11 20:00:54,845] {scheduler_job.py:153} INFO - Started process (PID=23654) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:54,859] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:00:54,863] {logging_mixin.py:112} INFO - [2022-04-11 20:00:54,862] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:54,910] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:00:55,066] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:55,068] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:00:55,083] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:00:55,330] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.485 seconds
[2022-04-11 20:01:02,831] {scheduler_job.py:153} INFO - Started process (PID=23658) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:02,845] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:02,847] {logging_mixin.py:112} INFO - [2022-04-11 20:01:02,847] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:02,895] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:03,014] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:03,016] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:03,029] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:03,222] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.391 seconds
[2022-04-11 20:01:10,946] {scheduler_job.py:153} INFO - Started process (PID=23662) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:10,975] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:10,981] {logging_mixin.py:112} INFO - [2022-04-11 20:01:10,980] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:11,159] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:11,307] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:11,319] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:11,333] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:11,651] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.705 seconds
[2022-04-11 20:01:19,020] {scheduler_job.py:153} INFO - Started process (PID=23666) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:19,036] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:19,038] {logging_mixin.py:112} INFO - [2022-04-11 20:01:19,037] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:19,252] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:19,449] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:19,452] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:19,467] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:19,729] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.710 seconds
[2022-04-11 20:01:27,747] {scheduler_job.py:153} INFO - Started process (PID=23671) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:27,768] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:27,780] {logging_mixin.py:112} INFO - [2022-04-11 20:01:27,779] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:27,871] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:28,267] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:28,277] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:28,303] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:29,531] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 1.785 seconds
[2022-04-11 20:01:35,037] {scheduler_job.py:153} INFO - Started process (PID=23675) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:35,054] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:35,061] {logging_mixin.py:112} INFO - [2022-04-11 20:01:35,061] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:35,113] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:35,234] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:35,236] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:35,251] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:35,481] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.444 seconds
[2022-04-11 20:01:44,904] {scheduler_job.py:153} INFO - Started process (PID=23679) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:44,917] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:44,919] {logging_mixin.py:112} INFO - [2022-04-11 20:01:44,919] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:44,986] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:45,160] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:45,162] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:45,177] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:45,578] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.675 seconds
[2022-04-11 20:01:55,276] {scheduler_job.py:153} INFO - Started process (PID=23683) to work on /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:55,285] {scheduler_job.py:1562} INFO - Processing file /c/users/dan/airflow/dags/big_query_data_load.py for tasks to queue
[2022-04-11 20:01:55,287] {logging_mixin.py:112} INFO - [2022-04-11 20:01:55,286] {dagbag.py:396} INFO - Filling up the DagBag from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:55,370] {logging_mixin.py:112} INFO - /c/Users/Dan/airflow/secrets/keyfile.json
[2022-04-11 20:01:55,518] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/gcs_to_bq.py:183: PendingDeprecationWarning: Invalid arguments were passed to GoogleCloudStorageToBigQueryOperator (task_id: load_data). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'field_delimeter': ',', 'biqquery_conn_id': 'google_cloud_default'}
  super(GoogleCloudStorageToBigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:55,520] {logging_mixin.py:112} WARNING - /home/collid/.local/lib/python3.8/site-packages/airflow/contrib/operators/bigquery_operator.py:211: PendingDeprecationWarning: Invalid arguments were passed to BigQueryOperator (task_id: create_table). Support for passing such arguments will be dropped in Airflow 2.0. Invalid arguments were:
*args: ()
**kwargs: {'bigQuery_conn_id': 'google_cloud_default'}
  super(BigQueryOperator, self).__init__(*args, **kwargs)
[2022-04-11 20:01:55,534] {scheduler_job.py:1574} INFO - DAG(s) dict_keys(['bigquery_data_load']) retrieved from /c/users/dan/airflow/dags/big_query_data_load.py
[2022-04-11 20:01:55,878] {scheduler_job.py:161} INFO - Processing /c/users/dan/airflow/dags/big_query_data_load.py took 0.603 seconds
